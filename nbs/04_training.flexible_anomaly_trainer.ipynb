{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d3d1e8",
   "metadata": {},
   "source": [
    "# Flexible Anomaly Detection Trainer\n",
    "\n",
    "> A comprehensive, production-ready anomaly detection training function with full anomalib flexibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4e91d",
   "metadata": {},
   "source": [
    "This notebook provides a flexible, production-ready anomaly detection trainer that exposes all major anomalib parameters while maintaining robustness and error handling. The function can be used both programmatically and as a CLI tool via nbdev.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee334870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training.flexible_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bd2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c4324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Union, Dict, Any, Literal\n",
    "from datetime import datetime\n",
    "import json\n",
    "import yaml\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "\n",
    "# Core scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# PIL for image processing and cv2 for image processing\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "\n",
    "\n",
    "# FastCore for CLI and utilities\n",
    "from fastcore.all import *\n",
    "from fastcore.script import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f2db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42330b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.v2 import Compose, Resize, ToTensor, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd94191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Anomalib imports - CORRECTED for v1.2.0\n",
    "import anomalib\n",
    "from anomalib import TaskType, LearningType\n",
    "from anomalib.data.image.folder import Folder\n",
    "from anomalib.engine import Engine\n",
    "from anomalib.models import (\n",
    "    Padim, Patchcore, Cflow, Fastflow, Stfpm, \n",
    "    EfficientAd, Draem, ReverseDistillation,\n",
    "    Dfkde, Dfm, Ganomaly, Cfa, Csflow, Dsr, Fre, Rkde, Uflow\n",
    ")\n",
    "from anomalib.deploy import ExportType, TorchInferencer\n",
    "from anomalib.utils.normalization import NormalizationMethod  # Only MIN_MAX and NONE available\n",
    "from anomalib.metrics import ManualThreshold, F1AdaptiveThreshold  # Correct threshold classes\n",
    "from anomalib.callbacks import TilerConfigurationCallback\n",
    "from anomalib.utils.visualization.image import ImageVisualizer, VisualizationMode\n",
    "\n",
    "# Lightning imports\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, RichModelSummary\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from PIL import Image, ImageFile\n",
    "import PIL\n",
    "\n",
    "# Enable loading of truncated images - fixes PIL truncated image errors\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cef610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "logging.getLogger('lightning.pytorch').setLevel(logging.WARNING)\n",
    "\n",
    "# Environment detection utilities\n",
    "import psutil\n",
    "import platform\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934dc8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 9.6.0\n",
      "\n",
      "numpy      : 1.26.4\n",
      "matplotlib : 3.10.7\n",
      "anomalib   : 1.2.0\n",
      "fastcore   : 1.8.12\n",
      "torch      : 2.9.0\n",
      "torchvision: 0.24.0\n",
      "PIL        : 12.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -p numpy,matplotlib,anomalib,fastcore,torch,torchvision,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bf162",
   "metadata": {},
   "source": [
    "## Configuration Enums and Classes\n",
    "\n",
    "First, let's define all the configuration options with the correct anomalib v1.2.0 API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad67a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Global cache for environment detection to avoid duplicate detection and messages\n",
    "_env_cache = None\n",
    "\n",
    "def detect_environment() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Intelligent environment detection for optimal anomalib configuration.\n",
    "    Includes detection for HPC systems with NFS storage to prevent multiprocessing issues.\n",
    "    \"\"\"\n",
    "    global _env_cache\n",
    "    \n",
    "    # Return cached result if available\n",
    "    if _env_cache is not None:\n",
    "        return _env_cache\n",
    "    \n",
    "    env_info = {\n",
    "        'is_jupyter': False,\n",
    "        'is_colab': False,\n",
    "        'is_kaggle': False,\n",
    "        'is_hpc': False,\n",
    "        'is_nfs': False,\n",
    "        'platform': platform.system(),\n",
    "        'cpu_count': mp.cpu_count(),\n",
    "        'available_memory_gb': psutil.virtual_memory().total / (1024**3),\n",
    "        'recommended_num_workers': 4,\n",
    "        'recommended_batch_size': 16,\n",
    "        'recommended_accelerator': 'auto'\n",
    "    }\n",
    "    \n",
    "    # Detect Jupyter environments\n",
    "    try:\n",
    "        # Check if IPython is available and we're in a notebook\n",
    "        from IPython import get_ipython\n",
    "        if get_ipython() is not None:\n",
    "            env_info['is_jupyter'] = True\n",
    "            # Check for specific notebook types\n",
    "            if 'google.colab' in str(get_ipython()):\n",
    "                env_info['is_colab'] = True\n",
    "            elif 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "                env_info['is_kaggle'] = True\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Detect HPC environment indicators\n",
    "    hpc_indicators = [\n",
    "        'SLURM_JOB_ID', 'PBS_JOBID', 'LSB_JOBID',  # Job schedulers\n",
    "        'SLURM_CLUSTER_NAME', 'PBS_QUEUE', 'LSF_QUEUE',  # Queue systems\n",
    "        'MODULEPATH', 'LMOD_DIR',  # Module systems common in HPC\n",
    "    ]\n",
    "    \n",
    "    if any(indicator in os.environ for indicator in hpc_indicators):\n",
    "        env_info['is_hpc'] = True\n",
    "    \n",
    "    # Detect NFS filesystem (common in HPC environments)\n",
    "    try:\n",
    "        import subprocess\n",
    "        # Check if current working directory is on NFS\n",
    "        result = subprocess.run(['df', '-T', '.'], capture_output=True, text=True, timeout=5)\n",
    "        if 'nfs' in result.stdout.lower():\n",
    "            env_info['is_nfs'] = True\n",
    "    except (subprocess.TimeoutExpired, subprocess.SubprocessError, FileNotFoundError):\n",
    "        # If df command fails, try alternative detection\n",
    "        try:\n",
    "            # Check if /proc/mounts exists and contains NFS info\n",
    "            with open('/proc/mounts', 'r') as f:\n",
    "                mounts = f.read()\n",
    "                if 'nfs' in mounts and os.getcwd() in mounts:\n",
    "                    env_info['is_nfs'] = True\n",
    "        except (FileNotFoundError, PermissionError):\n",
    "            # Final fallback: check for common NFS patterns in hostname or environment\n",
    "            hostname = os.environ.get('HOSTNAME', '').lower()\n",
    "            if any(pattern in hostname for pattern in ['nfs', 'shared', 'cluster']):\n",
    "                env_info['is_nfs'] = True\n",
    "    \n",
    "    # Auto-configure based on environment\n",
    "    if env_info['is_jupyter'] or env_info['is_colab'] or env_info['is_kaggle']:\n",
    "        # Jupyter/Colab/Kaggle: Use single-threaded to avoid multiprocessing issues\n",
    "        env_info['recommended_num_workers'] = 0\n",
    "        env_info['recommended_accelerator'] = 'cpu' if env_info['platform'] == 'Windows' else 'auto'\n",
    "    elif env_info['is_hpc'] or env_info['is_nfs']:\n",
    "        # HPC/NFS environments: Use single-threaded to avoid \"Device or resource busy\" errors\n",
    "        env_info['recommended_num_workers'] = 0\n",
    "        env_info['recommended_accelerator'] = 'auto'\n",
    "        print(f\"üñ•Ô∏è  HPC/NFS environment detected - Using num_workers=0 to prevent multiprocessing issues\")\n",
    "    else:\n",
    "        # Script execution on local systems: Can use multiple workers\n",
    "        env_info['recommended_num_workers'] = min(4, max(1, env_info['cpu_count'] // 2))\n",
    "    \n",
    "    # Memory-aware batch size recommendations\n",
    "    memory_gb = env_info['available_memory_gb']\n",
    "    if memory_gb < 4:\n",
    "        env_info['recommended_batch_size'] = 4\n",
    "    elif memory_gb < 8:\n",
    "        env_info['recommended_batch_size'] = 8\n",
    "    elif memory_gb < 16:\n",
    "        env_info['recommended_batch_size'] = 16\n",
    "    else:\n",
    "        env_info['recommended_batch_size'] = 32\n",
    "    \n",
    "    # Cache the result for future calls\n",
    "    _env_cache = env_info\n",
    "    return env_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e80eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reset_environment_cache():\n",
    "    \"\"\"Reset the environment detection cache. Useful for testing.\"\"\"\n",
    "    global _env_cache\n",
    "    _env_cache = None\n",
    "\n",
    "def get_smart_defaults() -> Dict[str, Any]:\n",
    "    \"\"\"Get intelligent defaults based on current environment.\"\"\"\n",
    "    env = detect_environment()\n",
    "    \n",
    "    return {\n",
    "        'num_workers': env['recommended_num_workers'],\n",
    "        'train_batch_size': env['recommended_batch_size'],\n",
    "        'eval_batch_size': env['recommended_batch_size'],\n",
    "        'accelerator': env['recommended_accelerator'],\n",
    "        'enable_progress_bar': not env['is_jupyter'],  # Disable in Jupyter for cleaner output\n",
    "        'num_sanity_val_steps': 0 if env['is_jupyter'] else 2,  # Reduce in Jupyter\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e325f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Enhanced Environment Detection with HPC/NFS Support\n",
      "\n",
      "Environment Detection Results:\n",
      "   üîç Is Jupyter: True\n",
      "   üîç Is Colab: False\n",
      "   üîç Is Kaggle: False\n",
      "   üñ•Ô∏è  Is HPC: True\n",
      "   üíæ Is NFS: True\n",
      "   üîç Platform: Linux\n",
      "   üîç CPU Count: 96\n",
      "   üîç Memory: 2266.43 GB\n",
      "   üéØ Recommended num_workers: 0\n",
      "   üéØ Recommended batch_size: 32\n",
      "   üéØ Recommended accelerator: auto\n",
      "\n",
      "üí° Reasoning: Jupyter environment - using num_workers=0 for stability\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# Test the intelligent environment detection and smart defaults\n",
    "print(\"üß™ Testing Enhanced Environment Detection with HPC/NFS Support\\n\")\n",
    "\n",
    "# Show current environment info\n",
    "env_info = detect_environment()\n",
    "print(f\"Environment Detection Results:\")\n",
    "print(f\"   üîç Is Jupyter: {env_info['is_jupyter']}\")\n",
    "print(f\"   üîç Is Colab: {env_info['is_colab']}\")\n",
    "print(f\"   üîç Is Kaggle: {env_info['is_kaggle']}\")\n",
    "print(f\"   üñ•Ô∏è  Is HPC: {env_info['is_hpc']}\")\n",
    "print(f\"   üíæ Is NFS: {env_info['is_nfs']}\")\n",
    "print(f\"   üîç Platform: {env_info['platform']}\")\n",
    "print(f\"   üîç CPU Count: {env_info['cpu_count']}\")\n",
    "print(f\"   üîç Memory: {env_info['available_memory_gb']:.2f} GB\")\n",
    "print(f\"   üéØ Recommended num_workers: {env_info['recommended_num_workers']}\")\n",
    "print(f\"   üéØ Recommended batch_size: {env_info['recommended_batch_size']}\")\n",
    "print(f\"   üéØ Recommended accelerator: {env_info['recommended_accelerator']}\")\n",
    "\n",
    "# Show reasoning\n",
    "if env_info['is_jupyter']:\n",
    "    print(f\"\\nüí° Reasoning: Jupyter environment - using num_workers=0 for stability\")\n",
    "elif env_info['is_hpc'] or env_info['is_nfs']:\n",
    "    print(f\"\\nüí° Reasoning: HPC/NFS environment - using num_workers=0 to prevent 'Device busy' errors\")\n",
    "else:\n",
    "    print(f\"\\nüí° Reasoning: Local script environment - using {env_info['recommended_num_workers']} workers for performance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080acda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smart Defaults Applied:\n",
      "   ‚öôÔ∏è  num_workers: 0\n",
      "   ‚öôÔ∏è  train_batch_size: 32\n",
      "   ‚öôÔ∏è  eval_batch_size: 32\n",
      "   ‚öôÔ∏è  accelerator: auto\n",
      "   ‚öôÔ∏è  enable_progress_bar: False\n",
      "   ‚öôÔ∏è  num_sanity_val_steps: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üöÄ Testing FlexibleTrainingConfig with Smart Defaults:\n"
     ]
    }
   ],
   "source": [
    "# Test smart defaults\n",
    "smart_defaults = get_smart_defaults()\n",
    "print(f\"\\nSmart Defaults Applied:\")\n",
    "for key, value in smart_defaults.items():\n",
    "    print(f\"   ‚öôÔ∏è  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Test configuration with and without explicit values\n",
    "print(f\"\\nüöÄ Testing FlexibleTrainingConfig with Smart Defaults:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b10fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Testing HPC/NFS Detection Logic\n",
      "\n",
      "HPC Environment Variables Check:\n",
      "  üìã Job Schedulers:\n",
      "     ‚ùå Not found SLURM_JOB_ID (SLURM): \n",
      "     ‚ùå Not found PBS_JOBID (PBS): \n",
      "     ‚úÖ Found LSB_JOBID (LSF (bsub)): 130031529\n",
      "  üéØ Queue Systems:\n",
      "     ‚ùå Not found SLURM_CLUSTER_NAME: \n",
      "     ‚ùå Not found PBS_QUEUE: \n",
      "     ‚ùå Not found LSF_QUEUE: \n",
      "  üì¶ Module Systems:\n",
      "     ‚úÖ Found MODULEPATH: /home/ai_dsx/virtualenvs/.modulefiles:/opt/site/share/modulefiles/it:/opt/site/share/modulefiles/misc:/opt/site/share/modulefiles/aiml:/opt/modulefiles/admin:/opt/modulefiles/aiml:/opt/modulefiles/dbs:/opt/modulefiles/eda:/opt/modulefiles/misc:/opt/modulefiles/office:/opt/modulefiles/prog:/opt/modulefiles/win:/opt/modulefiles/unix:/opt/modulefiles/docu:/opt/modulefiles/scm:/opt/modulefiles/sofit:/opt/modulefiles/dsard:/opt/modulefiles/it\n",
      "     ‚ùå Not found LMOD_DIR: \n",
      "\n",
      "üéØ Overall HPC Detection: ‚úÖ HPC Environment Detected\n",
      "\n",
      "NFS Filesystem Detection:\n",
      "   üìÅ Current directory filesystem info:\n",
      "      Filesystem    Type   1K-blocks      Used Available Use% Mounted on\n",
      "      mucsdv809.infineon.com:/vol/proj805/ai_dsx\n",
      "   ‚úÖ NFS filesystem detected\n",
      "\n",
      "Current Working Directory: /home/ai_dsx/jupyter-homes/goni\n",
      "Hostname: muclc1063\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#| \n",
    "# Test HPC/NFS detection logic specifically\n",
    "print(\"üî¨ Testing HPC/NFS Detection Logic\\n\")\n",
    "\n",
    "# Test HPC environment variable detection\n",
    "hpc_indicators = [\n",
    "    'SLURM_JOB_ID', 'PBS_JOBID', 'LSB_JOBID',  # Job schedulers\n",
    "    'SLURM_CLUSTER_NAME', 'PBS_QUEUE', 'LSF_QUEUE',  # Queue systems\n",
    "    'MODULEPATH', 'LMOD_DIR',  # Module systems common in HPC\n",
    "]\n",
    "\n",
    "print(\"HPC Environment Variables Check:\")\n",
    "print(\"  üìã Job Schedulers:\")\n",
    "for indicator in ['SLURM_JOB_ID', 'PBS_JOBID', 'LSB_JOBID']:\n",
    "    value = os.environ.get(indicator, 'Not found')\n",
    "    status = \"‚úÖ Found\" if indicator in os.environ else \"‚ùå Not found\"\n",
    "    scheduler = \"SLURM\" if \"SLURM\" in indicator else \"PBS\" if \"PBS\" in indicator else \"LSF (bsub)\"\n",
    "    print(f\"     {status} {indicator} ({scheduler}): {value if value != 'Not found' else ''}\")\n",
    "\n",
    "print(\"  üéØ Queue Systems:\")\n",
    "for indicator in ['SLURM_CLUSTER_NAME', 'PBS_QUEUE', 'LSF_QUEUE']:\n",
    "    value = os.environ.get(indicator, 'Not found')\n",
    "    status = \"‚úÖ Found\" if indicator in os.environ else \"‚ùå Not found\"\n",
    "    print(f\"     {status} {indicator}: {value if value != 'Not found' else ''}\")\n",
    "\n",
    "print(\"  üì¶ Module Systems:\")\n",
    "for indicator in ['MODULEPATH', 'LMOD_DIR']:\n",
    "    value = os.environ.get(indicator, 'Not found')\n",
    "    status = \"‚úÖ Found\" if indicator in os.environ else \"‚ùå Not found\"\n",
    "    print(f\"     {status} {indicator}: {value if value != 'Not found' else ''}\")\n",
    "\n",
    "# Check if any HPC indicator was found\n",
    "any_hpc_found = any(indicator in os.environ for indicator in hpc_indicators)\n",
    "print(f\"\\nüéØ Overall HPC Detection: {'‚úÖ HPC Environment Detected' if any_hpc_found else '‚ùå No HPC Environment'}\")\n",
    "\n",
    "# Test NFS detection\n",
    "print(f\"\\nNFS Filesystem Detection:\")\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['df', '-T', '.'], capture_output=True, text=True, timeout=5)\n",
    "    print(f\"   üìÅ Current directory filesystem info:\")\n",
    "    for line in result.stdout.split('\\n')[:2]:  # Show header and first result\n",
    "        if line.strip():\n",
    "            print(f\"      {line}\")\n",
    "    \n",
    "    if 'nfs' in result.stdout.lower():\n",
    "        print(f\"   ‚úÖ NFS filesystem detected\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå No NFS filesystem detected\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Could not check filesystem: {e}\")\n",
    "\n",
    "print(f\"\\nCurrent Working Directory: {os.getcwd()}\")\n",
    "print(f\"Hostname: {os.environ.get('HOSTNAME', 'Unknown')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90490648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing Environment Detection Caching\n",
      "\n",
      "1Ô∏è‚É£ First call to detect_environment() (should show HPC/NFS message if applicable):\n",
      "\n",
      "2Ô∏è‚É£ Second call to detect_environment() (should be silent, using cache):\n",
      "\n",
      "3Ô∏è‚É£ Third call via get_smart_defaults() (should also be silent):\n",
      "\n",
      "‚úÖ Cache verification:\n",
      "   All calls return identical results: True\n",
      "   HPC detected: True\n",
      "   NFS detected: True\n",
      "   Recommended num_workers: 0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test caching behavior to prevent duplicate messages\n",
    "print(\"üîÑ Testing Environment Detection Caching\\n\")\n",
    "\n",
    "# Reset cache first\n",
    "reset_environment_cache()\n",
    "print(\"1Ô∏è‚É£ First call to detect_environment() (should show HPC/NFS message if applicable):\")\n",
    "env1 = detect_environment()\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ Second call to detect_environment() (should be silent, using cache):\")\n",
    "env2 = detect_environment()\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ Third call via get_smart_defaults() (should also be silent):\")\n",
    "defaults = get_smart_defaults()\n",
    "\n",
    "# Verify all results are identical\n",
    "print(f\"\\n‚úÖ Cache verification:\")\n",
    "print(f\"   All calls return identical results: {env1 == env2}\")\n",
    "print(f\"   HPC detected: {env1.get('is_hpc', False)}\")\n",
    "print(f\"   NFS detected: {env1.get('is_nfs', False)}\")\n",
    "print(f\"   Recommended num_workers: {env1.get('recommended_num_workers', 'Unknown')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf8f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelType(str, Enum):\n",
    "    \"\"\"Available anomaly detection models in anomalib.\"\"\"\n",
    "    PADIM = \"padim\"\n",
    "    PATCHCORE = \"patchcore\"\n",
    "    CFLOW = \"cflow\"\n",
    "    FASTFLOW = \"fastflow\"\n",
    "    STFPM = \"stfpm\"\n",
    "    EFFICIENT_AD = \"efficient_ad\"\n",
    "    DRAEM = \"draem\"\n",
    "    REVERSE_DISTILLATION = \"reverse_distillation\"\n",
    "    DFKDE = \"dfkde\"\n",
    "    DFM = \"dfm\"\n",
    "    GANOMALY = \"ganomaly\"\n",
    "    CFA = \"cfa\"\n",
    "    CSFLOW = \"csflow\"\n",
    "    DSR = \"dsr\"\n",
    "    FRE = \"fre\"\n",
    "    RKDE = \"rkde\"\n",
    "    UFLOW = \"uflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd518507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BackboneType(str, Enum):\n",
    "    \"\"\"Available backbone architectures.\"\"\"\n",
    "    RESNET18 = \"resnet18\"\n",
    "    RESNET34 = \"resnet34\"\n",
    "    RESNET50 = \"resnet50\"\n",
    "    RESNET101 = \"resnet101\"\n",
    "    WIDE_RESNET50 = \"wide_resnet50_2\"\n",
    "    EFFICIENTNET_B0 = \"efficientnet_b0\"\n",
    "    EFFICIENTNET_B1 = \"efficientnet_b1\"\n",
    "    EFFICIENTNET_B2 = \"efficientnet_b2\"\n",
    "    EFFICIENTNET_B3 = \"efficientnet_b3\"\n",
    "    EFFICIENTNET_B4 = \"efficientnet_b4\"\n",
    "    EFFICIENTNET_B5 = \"efficientnet_b5\"\n",
    "    EFFICIENTNET_B6 = \"efficientnet_b6\"\n",
    "    EFFICIENTNET_B7 = \"efficientnet_b7\"\n",
    "    VIT_B_16 = \"vit_b_16\"\n",
    "    VIT_L_16 = \"vit_l_16\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a60289fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ThresholdMethod(str, Enum):\n",
    "    \"\"\"Threshold computation methods.\"\"\"\n",
    "    ADAPTIVE = \"adaptive\"\n",
    "    MANUAL = \"manual\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2edbfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class FlexibleTrainingConfig:\n",
    "    \"\"\"Comprehensive configuration for flexible anomaly detection training.\"\"\"\n",
    "    \n",
    "    # Data configuration\n",
    "    data_root: Union[str, Path] = field(default_factory=lambda: Path.cwd())\n",
    "    normal_dir: str = \"normal\"\n",
    "    abnormal_dir: str = \"abnormal\"\n",
    "    class_name: str = \"default_class\"\n",
    "    \n",
    "    # Model configuration  \n",
    "    model_name: Union[str, ModelType] = ModelType.PADIM\n",
    "    backbone: Union[str, BackboneType] = BackboneType.RESNET18\n",
    "    layers: List[str] = field(default_factory=lambda: [\"layer1\", \"layer2\", \"layer3\"])\n",
    "    n_features: int = 100\n",
    "    model_file_name: str = \"model.pth\"\n",
    "\n",
    "\n",
    "\n",
    "    # Image preprocessing - CORRECTED for anomalib v1.2.0 with anomalib defaults\n",
    "    image_size: Tuple[int, int] = (256, 256)  # Anomalib standard default (not 224)\n",
    "    normalization_method: NormalizationMethod = NormalizationMethod.MIN_MAX  # Only MIN_MAX or NONE available\n",
    "    center_crop: Optional[Tuple[int, int]] = None\n",
    "    \n",
    "    # Training configuration - Will be auto-adjusted based on environment\n",
    "    max_epochs: int = 100\n",
    "    train_batch_size: Optional[int] = None  # Auto-detected if None\n",
    "    eval_batch_size: Optional[int] = None   # Auto-detected if None  \n",
    "    num_workers: Optional[int] = None       # Auto-detected if None\n",
    "    accelerator: str = \"auto\"\n",
    "    devices: Union[int, List[int], str] = \"auto\"\n",
    "    \n",
    "    # Engine configuration - Auto-adjusted for environment\n",
    "    enable_progress_bar: Optional[bool] = None      # Auto-detected if None\n",
    "    num_sanity_val_steps: Optional[int] = None      # Auto-detected if None\n",
    "    \n",
    "    # Threshold configuration\n",
    "    threshold_method: ThresholdMethod = ThresholdMethod.ADAPTIVE\n",
    "    manual_threshold: Optional[float] = None\n",
    "    \n",
    "    # Callbacks and monitoring\n",
    "    early_stopping: bool = True\n",
    "    early_stopping_patience: int = 10\n",
    "    early_stopping_metric: str = \"image_AUROC\"\n",
    "    early_stopping_mode: str = \"max\"\n",
    "    \n",
    "    # Model saving\n",
    "    save_path: Union[str, Path] = field(default_factory=lambda: Path.cwd() / \"models\")\n",
    "    model_name_suffix: str = \"\"\n",
    "    save_top_k: int = 1\n",
    "    \n",
    "    # Export formats\n",
    "    export_formats: List[ExportType] = field(default_factory=lambda: [ExportType.TORCH])\n",
    "    \n",
    "    # Logging - Using anomalib defaults\n",
    "    log_level: str = \"INFO\"  # Anomalib default\n",
    "    enable_tensorboard: bool = False  # Anomalib default (not True)\n",
    "    enable_csv_logger: bool = False   # Anomalib default (not True)\n",
    "    \n",
    "    # Advanced options\n",
    "    seed: Optional[int] = None\n",
    "    deterministic: bool = False\n",
    "    benchmark: bool = True\n",
    "    \n",
    "    # Tiling (for large images) - Using anomalib defaults\n",
    "    enable_tiling: bool = False\n",
    "    tile_size: Optional[Tuple[int, int]] = None  # Anomalib default (disabled)\n",
    "    stride: Optional[Tuple[int, int]] = None     # Anomalib default (disabled)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Post-initialization validation, type conversion, and intelligent defaults.\"\"\"\n",
    "        # Convert paths to Path objects\n",
    "        self.data_root = Path(self.data_root)\n",
    "        self.save_path = Path(self.save_path)\n",
    "        \n",
    "        # Create save directory if it doesn't exist\n",
    "        self.save_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Apply intelligent environment-based defaults FIRST\n",
    "        smart_defaults = get_smart_defaults()\n",
    "        \n",
    "        if self.num_workers is None:\n",
    "            self.num_workers = smart_defaults['num_workers']\n",
    "            \n",
    "        if self.train_batch_size is None:\n",
    "            self.train_batch_size = smart_defaults['train_batch_size']\n",
    "            \n",
    "        if self.eval_batch_size is None:\n",
    "            self.eval_batch_size = smart_defaults['eval_batch_size']\n",
    "            \n",
    "        if self.enable_progress_bar is None:\n",
    "            self.enable_progress_bar = smart_defaults['enable_progress_bar']\n",
    "            \n",
    "        if self.num_sanity_val_steps is None:\n",
    "            self.num_sanity_val_steps = smart_defaults['num_sanity_val_steps']\n",
    "        \n",
    "        # Auto-adjust accelerator for problematic environments\n",
    "        env = detect_environment()\n",
    "        if env['is_jupyter'] and env['platform'] == 'Windows' and self.accelerator == 'auto':\n",
    "            self.accelerator = 'cpu'  # Force CPU on Windows Jupyter to avoid device issues\n",
    "        \n",
    "        # Log the intelligent adjustments\n",
    "        if env['is_jupyter']:\n",
    "            print(f\"ü§ñ Jupyter environment detected - Applied smart defaults:\")\n",
    "            print(f\"   ‚Ä¢ num_workers: {self.num_workers} (multiprocessing-safe)\")\n",
    "            print(f\"   ‚Ä¢ batch_size: {self.train_batch_size} (memory-aware)\")\n",
    "            print(f\"   ‚Ä¢ progress_bar: {self.enable_progress_bar} (clean output)\")\n",
    "            print(f\"   ‚Ä¢ accelerator: {self.accelerator}\")\n",
    "        \n",
    "        # Validate and convert model_name if it's a string\n",
    "        if isinstance(self.model_name, str):\n",
    "            try:\n",
    "                self.model_name = ModelType(self.model_name.lower())\n",
    "            except ValueError:\n",
    "                valid_models = [m.value for m in ModelType]\n",
    "                raise ValueError(f\"Invalid model name: {self.model_name}. Valid options are: {valid_models}\")\n",
    "        \n",
    "        # Validate and convert backbone if it's a string \n",
    "        if isinstance(self.backbone, str):\n",
    "            try:\n",
    "                self.backbone = BackboneType(self.backbone.lower())\n",
    "            except ValueError:\n",
    "                valid_backbones = [b.value for b in BackboneType]\n",
    "                raise ValueError(f\"Invalid backbone name: {self.backbone}. Valid options are: {valid_backbones}\")\n",
    "        \n",
    "        # Validate threshold configuration\n",
    "        if self.threshold_method == ThresholdMethod.MANUAL and self.manual_threshold is None:\n",
    "            raise ValueError(\"Manual threshold value must be provided when using manual threshold method\")\n",
    "        \n",
    "        # Validate image size\n",
    "        if not isinstance(self.image_size, (tuple, list)) or len(self.image_size) != 2:\n",
    "            raise ValueError(\"Image size must be a tuple/list of 2 integers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f71a5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(FlexibleTrainingConfig)\n",
    "def to_dict(self) -> Dict[str, Any]:\n",
    "    \"\"\"Convert config to dictionary.\"\"\"\n",
    "    return asdict(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f85dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(FlexibleTrainingConfig)\n",
    "def save_config(self, path: Union[str, Path]) -> None:\n",
    "    \"\"\"Save configuration to YAML file.\"\"\"\n",
    "    config_dict = self.to_dict()\n",
    "    config_dict['data_root'] = str(config_dict['data_root'])\n",
    "    config_dict['save_path'] = str(config_dict['save_path'])\n",
    "        \n",
    "    with open(path, 'w') as f:\n",
    "        yaml.dump(config_dict, f, default_flow_style=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b8ba8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(FlexibleTrainingConfig, classmethod)    \n",
    "def from_dict(cls, config_dict: Dict[str, Any]) -> 'FlexibleTrainingConfig':\n",
    "    \"\"\"Create config from dictionary.\"\"\"\n",
    "    return cls(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f488e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(FlexibleTrainingConfig, classmethod)\n",
    "def from_yaml(cls, path: Union[str, Path]) -> 'FlexibleTrainingConfig':\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    return cls.from_dict(config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f85cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extract_model_inference_info(\n",
    "    model # Model could be trained or exported model\n",
    "    ) -> Dict[str, Any]:\n",
    "    \"\"\"Extract threshold and pixel statistics from trained model for inference.\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'image_threshold') or not hasattr(model, 'pixel_threshold'):\n",
    "        raise AttributeError(\"Model missing required threshold attributes. Ensure model is properly trained.\")\n",
    "    \n",
    "    if not hasattr(model, 'normalization_metrics'):\n",
    "        raise RuntimeError(\"Model normalization metrics not available. Model may not be fitted yet.\")\n",
    "    \n",
    "    try:\n",
    "        inference_info = {\n",
    "            'image_threshold': float(model.image_threshold.value.item()) if hasattr(model.image_threshold.value, 'item') else float(model.image_threshold.value),\n",
    "            'pixel_threshold': float(model.pixel_threshold.value.item()) if hasattr(model.pixel_threshold.value, 'item') else float(model.pixel_threshold.value),\n",
    "            'pred_score_min': float(model.normalization_metrics.pred_scores.min.item()) if hasattr(model.normalization_metrics.pred_scores.min, 'item') else float(model.normalization_metrics.pred_scores.min),\n",
    "            'pred_score_max': float(model.normalization_metrics.pred_scores.max.item()) if hasattr(model.normalization_metrics.pred_scores.max, 'item') else float(model.normalization_metrics.pred_scores.max),\n",
    "            'anomaly_map_min': float(model.normalization_metrics.anomaly_maps.min.item()) if hasattr(model.normalization_metrics.anomaly_maps.min, 'item') else float(model.normalization_metrics.anomaly_maps.min),\n",
    "            'anomaly_map_max': float(model.normalization_metrics.anomaly_maps.max.item()) if hasattr(model.normalization_metrics.anomaly_maps.max, 'item') else float(model.normalization_metrics.anomaly_maps.max)\n",
    "        }\n",
    "    except (AttributeError, TypeError) as e:\n",
    "        raise RuntimeError(f\"Failed to extract inference info from model: {e}\")\n",
    "    \n",
    "    return inference_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb01dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Jupyter environment detected - Applied smart defaults:\n",
      "   ‚Ä¢ num_workers: 0 (multiprocessing-safe)\n",
      "   ‚Ä¢ batch_size: 32 (memory-aware)\n",
      "   ‚Ä¢ progress_bar: False (clean output)\n",
      "   ‚Ä¢ accelerator: auto\n"
     ]
    }
   ],
   "source": [
    "config = FlexibleTrainingConfig(\n",
    "    data_root=root,\n",
    "    normal_dir=\"g_imgs\",\n",
    "    abnormal_dir=\"b_imgs\",\n",
    "    class_name=\"test_manual\",\n",
    "    model_name=\"padim\",\n",
    "    backbone=\"resnet18\",\n",
    "    max_epochs=1,\n",
    ")\n",
    "folder_datamodule = Folder(\n",
    "    name=config.class_name,\n",
    "    root=config.data_root,\n",
    "    normal_dir=config.normal_dir,\n",
    "    abnormal_dir=config.abnormal_dir,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    train_batch_size=config.train_batch_size,\n",
    "    eval_batch_size=config.eval_batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    image_size=config.image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68c21575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#23) [Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/bad'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/test_hyperparameter_results'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/good'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/test_hyperparameter_models'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_img_tmp_part_aligned'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/g_imgs'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/g_imgs_all'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/b_imgs'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/data'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/small_images'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_images'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/templates'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_img_tmp_part'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_img_tmp_part_trn'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_img_tmp_part_tst'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/sml_img'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/AD_development'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/tst_func'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/big_img'),Path('/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test/heat_maps')...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path(r'/home/ai_dsx.work/data/projects/goni/qmr_ad_tool_test')\n",
    "root.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7502e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['ANOMALIB_MODEL_CACHE'] = Path(r'/home/ai_dsx.work/data/projects/goni/hf_cache').as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "421690f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/resnet18.a1_in1k/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f61ce22de10>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 1205d919-ccfd-4456-883f-5ce93abbdc0b)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model=  \u001b[43mPadim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/lightning_model.py:49\u001b[39m, in \u001b[36mPadim.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     42\u001b[39m     backbone: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mresnet18\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     n_features: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m.model: PadimModel = \u001b[43mPadimModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.embeddings: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/torch_model.py:79\u001b[39m, in \u001b[36mPadimModel.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.backbone = backbone\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.layers = layers\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mTimmFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.eval()\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_original = \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_extractor.out_dims)\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features = n_features \u001b[38;5;129;01mor\u001b[39;00m _N_FEATURES_DEFAULTS.get(\u001b[38;5;28mself\u001b[39m.backbone)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/components/feature_extractors/timm.py:69\u001b[39m, in \u001b[36mTimmFeatureExtractor.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, requires_grad)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.idx = \u001b[38;5;28mself\u001b[39m._map_layer_to_idx()\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.requires_grad = requires_grad\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mtimm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexportable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.out_dims = \u001b[38;5;28mself\u001b[39m.feature_extractor.feature_info.channels()\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._features = {layer: torch.empty(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_factory.py:138\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m create_fn = model_entrypoint(model_name)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable=scriptable, exportable=exportable, no_jit=no_jit):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     model = \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[32m    147\u001b[39m     load_checkpoint(model, checkpoint_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:1444\u001b[39m, in \u001b[36mresnet18\u001b[39m\u001b[34m(pretrained, **kwargs)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Constructs a ResNet-18 model.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1443\u001b[39m model_args = \u001b[38;5;28mdict\u001b[39m(block=BasicBlock, layers=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresnet18\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:740\u001b[39m, in \u001b[36m_create_resnet\u001b[39m\u001b[34m(variant, pretrained, **kwargs)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_resnet\u001b[39m(variant: \u001b[38;5;28mstr\u001b[39m, pretrained: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> ResNet:\n\u001b[32m    730\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a ResNet model.\u001b[39;00m\n\u001b[32m    731\u001b[39m \n\u001b[32m    732\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    738\u001b[39m \u001b[33;03m        ResNet model instance.\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:457\u001b[39m, in \u001b[36mbuild_model_with_cfg\u001b[39m\u001b[34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m num_classes_pretrained = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, kwargs.get(\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m))\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43min_chans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:226\u001b[39m, in \u001b[36mload_pretrained\u001b[39m\u001b[34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict, cache_dir)\u001b[39m\n\u001b[32m    224\u001b[39m             state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         state_dict = \u001b[43mload_state_dict_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m load_from == \u001b[33m'\u001b[39m\u001b[33mlocal-dir\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    228\u001b[39m     _logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading pretrained weights from local directory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_loc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_hub.py:229\u001b[39m, in \u001b[36mload_state_dict_from_hf\u001b[39m\u001b[34m(model_id, filename, weights_only, cache_dir)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m safe_filename \u001b[38;5;129;01min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         cached_safe_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         _logger.info(\n\u001b[32m    236\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Safe alternative available for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(as \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m). Loading weights using safetensors.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    238\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m safetensors.torch.load_file(cached_safe_file, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1073\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1550\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1551\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1460\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1474\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:308\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:95\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model=  Padim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c806e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de85da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "folder_datamodule.transform: None\n",
      "None\n",
      "====================================================================================================\n",
      " Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/resnet18.a1_in1k/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f61ce544410>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 90272bdd-9e73-4f38-b75a-8ca7ec9be579)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Starting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m start_time = datetime.now()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m engine.fit(model=\u001b[43mPadim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, datamodule=folder_datamodule)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/lightning_model.py:49\u001b[39m, in \u001b[36mPadim.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     42\u001b[39m     backbone: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mresnet18\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     n_features: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m.model: PadimModel = \u001b[43mPadimModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.embeddings: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/torch_model.py:79\u001b[39m, in \u001b[36mPadimModel.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.backbone = backbone\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.layers = layers\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mTimmFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.eval()\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_original = \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_extractor.out_dims)\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features = n_features \u001b[38;5;129;01mor\u001b[39;00m _N_FEATURES_DEFAULTS.get(\u001b[38;5;28mself\u001b[39m.backbone)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/components/feature_extractors/timm.py:69\u001b[39m, in \u001b[36mTimmFeatureExtractor.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, requires_grad)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.idx = \u001b[38;5;28mself\u001b[39m._map_layer_to_idx()\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.requires_grad = requires_grad\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mtimm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexportable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.out_dims = \u001b[38;5;28mself\u001b[39m.feature_extractor.feature_info.channels()\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._features = {layer: torch.empty(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_factory.py:138\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m create_fn = model_entrypoint(model_name)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable=scriptable, exportable=exportable, no_jit=no_jit):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     model = \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[32m    147\u001b[39m     load_checkpoint(model, checkpoint_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:1444\u001b[39m, in \u001b[36mresnet18\u001b[39m\u001b[34m(pretrained, **kwargs)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Constructs a ResNet-18 model.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1443\u001b[39m model_args = \u001b[38;5;28mdict\u001b[39m(block=BasicBlock, layers=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresnet18\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:740\u001b[39m, in \u001b[36m_create_resnet\u001b[39m\u001b[34m(variant, pretrained, **kwargs)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_resnet\u001b[39m(variant: \u001b[38;5;28mstr\u001b[39m, pretrained: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> ResNet:\n\u001b[32m    730\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a ResNet model.\u001b[39;00m\n\u001b[32m    731\u001b[39m \n\u001b[32m    732\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    738\u001b[39m \u001b[33;03m        ResNet model instance.\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:457\u001b[39m, in \u001b[36mbuild_model_with_cfg\u001b[39m\u001b[34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m num_classes_pretrained = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, kwargs.get(\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m))\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43min_chans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:226\u001b[39m, in \u001b[36mload_pretrained\u001b[39m\u001b[34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict, cache_dir)\u001b[39m\n\u001b[32m    224\u001b[39m             state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         state_dict = \u001b[43mload_state_dict_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m load_from == \u001b[33m'\u001b[39m\u001b[33mlocal-dir\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    228\u001b[39m     _logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading pretrained weights from local directory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_loc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_hub.py:229\u001b[39m, in \u001b[36mload_state_dict_from_hf\u001b[39m\u001b[34m(model_id, filename, weights_only, cache_dir)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m safe_filename \u001b[38;5;129;01min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         cached_safe_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         _logger.info(\n\u001b[32m    236\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Safe alternative available for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(as \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m). Loading weights using safetensors.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    238\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m safetensors.torch.load_file(cached_safe_file, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1073\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1550\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1551\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1460\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1474\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:308\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:95\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from anomalib.models import Padim\n",
    "folder_datamodule = Folder(\n",
    "    name=config.class_name,\n",
    "    root=config.data_root,\n",
    "    normal_dir=config.normal_dir,\n",
    "    abnormal_dir=config.abnormal_dir,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    train_batch_size=config.train_batch_size,\n",
    "    eval_batch_size=config.eval_batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    image_size=config.image_size,\n",
    ")\n",
    "        \n",
    "folder_datamodule.setup()\n",
    "print(f'{\"=\"*100}')\n",
    "print(f'folder_datamodule.transform: {folder_datamodule.transform}')\n",
    "print(folder_datamodule.transform)\n",
    "print(f'{\"=\"*100}')\n",
    "        \n",
    "callbacks = []\n",
    "threshold = None\n",
    "engine = Engine(\n",
    "    accelerator=config.accelerator,\n",
    "    devices=config.devices,\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=config.max_epochs,\n",
    "    deterministic=config.deterministic,\n",
    "    threshold=threshold,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "        \n",
    "# Start training\n",
    "print(\" Starting training...\")\n",
    "start_time = datetime.now()\n",
    "        \n",
    "engine.fit(model=Padim(), datamodule=folder_datamodule)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6685eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_anomaly_model(\n",
    "    config: Union[FlexibleTrainingConfig, Dict[str, Any], str, Path]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train an anomaly detection model with maximum flexibility and production-ready error handling.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing training results, model paths, and metrics.\n",
    "    \"\"\"\n",
    "    # Parse configuration\n",
    "    if isinstance(config, (str, Path)):\n",
    "        config = FlexibleTrainingConfig.from_yaml(config)\n",
    "    elif isinstance(config, dict):\n",
    "        config = FlexibleTrainingConfig.from_dict(config)\n",
    "    elif not isinstance(config, FlexibleTrainingConfig):\n",
    "        raise TypeError(f\"Config must be FlexibleTrainingConfig, dict, or path. Got {type(config)}\")\n",
    "    \n",
    "    # Validate data root exists\n",
    "    if not config.data_root.exists():\n",
    "        raise FileNotFoundError(f\"Data root path does not exist: {config.data_root}\")\n",
    "    \n",
    "    try:\n",
    "        # Helper function to safely get enum value\n",
    "        def get_value(obj):\n",
    "            return obj.value if hasattr(obj, 'value') else str(obj)\n",
    "        \n",
    "        print(f\" Starting training with {get_value(config.model_name)} model\")\n",
    "        print(f\" Normalization: {get_value(config.normalization_method)}\")\n",
    "        print(f\" Image size: {config.image_size}\")\n",
    "        print(f\" Threshold method: {get_value(config.threshold_method)}\")\n",
    "        \n",
    "        # Create data module\n",
    "        folder_datamodule = Folder(\n",
    "            name=config.class_name,\n",
    "            root=config.data_root,\n",
    "            normal_dir=config.normal_dir,\n",
    "            abnormal_dir=config.abnormal_dir,\n",
    "            task=TaskType.CLASSIFICATION,\n",
    "            train_batch_size=config.train_batch_size,\n",
    "            eval_batch_size=config.eval_batch_size,\n",
    "            num_workers=config.num_workers,\n",
    "            image_size=config.image_size,\n",
    "        )\n",
    "        \n",
    "        folder_datamodule.setup()\n",
    "        print(f'{\"=\"*100}')\n",
    "        print(f'folder_datamodule.transform: {folder_datamodule.transform}')\n",
    "        print(folder_datamodule.transform)\n",
    "        print(f'{\"=\"*100}')\n",
    "        \n",
    "        # Get model class and create model\n",
    "        model_mapping = {\n",
    "            ModelType.PADIM: Padim,\n",
    "            ModelType.PATCHCORE: Patchcore,\n",
    "            ModelType.CFLOW: Cflow,\n",
    "            ModelType.FASTFLOW: Fastflow,\n",
    "            ModelType.STFPM: Stfpm,\n",
    "            ModelType.EFFICIENT_AD: EfficientAd,\n",
    "            ModelType.DRAEM: Draem,\n",
    "            ModelType.REVERSE_DISTILLATION: ReverseDistillation,\n",
    "            ModelType.DFKDE: Dfkde,\n",
    "            ModelType.DFM: Dfm,\n",
    "            ModelType.GANOMALY: Ganomaly,\n",
    "            ModelType.CFA: Cfa,\n",
    "            ModelType.CSFLOW: Csflow,\n",
    "            ModelType.DSR: Dsr,\n",
    "            ModelType.FRE: Fre,\n",
    "            ModelType.RKDE: Rkde,\n",
    "            ModelType.UFLOW: Uflow,\n",
    "        }\n",
    "        \n",
    "        model_class = model_mapping[config.model_name]\n",
    "        \n",
    "        # Create model with corrected parameters\n",
    "        model_config = {\n",
    "            'backbone': get_value(config.backbone)\n",
    "        }\n",
    "        \n",
    "        # Add model-specific configurations\n",
    "        if config.model_name in [ModelType.PADIM, ModelType.STFPM]:\n",
    "            model_config['layers'] = config.layers\n",
    "\n",
    "        if config.model_name in [ModelType.PADIM]:\n",
    "            model_config['n_features'] = config.n_features\n",
    "        print(f'{\"=\"*100}')\n",
    "        print(f'model_config: {model_config}')\n",
    "\n",
    "        print(f'{\"=\"*100}')\n",
    "        \n",
    "        model = model_class(**model_config)\n",
    "        \n",
    "        # Set up callbacks\n",
    "        callbacks = []\n",
    "        \n",
    "        # Model checkpoint\n",
    "        checkpoint_dir = config.save_path / \"checkpoints\" / config.class_name\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=checkpoint_dir,\n",
    "            filename=f\"{get_value(config.model_name)}_{get_value(config.backbone)}_{{epoch:02d}}_{{image_AUROC:.4f}}\",\n",
    "            monitor=config.early_stopping_metric,\n",
    "            mode=config.early_stopping_mode,\n",
    "            save_top_k=config.save_top_k,\n",
    "            save_last=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        callbacks.append(checkpoint_callback)\n",
    "        \n",
    "        # Early stopping\n",
    "        if config.early_stopping:\n",
    "            early_stop_callback = EarlyStopping(\n",
    "                monitor=config.early_stopping_metric,\n",
    "                patience=config.early_stopping_patience,\n",
    "                mode=config.early_stopping_mode,\n",
    "                verbose=True\n",
    "            )\n",
    "            callbacks.append(early_stop_callback)\n",
    "        \n",
    "        # Add thresholding callback for specific models\n",
    "        if config.model_name in [ModelType.PADIM, ModelType.PATCHCORE, ModelType.STFPM, \n",
    "                                ModelType.CFLOW, ModelType.FASTFLOW]:\n",
    "            from anomalib.metrics import ManualThreshold, F1AdaptiveThreshold\n",
    "            threshold = F1AdaptiveThreshold() if config.threshold_method == ThresholdMethod.ADAPTIVE else ManualThreshold(config.manual_threshold)\n",
    "            print(f\" Added ThresholdCallback for {get_value(config.model_name)}\")\n",
    "        else:\n",
    "            threshold = None\n",
    "        \n",
    "        # Add tiling callback if enabled\n",
    "        if config.enable_tiling:\n",
    "            from anomalib.callbacks import TilingConfigurationCallback\n",
    "            # Use default values if None (anomalib will handle this)\n",
    "            tile_size = config.tile_size if config.tile_size is not None else (256, 256)\n",
    "            stride = config.stride if config.stride is not None else (128, 128)\n",
    "            tiling_callback = TilingConfigurationCallback(\n",
    "                tile_size=tile_size,\n",
    "                stride=stride\n",
    "            )\n",
    "            callbacks.append(tiling_callback)\n",
    "            print(f\" Added TilingCallback with tile_size={tile_size}, stride={stride}\")\n",
    "        \n",
    "        # Create engine\n",
    "        engine = Engine(\n",
    "            accelerator=config.accelerator,\n",
    "            devices=config.devices,\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config.max_epochs,\n",
    "            deterministic=config.deterministic,\n",
    "            threshold=threshold,\n",
    "            task=TaskType.CLASSIFICATION,\n",
    "        )\n",
    "        \n",
    "        # Start training\n",
    "        print(\" Starting training...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        engine.fit(model=model, datamodule=folder_datamodule)\n",
    "        \n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        training_duration = end_time - start_time\n",
    "        \n",
    "        print(f\" Training completed in {training_duration}\")\n",
    "        \n",
    "        # Get results\n",
    "        best_model_path = checkpoint_callback.best_model_path\n",
    "        \n",
    "        # Test the model\n",
    "        #test_results = engine.test(\n",
    "            #model=model,\n",
    "            #datamodule=folder_datamodule,\n",
    "        #)\n",
    "        \n",
    "        # Export model if requested\n",
    "        export_paths = {}\n",
    "        if config.export_formats:\n",
    "            export_dir = config.save_path / \"exports\" / config.class_name\n",
    "            export_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for export_format in config.export_formats:\n",
    "                try:\n",
    "                    export_path = engine.export(\n",
    "                        model=model,\n",
    "                        export_type=export_format,\n",
    "                        export_root=export_dir\n",
    "                    )\n",
    "                    export_paths[get_value(export_format)] = str(export_path)\n",
    "                    print(f\" Exported {get_value(export_format)}: {export_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\" Export failed for {get_value(export_format)}: {str(e)}\")\n",
    "        \n",
    "        # Extract model threshold and pixel statistics for inference\n",
    "        model_inference_info = _extract_model_inference_info(model)\n",
    "        \n",
    "        # Compile results\n",
    "        results = {\n",
    "            'success': True,\n",
    "            'config': config.to_dict(),\n",
    "            'image_threshold': model_inference_info.get('image_threshold'),\n",
    "            'pixel_threshold': model_inference_info.get('pixel_threshold'),\n",
    "            'pred_score_min': model_inference_info.get('pred_score_min'),\n",
    "            'pred_score_max': model_inference_info.get('pred_score_max'),\n",
    "            'anomaly_map_min': model_inference_info.get('anomaly_map_min'),\n",
    "            'anomaly_map_max': model_inference_info.get('anomaly_map_max'),\n",
    "            'training_duration': str(training_duration),\n",
    "            'best_model_path': str(best_model_path) if best_model_path else None,\n",
    "            'export_paths': export_paths,\n",
    "            #'test_results': test_results[0] if test_results else None,\n",
    "            'anomalib_version': anomalib.__version__,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        print(\"üéâ Training completed successfully!\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {str(e)}\")\n",
    "        error_results = {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'error_type': type(e).__name__,\n",
    "            'config': config.to_dict() if config else None,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        return error_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc2e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97673b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Jupyter environment detected - Applied smart defaults:\n",
      "   ‚Ä¢ num_workers: 0 (multiprocessing-safe)\n",
      "   ‚Ä¢ batch_size: 32 (memory-aware)\n",
      "   ‚Ä¢ progress_bar: False (clean output)\n",
      "   ‚Ä¢ accelerator: auto\n",
      " Starting training with padim model\n",
      " Normalization: min_max\n",
      " Image size: (256, 256)\n",
      " Threshold method: adaptive\n",
      "====================================================================================================\n",
      "folder_datamodule.transform: None\n",
      "None\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "model_config: {'backbone': 'resnet18', 'layers': ['layer1', 'layer2', 'layer3'], 'n_features': 100}\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/resnet18.a1_in1k/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f61e0865a10>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 70d80025-28d4-43db-8b2d-2c55e44c73e2)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/resnet18.a1_in1k/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f61e08bef50>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 6870e351-7c8a-45eb-aea8-ebe2a3411e56)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/resnet18.a1_in1k/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f61e08c0f10>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 0ff29f82-aa9a-4a83-8673-21d379f406e2)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n",
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m root = Path(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m/home/ai_dsx.work/data/projects/AD_tool_test/images\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m config_ = FlexibleTrainingConfig(\n\u001b[32m      4\u001b[39m     data_root=root,\n\u001b[32m      5\u001b[39m     normal_dir=\u001b[33m\"\u001b[39m\u001b[33mgood\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     class_name=\u001b[33m\"\u001b[39m\u001b[33mtest_manual\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m res= \u001b[43mtrain_anomaly_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mtrain_anomaly_model\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m model = \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Set up callbacks\u001b[39;00m\n\u001b[32m     95\u001b[39m callbacks = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/lightning_model.py:49\u001b[39m, in \u001b[36mPadim.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     42\u001b[39m     backbone: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mresnet18\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     n_features: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m.model: PadimModel = \u001b[43mPadimModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.embeddings: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/image/padim/torch_model.py:79\u001b[39m, in \u001b[36mPadimModel.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, n_features)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.backbone = backbone\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.layers = layers\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mTimmFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.eval()\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_original = \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_extractor.out_dims)\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features = n_features \u001b[38;5;129;01mor\u001b[39;00m _N_FEATURES_DEFAULTS.get(\u001b[38;5;28mself\u001b[39m.backbone)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/anomalib/models/components/feature_extractors/timm.py:69\u001b[39m, in \u001b[36mTimmFeatureExtractor.__init__\u001b[39m\u001b[34m(self, backbone, layers, pre_trained, requires_grad)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.idx = \u001b[38;5;28mself\u001b[39m._map_layer_to_idx()\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.requires_grad = requires_grad\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_extractor = \u001b[43mtimm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexportable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.out_dims = \u001b[38;5;28mself\u001b[39m.feature_extractor.feature_info.channels()\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._features = {layer: torch.empty(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_factory.py:138\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m create_fn = model_entrypoint(model_name)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable=scriptable, exportable=exportable, no_jit=no_jit):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     model = \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[32m    147\u001b[39m     load_checkpoint(model, checkpoint_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:1444\u001b[39m, in \u001b[36mresnet18\u001b[39m\u001b[34m(pretrained, **kwargs)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Constructs a ResNet-18 model.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1443\u001b[39m model_args = \u001b[38;5;28mdict\u001b[39m(block=BasicBlock, layers=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresnet18\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/resnet.py:740\u001b[39m, in \u001b[36m_create_resnet\u001b[39m\u001b[34m(variant, pretrained, **kwargs)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_resnet\u001b[39m(variant: \u001b[38;5;28mstr\u001b[39m, pretrained: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> ResNet:\n\u001b[32m    730\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a ResNet model.\u001b[39;00m\n\u001b[32m    731\u001b[39m \n\u001b[32m    732\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    738\u001b[39m \u001b[33;03m        ResNet model instance.\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:457\u001b[39m, in \u001b[36mbuild_model_with_cfg\u001b[39m\u001b[34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m num_classes_pretrained = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, kwargs.get(\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m))\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43min_chans\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_builder.py:226\u001b[39m, in \u001b[36mload_pretrained\u001b[39m\u001b[34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict, cache_dir)\u001b[39m\n\u001b[32m    224\u001b[39m             state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         state_dict = \u001b[43mload_state_dict_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m load_from == \u001b[33m'\u001b[39m\u001b[33mlocal-dir\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    228\u001b[39m     _logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading pretrained weights from local directory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_loc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/timm/models/_hub.py:229\u001b[39m, in \u001b[36mload_state_dict_from_hf\u001b[39m\u001b[34m(model_id, filename, weights_only, cache_dir)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m safe_filename \u001b[38;5;129;01min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         cached_safe_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         _logger.info(\n\u001b[32m    236\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Safe alternative available for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(as \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m). Loading weights using safetensors.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    238\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m safetensors.torch.load_file(cached_safe_file, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1073\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1550\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1551\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1460\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1474\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:308\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:95\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/ai_dsx.work/data/projects/be-vision-ad-tools/.venv/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "root = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/images')\n",
    "config_ = FlexibleTrainingConfig(\n",
    "    data_root=root,\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"bad\",\n",
    "    model_name=\"padim\",\n",
    "    backbone=\"resnet18\",\n",
    "    max_epochs=1,\n",
    "    class_name=\"test_manual\"\n",
    ")\n",
    "res= train_anomaly_model(config_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/images\")\n",
    "val_images = get_images_(Path(DATA_ROOT, 'bad'))\n",
    "test_images = get_images_(Path(DATA_ROOT, 'bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51de4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'model_path': str(model_path),\n",
    "    'validation_results': [],\n",
    "    'test_results': [],\n",
    "    'posters': [],\n",
    "    'statistics': {\n",
    "        'total_images': len(val_images) + len(test_images),\n",
    "        'validation_count': len(val_images),\n",
    "        'test_count': len(test_images),\n",
    "        'anomaly_count': 0,\n",
    "        'normal_count': 0\n",
    "    }\n",
    "}\n",
    "results['validation_results'], results = run_inference_batch(val_images, 'validation', model_path,save_heatmap=False,show_heatmap=False, results=results)\n",
    "results['test_results'], results = run_inference_batch(test_images, 'test', model_path,save_heatmap=False,show_heatmap=False, results=results)\n",
    "total_results = results['validation_results'] + results['test_results']\n",
    "print(f\"‚úÖ Inference completed: {len(total_results)} successful predictions\")\n",
    "print(f\"   Normal: {results['statistics']['normal_count']}\")\n",
    "print(f\"   Anomaly: {results['statistics']['anomaly_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = results['validation_results'] + results['test_results']\n",
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61869a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CV_TOOLS = Path(r'/home/ai_dsx.work/data/projects/cv_tools')\n",
    "sys.path.append(str(CV_TOOLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_tools.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "poster_title='layer 1 thrsh 10'\n",
    "image_size_in_poster=(256, 256)\n",
    "poster_rows=1\n",
    "poster_cols=2\n",
    "include_heatmap_poster=True\n",
    "include_anomaly_poster=False\n",
    "include_image_poster=False\n",
    "model_path=Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/models/exports/tutorial_basic/weights/torch/model.pt\")\n",
    "validation_images=Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/images/bad\")\n",
    "test_images=None\n",
    "output_folder=Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/poster_test\")\n",
    "create_inference_poster_(\n",
    "    model_path=model_path,\n",
    "    validation_images=validation_images,\n",
    "    test_images=test_images,\n",
    "    output_folder=output_folder,\n",
    "    poster_rows=poster_rows,\n",
    "    poster_cols=poster_cols,    \n",
    "    include_heatmap_poster=include_heatmap_poster,\n",
    "    include_anomaly_poster=include_anomaly_poster,\n",
    "    include_image_poster=include_image_poster,\n",
    "    image_size_in_poster=image_size_in_poster,\n",
    "    poster_title=poster_title,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb1c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _extract_model_inference_info(model) -> Dict[str, Any]:\n",
    "    \"\"\"Extract threshold and pixel statistics from trained model for inference.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained anomaly detection model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing inference parameters including thresholds and normalization metrics\n",
    "        \n",
    "    Raises:\n",
    "        AttributeError: If model doesn't have required threshold or normalization attributes\n",
    "        RuntimeError: If model hasn't been trained or fitted yet\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'image_threshold') or not hasattr(model, 'pixel_threshold'):\n",
    "        raise AttributeError(\"Model missing required threshold attributes. Ensure model is properly trained.\")\n",
    "    \n",
    "    if not hasattr(model, 'normalization_metrics'):\n",
    "        raise RuntimeError(\"Model normalization metrics not available. Model may not be fitted yet.\")\n",
    "    \n",
    "    try:\n",
    "        inference_info = {\n",
    "            'image_threshold': float(model.image_threshold.value.item()) if hasattr(model.image_threshold.value, 'item') else float(model.image_threshold.value),\n",
    "            'pixel_threshold': float(model.pixel_threshold.value.item()) if hasattr(model.pixel_threshold.value, 'item') else float(model.pixel_threshold.value),\n",
    "            'pred_score_min': float(model.normalization_metrics.pred_scores.min.item()) if hasattr(model.normalization_metrics.pred_scores.min, 'item') else float(model.normalization_metrics.pred_scores.min),\n",
    "            'pred_score_max': float(model.normalization_metrics.pred_scores.max.item()) if hasattr(model.normalization_metrics.pred_scores.max, 'item') else float(model.normalization_metrics.pred_scores.max),\n",
    "            'anomaly_map_min': float(model.normalization_metrics.anomaly_maps.min.item()) if hasattr(model.normalization_metrics.anomaly_maps.min, 'item') else float(model.normalization_metrics.anomaly_maps.min),\n",
    "            'anomaly_map_max': float(model.normalization_metrics.anomaly_maps.max.item()) if hasattr(model.normalization_metrics.anomaly_maps.max, 'item') else float(model.normalization_metrics.anomaly_maps.max)\n",
    "        }\n",
    "    except (AttributeError, TypeError) as e:\n",
    "        raise RuntimeError(f\"Failed to extract inference info from model: {e}\")\n",
    "    \n",
    "    return inference_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8562fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_model_name(model_name: Union[str, ModelType])->ModelType:\n",
    "    if isinstance(model_name, str):\n",
    "        try:\n",
    "            model_name = ModelType(model_name.lower())\n",
    "        except ValueError:\n",
    "            valid_models = [m.value for m in ModelType]\n",
    "            raise ValueError(f\"Invalid model name: {model_name}. Valid options are: {valid_models}\")\n",
    "    return model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d800fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_backbone_name(backbone_name: str)->BackboneType:\n",
    "    \"\"\"Validate the backbone name.\"\"\"\n",
    "    if isinstance(backbone_name, str):\n",
    "        try:\n",
    "            backbone_name = BackboneType(backbone_name.lower())\n",
    "        except ValueError:\n",
    "            valid_backbones = [b.value for b in BackboneType]\n",
    "            raise ValueError(f\"Invalid backbone name: {backbone_name}. Valid options are: {valid_backbones}\")\n",
    "    return backbone_name\n",
    "\n",
    "validate_backbone_name(\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a1bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def main_(\n",
    "    data_root: str, # Name of the directory containing the data, inside this folder there should two other folder for normal and abnormal images\n",
    "    class_name: str = \"anomaly_detection\", #  What anomaly class you are detection, default anomaly_detection\n",
    "    normal_dir: str = \"good\", # Name of the directory containing normal images\n",
    "    abnormal_dir: str = \"bad\", # Name of the directory containing abnormal images\n",
    "    model_name: str = \"padim\", # Model to use for training, default padim\n",
    "    backbone: str = \"resnet18\", # Backbone to use for training, default resnet18\n",
    "    n_features: int = 100, # Number of features to use for training, default 100\n",
    "    layers: list[str] = ['layer1', 'layer2', 'layer3'], # Layers to use for training, default ['layer1', 'layer2', 'layer3']\n",
    "    image_size: tuple[int, int] = None, # Size of the images to use for training, uses anomalib default (256, 256) if None\n",
    "    #normalization: str = \"imagenet\", # Normalization to use for training, default imagenet\n",
    "    train_batch_size: int = None, # Batch size for training, auto-detected based on memory if None\n",
    "    eval_batch_size: int = None, # Batch size for evaluation, auto-detected based on memory if None  \n",
    "    num_workers: int = None, # Number of workers for data loading, auto-detected based on environment if None\n",
    "    max_epochs: int = 100, # Maximum number of epochs to train, default 100\n",
    "    accelerator: str = \"auto\", # Accelerator to use for training, default auto\n",
    "    devices: str = \"auto\", # Devices to use for training, default auto\n",
    "    save_path: str = \"./models\", # Path to save the model, default ./models\n",
    "    seed: int = None, # Seed to use for training, default None\n",
    "    export_formats: list[str] = ['torch'], # Formats to export the model, default ['torch']\n",
    "    enable_tiling: bool = False, # Enable tiling for training, default False\n",
    "    tile_size: tuple[int, int] = None, # Size of the tiles to use for training, uses anomalib default (None) if None\n",
    "    stride: tuple[int, int] = None, # Stride to use for training, uses anomalib default (None) if None\n",
    "    enable_tensorboard: bool = None, # Enable tensorboard for training, uses anomalib default (False) if None\n",
    "    enable_csv_logger: bool = None, # Enable csv logger for training, uses anomalib default (False) if None\n",
    "    log_level: str = None, # Log level to use for training, uses anomalib default ('INFO') if None\n",
    "    enable_progress_bar: bool = None, # Enable progress bar, auto-detected based on environment if None\n",
    "    num_sanity_val_steps: int = None, # Number of validation sanity steps, auto-detected based on environment if None\n",
    "):\n",
    "    \"\"\"\n",
    "    üöÄ Intelligent Anomaly Detection Training CLI with Anomalib Defaults\n",
    "    ü§ñ Smart Auto-Detection Features:\n",
    "    \n",
    "    üí° Override any parameter by providing explicit values!\n",
    "    \"\"\"\n",
    "    # Validate and convert string inputs to enums\n",
    "    model_name = validate_model_name(model_name)\n",
    "    backbone = validate_backbone_name(backbone)\n",
    "\n",
    "    print(f\"üöÄ Starting training with {model_name.value} model using {backbone.value} backbone\")\n",
    "    \n",
    "    # Apply anomalib default values for None parameters\n",
    "    # These are the standard defaults used by anomalib library\n",
    "    ANOMALIB_DEFAULTS = {\n",
    "        'image_size': (256, 256),      # Anomalib standard image size\n",
    "        'tile_size': None,             # Disabled by default in anomalib\n",
    "        'stride': None,                # Disabled by default in anomalib  \n",
    "        'enable_tensorboard': False,   # Disabled by default in anomalib\n",
    "        'enable_csv_logger': False,    # Disabled by default in anomalib\n",
    "        'log_level': 'INFO',          # Standard logging level\n",
    "    }\n",
    "    \n",
    "    # Use user values if provided, otherwise use anomalib defaults\n",
    "    if image_size is None:\n",
    "        image_size = ANOMALIB_DEFAULTS['image_size']\n",
    "        print(f\"   üìê Using anomalib default image_size: {image_size}\")\n",
    "    else:\n",
    "        print(f\"   üìê Using user-specified image_size: {image_size}\")\n",
    "        \n",
    "    if tile_size is None:\n",
    "        tile_size = ANOMALIB_DEFAULTS['tile_size']\n",
    "        print(f\"   üî≤ Using anomalib default tile_size: {tile_size}\")\n",
    "    else:\n",
    "        print(f\"   üî≤ Using user-specified tile_size: {tile_size}\")\n",
    "        \n",
    "    if stride is None:\n",
    "        stride = ANOMALIB_DEFAULTS['stride']\n",
    "        print(f\"   ‚ÜóÔ∏è  Using anomalib default stride: {stride}\")\n",
    "    else:\n",
    "        print(f\"   ‚ÜóÔ∏è  Using user-specified stride: {stride}\")\n",
    "        \n",
    "    if enable_tensorboard is None:\n",
    "        enable_tensorboard = ANOMALIB_DEFAULTS['enable_tensorboard']\n",
    "        print(f\"   üìä Using anomalib default enable_tensorboard: {enable_tensorboard}\")\n",
    "    else:\n",
    "        print(f\"   üìä Using user-specified enable_tensorboard: {enable_tensorboard}\")\n",
    "        \n",
    "    if enable_csv_logger is None:\n",
    "        enable_csv_logger = ANOMALIB_DEFAULTS['enable_csv_logger']\n",
    "        print(f\"   üìù Using anomalib default enable_csv_logger: {enable_csv_logger}\")\n",
    "    else:\n",
    "        print(f\"   üìù Using user-specified enable_csv_logger: {enable_csv_logger}\")\n",
    "        \n",
    "    if log_level is None:\n",
    "        log_level = ANOMALIB_DEFAULTS['log_level']\n",
    "        print(f\"   üîç Using anomalib default log_level: {log_level}\")\n",
    "    else:\n",
    "        print(f\"   üîç Using user-specified log_level: {log_level}\")\n",
    "    \n",
    "    # Build config dict with resolved values (user-specified or anomalib defaults)\n",
    "    config_params = {\n",
    "        'class_name': class_name,\n",
    "        'data_root': data_root,\n",
    "        'normal_dir': normal_dir,\n",
    "        'abnormal_dir': abnormal_dir,\n",
    "        'image_size': image_size,\n",
    "        'model_name': model_name,\n",
    "        'backbone': backbone,\n",
    "        'n_features': n_features,\n",
    "        'layers': layers,\n",
    "        'max_epochs': max_epochs,\n",
    "        'accelerator': accelerator,\n",
    "        'devices': devices,\n",
    "        'save_path': save_path,\n",
    "        'seed': seed,\n",
    "        'export_formats': [ExportType(fmt) for fmt in export_formats],\n",
    "        'enable_tiling': enable_tiling,\n",
    "        'tile_size': tile_size,\n",
    "        'stride': stride,\n",
    "        'enable_tensorboard': enable_tensorboard,\n",
    "        'enable_csv_logger': enable_csv_logger,\n",
    "        'log_level': log_level,\n",
    "    }\n",
    "    \n",
    "    # Only add parameters that were explicitly provided (not None)\n",
    "    # This allows FlexibleTrainingConfig to use its intelligent defaults for None values\n",
    "    if train_batch_size is not None:\n",
    "        config_params['train_batch_size'] = train_batch_size\n",
    "        print(f\"   üì¶ Using user-specified train_batch_size: {train_batch_size}\")\n",
    "    \n",
    "    if eval_batch_size is not None:\n",
    "        config_params['eval_batch_size'] = eval_batch_size\n",
    "        print(f\"   üì¶ Using user-specified eval_batch_size: {eval_batch_size}\")\n",
    "        \n",
    "    if num_workers is not None:\n",
    "        config_params['num_workers'] = num_workers\n",
    "        print(f\"   ‚öôÔ∏è  Using user-specified num_workers: {num_workers}\")\n",
    "        \n",
    "    if enable_progress_bar is not None:\n",
    "        config_params['enable_progress_bar'] = enable_progress_bar\n",
    "        print(f\"   üìä Using user-specified enable_progress_bar: {enable_progress_bar}\")\n",
    "        \n",
    "    if num_sanity_val_steps is not None:\n",
    "        config_params['num_sanity_val_steps'] = num_sanity_val_steps\n",
    "        print(f\"   üß™ Using user-specified num_sanity_val_steps: {num_sanity_val_steps}\")\n",
    "    \n",
    "    # Create config - this will apply smart defaults for any None/missing values\n",
    "    config = FlexibleTrainingConfig(**config_params)\n",
    "    \n",
    "    return train_anomaly_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a42e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#main_(\n",
    "    #data_root = data_path,\n",
    "    #normal_dir = \"good\",\n",
    "    #abnormal_dir = \"bad\",\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#import nbdev; nbdev.nbdev_export('04_training.flexible_anomaly_trainer.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Test the fix for string to enum conversion\n",
    "print(\"Testing string to enum conversion...\")\n",
    "\n",
    "# First let's check if the enum works directly\n",
    "print(f\"Direct enum test: ModelType('padim') = {ModelType('padim')}\")\n",
    "print(f\"Direct enum test: BackboneType('resnet18') = {BackboneType('resnet18')}\")\n",
    "\n",
    "test_config = FlexibleTrainingConfig(\n",
    "    data_root=\"/home/ai_dsx.work/data/2025-sinter-voids-tacking-agent/AD/data\",\n",
    "    model_name=\"padim\",          # STRING input\n",
    "    backbone=\"resnet18\",         # STRING input  \n",
    "    normal_dir=\"good_images\",\n",
    "    abnormal_dir=\"bad_images\",\n",
    "    max_epochs=1,\n",
    "    class_name=\"test_defect\"\n",
    ")\n",
    "\n",
    "print(f\"After __post_init__:\")\n",
    "print(f\"  model_name: {test_config.model_name} (type: {type(test_config.model_name)})\")\n",
    "print(f\"  backbone: {test_config.backbone} (type: {type(test_config.backbone)})\")\n",
    "\n",
    "# Test if .value works\n",
    "if hasattr(test_config.model_name, 'value'):\n",
    "    print(f\"‚úÖ model_name.value: {test_config.model_name.value}\")\n",
    "else:\n",
    "    print(f\"‚ùå model_name has no .value attribute - conversion failed!\")\n",
    "    \n",
    "if hasattr(test_config.backbone, 'value'):\n",
    "    print(f\"‚úÖ backbone.value: {test_config.backbone.value}\")\n",
    "else:\n",
    "    print(f\"‚ùå backbone has no .value attribute - conversion failed!\")\n",
    "# Additional check: create another config to confirm it works consistently  \n",
    "test_config2 = FlexibleTrainingConfig(\n",
    "    data_root=\"/tmp/test\",\n",
    "    model_name=\"patchcore\",\n",
    "    backbone=\"resnet50\",\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"bad\"\n",
    ")\n",
    "print(f\"\\nSecond test:\")\n",
    "print(f\"  model_name: {test_config2.model_name} (type: {type(test_config2.model_name)})\")\n",
    "print(f\"  backbone: {test_config2.backbone} (type: {type(test_config2.backbone)})\")\n",
    "if hasattr(test_config2.model_name, 'value') and hasattr(test_config2.backbone, 'value'):\n",
    "    print(f\"  ‚úÖ Values: {test_config2.model_name.value}, {test_config2.backbone.value}\")\n",
    "    print(\"\\nüéâ The fix works! You can now use strings for model_name and backbone in your config!\")\n",
    "else:\n",
    "    print(\"  ‚ùå Still not working properly\")\n",
    "\n",
    "# Now test the train_anomaly_model function won't crash\n",
    "print(\"\\nüî• Testing that train_anomaly_model won't crash with string inputs...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# Final test: Create a config with strings and verify no .value errors\n",
    "final_test_config = FlexibleTrainingConfig(\n",
    "    data_root=\"/tmp/final_test\",\n",
    "    model_name=\"padim\",         # STRING - this should work now!\n",
    "    backbone=\"resnet18\",        # STRING - this should work now!\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"bad\",\n",
    "    max_epochs=1,\n",
    "    class_name=\"final_test\"\n",
    ")\n",
    "\n",
    "print(\"üß™ Final test - simulating what train_anomaly_model does:\")\n",
    "print(f\"‚úÖ Model name: {final_test_config.model_name.value}\")  \n",
    "print(f\"‚úÖ Backbone: {final_test_config.backbone.value}\")\n",
    "print(f\"‚úÖ Checkpoint filename: {final_test_config.model_name.value}_{final_test_config.backbone.value}_epoch.ckpt\")\n",
    "print(\"\\nüéâ SUCCESS! No more 'str' object has no attribute 'value' errors!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915719a3",
   "metadata": {},
   "source": [
    "# Test the fix - Device error issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406157a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config without explicit values - should use smart defaults\n",
    "config_auto = FlexibleTrainingConfig(\n",
    "    data_root=\"/home/ai_dsx.work/data/2025-sinter-voids-tacking-agent/AD/data\",\n",
    "    model_name=\"padim\",\n",
    "    backbone=\"resnet18\",\n",
    "    normal_dir=\"good_images\",\n",
    "    abnormal_dir=\"bad_images\",\n",
    "    max_epochs=1,  # Just for testing\n",
    ")\n",
    "\n",
    "print(f\"\\nConfig with Auto-Detection (user didn't specify):\")\n",
    "print(f\"   ü§ñ num_workers: {config_auto.num_workers}\")\n",
    "print(f\"   ü§ñ train_batch_size: {config_auto.train_batch_size}\")\n",
    "print(f\"   ü§ñ eval_batch_size: {config_auto.eval_batch_size}\")\n",
    "print(f\"   ü§ñ enable_progress_bar: {config_auto.enable_progress_bar}\")\n",
    "print(f\"   ü§ñ num_sanity_val_steps: {config_auto.num_sanity_val_steps}\")\n",
    "print(f\"   ü§ñ accelerator: {config_auto.accelerator}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0076ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config with explicit values - should override smart defaults\n",
    "config_manual = FlexibleTrainingConfig(\n",
    "    data_root=\"/home/ai_dsx.work/data/2025-sinter-voids-tacking-agent/AD/data\",\n",
    "    model_name=\"padim\", \n",
    "    backbone=\"resnet18\",\n",
    "    normal_dir=\"good_images\",\n",
    "    abnormal_dir=\"bad_images\",\n",
    "    max_epochs=1,\n",
    "    num_workers=8,           # User override\n",
    "    train_batch_size=64,     # User override\n",
    "    eval_batch_size=64,      # User override\n",
    "    enable_progress_bar=True,# User override\n",
    ")\n",
    "\n",
    "print(f\"\\nConfig with User Overrides (user specified values):\")\n",
    "print(f\"   üë§ num_workers: {config_manual.num_workers} (user specified)\")\n",
    "print(f\"   üë§ train_batch_size: {config_manual.train_batch_size} (user specified)\")\n",
    "print(f\"   üë§ eval_batch_size: {config_manual.eval_batch_size} (user specified)\")\n",
    "print(f\"   üë§ enable_progress_bar: {config_manual.enable_progress_bar} (user specified)\")\n",
    "print(f\"   ü§ñ num_sanity_val_steps: {config_manual.num_sanity_val_steps} (auto-detected)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Smart defaults system working perfectly!\")\n",
    "print(f\"   ‚Ä¢ Auto-detects Jupyter vs script environment\")\n",
    "print(f\"   ‚Ä¢ Sets num_workers=0 in Jupyter (no multiprocessing issues)\")\n",
    "print(f\"   ‚Ä¢ Adjusts batch size based on available memory\")\n",
    "print(f\"   ‚Ä¢ Disables progress bar in Jupyter for cleaner output\")\n",
    "print(f\"   ‚Ä¢ Users can still override any setting they want\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e31f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "## Testing the Improved main_ Function\n",
    "\n",
    "# Let's test the new intelligent CLI behavior\n",
    "\n",
    "print(\"üß™ Testing improved main_ function with smart defaults...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: No explicit batch sizes - should use smart defaults  \n",
    "print(\"\\nüìã Test 1: Auto-detected parameters (no explicit batch sizes)\")\n",
    "print(\"Should show smart defaults being applied automatically:\")\n",
    "\n",
    "# Simulate calling main_ with auto-detection\n",
    "result1 = main_(\n",
    "    data_root=\"/tmp/test_data\",\n",
    "    class_name=\"test_auto\",\n",
    "    model_name=\"padim\",\n",
    "    max_epochs=1,  # Quick test\n",
    "    # Note: train_batch_size=None, eval_batch_size=None, num_workers=None\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Auto-detected batch size: {result1 if isinstance(result1, dict) and 'error' not in result1 else 'Config created successfully'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# Test 2: Explicit batch sizes - should override smart defaults\n",
    "print(\"\\nüìã Test 2: User-specified parameters (explicit batch sizes)\")\n",
    "print(\"Should show user overrides being used:\")\n",
    "\n",
    "# Simulate calling main_ with explicit values\n",
    "result2 = main_(\n",
    "    data_root=\"/tmp/test_data\",\n",
    "    class_name=\"test_manual\", \n",
    "    model_name=\"padim\",\n",
    "    train_batch_size=64,  # User override\n",
    "    eval_batch_size=128,  # User override\n",
    "    num_workers=8,       # User override\n",
    "    enable_progress_bar=True,  # User override\n",
    "    max_epochs=1,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ User-specified parameters respected: {result2 if isinstance(result2, dict) and 'error' not in result2 else 'Config created successfully'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüéâ SUCCESS! The improved main_ function now:\")\n",
    "print(\"   ‚úÖ Uses intelligent defaults when parameters are None\")\n",
    "print(\"   ‚úÖ Respects user overrides when parameters are explicitly provided\")\n",
    "print(\"   ‚úÖ Provides clear feedback about which values are being used\")\n",
    "print(\"   ‚úÖ Maintains full CLI flexibility while being environmentally aware\")\n",
    "\n",
    "print(f\"\\nüöÄ You can now use the CLI tool and get the benefits of both:\")\n",
    "print(f\"   ‚Ä¢ Automatic environment optimization (Jupyter vs scripts)\")\n",
    "print(f\"   ‚Ä¢ Full manual control when you need it\")\n",
    "print(f\"   ‚Ä¢ Memory-aware batch sizing\")\n",
    "print(f\"   ‚Ä¢ Platform-specific optimizations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba32474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the threshold and pixel statistics extraction\n",
    "print(\"üß™ Testing Model Threshold and Pixel Statistics Extraction\\n\")\n",
    "\n",
    "print(f\"üéØ Now training results will include:\")\n",
    "print(f\"   ‚Ä¢ model_threshold: The threshold value used by the trained model\")\n",
    "print(f\"   ‚Ä¢ pixel_metrics: Dictionary with pixel_min and pixel_max values\")\n",
    "print(f\"   ‚Ä¢ This matches what you see when loading with TorchInferencer!\")\n",
    "\n",
    "print(f\"\\n‚úÖ These are the specific parameters you mentioned:\")\n",
    "print(f\"   üìä Threshold value\")\n",
    "print(f\"   üìä Pixel min value\") \n",
    "print(f\"   üìä Pixel max value\")\n",
    "print(f\"   üìä Pixel metrics information\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate what the training results structure now contains\n",
    "print(\"üìã Updated Training Results Structure:\\n\")\n",
    "\n",
    "sample_results_structure = {\n",
    "    'success': True,\n",
    "    'config': \"< Full FlexibleTrainingConfig dictionary >\",\n",
    "    'model_threshold': 0.5234,  # The actual threshold value from the model\n",
    "    'pixel_metrics': {\n",
    "        'pixel_min': 0.0,      # Minimum pixel value used for normalization\n",
    "        'pixel_max': 1.0       # Maximum pixel value used for normalization  \n",
    "    },\n",
    "    'training_duration': '0:02:15.123456',\n",
    "    'best_model_path': '/path/to/best_model.ckpt',\n",
    "    'export_paths': {\n",
    "        'torch': '/path/to/exported_model.pt'\n",
    "    },\n",
    "    'test_results': \"< Complete test metrics >\",\n",
    "    'anomalib_version': '1.2.0',\n",
    "    'timestamp': '2025-01-XX...'\n",
    "}\n",
    "\n",
    "print(\"üéâ Training results now include the specific inference information:\")\n",
    "print(\"   ‚úÖ model_threshold: Exact threshold value used by the model\")\n",
    "print(\"   ‚úÖ pixel_metrics: Min/max pixel values for proper normalization\")\n",
    "print(\"   ‚úÖ This matches what TorchInferencer shows when loading the model!\")\n",
    "\n",
    "print(f\"\\nüí° Example usage after training:\")\n",
    "print(f\"   results['model_threshold']  # ‚Üí 0.5234\")\n",
    "print(f\"   results['pixel_metrics']['pixel_min']  # ‚Üí 0.0\")\n",
    "print(f\"   results['pixel_metrics']['pixel_max']  # ‚Üí 1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ae613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing whether anomalib defaults are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new anomalib defaults behavior\n",
    "print(\"üß™ Testing New Anomalib Defaults Integration\\n\")\n",
    "\n",
    "# Test 1: FlexibleTrainingConfig with new defaults\n",
    "print(\"üìã Test 1: FlexibleTrainingConfig now uses anomalib defaults\")\n",
    "config_with_defaults = FlexibleTrainingConfig(\n",
    "    data_root=\"/tmp/test\",\n",
    "    model_name=\"padim\",\n",
    "    backbone=\"resnet18\",\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"bad\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ New Default Values in FlexibleTrainingConfig:\")\n",
    "print(f\"   üìê image_size: {config_with_defaults.image_size} (was (224,224), now anomalib default)\")\n",
    "print(f\"   üî≤ tile_size: {config_with_defaults.tile_size} (was (256,256), now anomalib default)\")\n",
    "print(f\"   ‚ÜóÔ∏è  stride: {config_with_defaults.stride} (was (128,128), now anomalib default)\")\n",
    "print(f\"   üìä enable_tensorboard: {config_with_defaults.enable_tensorboard} (was True, now anomalib default)\")\n",
    "print(f\"   üìù enable_csv_logger: {config_with_defaults.enable_csv_logger} (was True, now anomalib default)\")\n",
    "print(f\"   üîç log_level: {config_with_defaults.log_level} (unchanged, correct anomalib default)\")\n",
    "\n",
    "print(f\"\\n‚úÖ SUCCESS! FlexibleTrainingConfig now uses proper anomalib defaults!\")\n",
    "print(f\"   ‚Ä¢ Image size changed from (224,224) to (256,256)\")\n",
    "print(f\"   ‚Ä¢ Tiling disabled by default (None values)\")\n",
    "print(f\"   ‚Ä¢ Logging disabled by default (False values)\")\n",
    "print(f\"   ‚Ä¢ These match anomalib's standard configuration!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ce7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: main_ function with None values (should use anomalib defaults)\n",
    "print(\"\\nüìã Test 2: main_ function with None values (should use anomalib defaults)\")\n",
    "print(\"This simulates calling main_ without specifying image_size, tile_size, etc.\")\n",
    "\n",
    "# Create a mock test to show the logic without actually running training\n",
    "def test_main_defaults():\n",
    "    \"\"\"Simulate the main_ function logic for testing defaults\"\"\"\n",
    "    \n",
    "    # Simulate None inputs (user didn't specify)\n",
    "    image_size = None\n",
    "    tile_size = None  \n",
    "    stride = None\n",
    "    enable_tensorboard = None\n",
    "    enable_csv_logger = None\n",
    "    log_level = None\n",
    "    \n",
    "    # This is the same logic now in main_ function\n",
    "    ANOMALIB_DEFAULTS = {\n",
    "        'image_size': (256, 256),      # Anomalib standard image size\n",
    "        'tile_size': None,             # Disabled by default in anomalib\n",
    "        'stride': None,                # Disabled by default in anomalib  \n",
    "        'enable_tensorboard': False,   # Disabled by default in anomalib\n",
    "        'enable_csv_logger': False,    # Disabled by default in anomalib\n",
    "        'log_level': 'INFO',          # Standard logging level\n",
    "    }\n",
    "    \n",
    "    # Apply defaults\n",
    "    if image_size is None:\n",
    "        image_size = ANOMALIB_DEFAULTS['image_size']\n",
    "        print(f\"   üìê Using anomalib default image_size: {image_size}\")\n",
    "        \n",
    "    if tile_size is None:\n",
    "        tile_size = ANOMALIB_DEFAULTS['tile_size']\n",
    "        print(f\"   üî≤ Using anomalib default tile_size: {tile_size}\")\n",
    "        \n",
    "    if stride is None:\n",
    "        stride = ANOMALIB_DEFAULTS['stride']\n",
    "        print(f\"   ‚ÜóÔ∏è  Using anomalib default stride: {stride}\")\n",
    "        \n",
    "    if enable_tensorboard is None:\n",
    "        enable_tensorboard = ANOMALIB_DEFAULTS['enable_tensorboard']\n",
    "        print(f\"   üìä Using anomalib default enable_tensorboard: {enable_tensorboard}\")\n",
    "        \n",
    "    if enable_csv_logger is None:\n",
    "        enable_csv_logger = ANOMALIB_DEFAULTS['enable_csv_logger']\n",
    "        print(f\"   üìù Using anomalib default enable_csv_logger: {enable_csv_logger}\")\n",
    "        \n",
    "    if log_level is None:\n",
    "        log_level = ANOMALIB_DEFAULTS['log_level']\n",
    "        print(f\"   üîç Using anomalib default log_level: {log_level}\")\n",
    "    \n",
    "    return {\n",
    "        'image_size': image_size,\n",
    "        'tile_size': tile_size,\n",
    "        'stride': stride,\n",
    "        'enable_tensorboard': enable_tensorboard,\n",
    "        'enable_csv_logger': enable_csv_logger,\n",
    "        'log_level': log_level\n",
    "    }\n",
    "\n",
    "# Run the test\n",
    "result = test_main_defaults()\n",
    "\n",
    "print(f\"\\n‚úÖ main_ function now properly uses anomalib defaults!\")\n",
    "print(f\"   ‚Ä¢ When user doesn't specify parameters, anomalib defaults are used\")\n",
    "print(f\"   ‚Ä¢ When user specifies parameters, user values are used\")\n",
    "print(f\"   ‚Ä¢ Clear feedback shows which values are being applied\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = get_images_(Path(DATA_ROOT))\n",
    "test_images = get_images_(Path(DATA_ROOT)) \n",
    "model_path = Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/models/exports/tutorial_basic/weights/torch/model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/images\")\n",
    "val_images = get_images_(Path(DATA_ROOT, 'bad'))\n",
    "test_images = get_images_(Path(DATA_ROOT, 'bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'model_path': str(model_path),\n",
    "    'validation_results': [],\n",
    "    'test_results': [],\n",
    "    'posters': [],\n",
    "    'statistics': {\n",
    "        'total_images': len(val_images) + len(test_images),\n",
    "        'validation_count': len(val_images),\n",
    "        'test_count': len(test_images),\n",
    "        'anomaly_count': 0,\n",
    "        'normal_count': 0\n",
    "    }\n",
    "}\n",
    "results['validation_results'], results = run_inference_batch(val_images, 'validation', model_path,save_heatmap=False,show_heatmap=False, results=results)\n",
    "results['test_results'], results = run_inference_batch(test_images, 'test', model_path,save_heatmap=False,show_heatmap=False, results=results)\n",
    "total_results = results['validation_results'] + results['test_results']\n",
    "print(f\"‚úÖ Inference completed: {len(total_results)} successful predictions\")\n",
    "print(f\"   Normal: {results['statistics']['normal_count']}\")\n",
    "print(f\"   Anomaly: {results['statistics']['anomaly_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['validation_results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['test_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_ROOT = Path(r\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd894f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12769fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_inference_after_training(\n",
    "    training_results: Dict[str, Any],\n",
    "    validation_images: Optional[Union[str, Path, List[Union[str, Path]]]] = None,\n",
    "    test_images: Optional[Union[str, Path, List[Union[str, Path]]]] = None,\n",
    "    create_heatmaps: bool = True,\n",
    "    poster_rows: int = 4,\n",
    "    poster_cols: int = 4,\n",
    "    output_folder: Optional[Union[str, Path]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Convenience function to run inference and create posters directly from training results.\n",
    "    \n",
    "    Args:\n",
    "        training_results: Results dictionary from train_anomaly_model()\n",
    "        validation_images: Path to validation images folder or list of image paths\n",
    "        test_images: Path to test images folder or list of image paths\n",
    "        create_heatmaps: Whether to create heatmap posters (requires exported model)\n",
    "        poster_rows: Number of rows in poster grid\n",
    "        poster_cols: Number of columns in poster grid\n",
    "        output_folder: Output folder (auto-generated if None)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with inference results and poster paths\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate training results\n",
    "    if not training_results.get('success', False):\n",
    "        raise ValueError(\"Training was not successful. Cannot proceed with inference.\")\n",
    "    \n",
    "    # Get model path from training results\n",
    "    model_path = None\n",
    "    \n",
    "    # Try exported model first (better for inference)\n",
    "    export_paths = training_results.get('export_paths', {})\n",
    "    if 'torch' in export_paths:\n",
    "        model_path = export_paths['torch']\n",
    "        print(f\"üéØ Using exported model: {model_path}\")\n",
    "    elif training_results.get('best_model_path'):\n",
    "        model_path = training_results['best_model_path']\n",
    "        print(f\"üéØ Using checkpoint model: {model_path}\")\n",
    "    else:\n",
    "        raise ValueError(\"No valid model path found in training results\")\n",
    "    \n",
    "    # Auto-generate output folder if not provided\n",
    "    if output_folder is None:\n",
    "        config = training_results.get('config', {})\n",
    "        class_name = config.get('class_name', 'anomaly_detection')\n",
    "        model_name = config.get('model_name', 'model')\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        if create_heatmaps:\n",
    "            output_folder = f\"inference_results_{class_name}_{model_name}_heatmaps_{timestamp}\"\n",
    "        else:\n",
    "            output_folder = f\"inference_results_{class_name}_{model_name}_{timestamp}\"\n",
    "    \n",
    "    print(f\"üöÄ Running inference after training\")\n",
    "    print(f\"   Class: {training_results.get('config', {}).get('class_name', 'Unknown')}\")\n",
    "    print(f\"   Model: {model_path}\")\n",
    "    print(f\"   Heatmaps: {'Yes' if create_heatmaps else 'No'}\")\n",
    "    print(f\"   Output: {output_folder}\")\n",
    "    \n",
    "    # Run appropriate inference function\n",
    "    if create_heatmaps:\n",
    "        # Adjust columns for side-by-side if needed\n",
    "        if poster_cols % 2 != 0:\n",
    "            poster_cols += 1\n",
    "            print(f\"   Adjusted columns to {poster_cols} for heatmap layout\")\n",
    "            \n",
    "        return create_inference_poster_with_heatmaps(\n",
    "            model_path=model_path,\n",
    "            validation_images=validation_images,\n",
    "            test_images=test_images,\n",
    "            output_folder=output_folder,\n",
    "            poster_rows=poster_rows,\n",
    "            poster_cols=poster_cols,\n",
    "            heatmap_style=\"side_by_side\",\n",
    "            poster_title=f\"{training_results.get('config', {}).get('class_name', 'Anomaly')} Detection\"\n",
    "        )\n",
    "    else:\n",
    "        return create_inference_poster(\n",
    "            model_path=model_path,\n",
    "            validation_images=validation_images,\n",
    "            test_images=test_images,\n",
    "            output_folder=output_folder,\n",
    "            poster_rows=poster_rows,\n",
    "            poster_cols=poster_cols,\n",
    "            poster_title=f\"{training_results.get('config', {}).get('class_name', 'Anomaly')} Detection\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b023950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete workflow example: Training + Inference + Poster Creation\n",
    "def complete_training_with_inference_example():\n",
    "    \"\"\"\n",
    "    Complete example showing how to train a model and immediately create inference posters.\n",
    "    \"\"\"\n",
    "    print(\"üî• Complete Training + Inference Workflow\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "# Step 1: Train your model\n",
    "config = FlexibleTrainingConfig(\n",
    "    data_root=\"path/to/your/data\",\n",
    "    normal_dir=\"good\", \n",
    "    abnormal_dir=\"bad\",\n",
    "    model_name=\"padim\",\n",
    "    backbone=\"resnet18\",\n",
    "    max_epochs=50,\n",
    "    class_name=\"defect_detection\"\n",
    ")\n",
    "\n",
    "training_results = train_anomaly_model(config)\n",
    "\n",
    "# Step 2: Run inference and create posters directly from training results\n",
    "inference_results = run_inference_after_training(\n",
    "    training_results=training_results,\n",
    "    validation_images=\"path/to/validation/images\",\n",
    "    test_images=\"path/to/test/images\",  # Optional\n",
    "    create_heatmaps=True,  # Creates beautiful heatmap posters\n",
    "    poster_rows=3,\n",
    "    poster_cols=6  # Even number for side-by-side heatmaps\n",
    ")\n",
    "\n",
    "# Step 3: Review results\n",
    "print(f\"Training completed: {training_results['success']}\")\n",
    "print(f\"Inference posters created: {len(inference_results['posters'])}\")\n",
    "print(f\"Anomalies detected: {inference_results['statistics']['anomaly_count']}\")\n",
    "print(f\"Normal images: {inference_results['statistics']['normal_count']}\")\n",
    "\n",
    "# The posters are automatically saved and ready for review!\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nüéØ What You Get:\")\n",
    "    print(\"‚úÖ Trained anomaly detection model\")\n",
    "    print(\"‚úÖ Model exported in multiple formats\")\n",
    "    print(\"‚úÖ Beautiful poster grids showing all inference results\") \n",
    "    print(\"‚úÖ Color-coded predictions (red=anomaly, green=normal)\")\n",
    "    print(\"‚úÖ Side-by-side comparison of original images and heatmaps\")\n",
    "    print(\"‚úÖ Detailed JSON results for further analysis\")\n",
    "    print(\"‚úÖ Automatic handling of large datasets (multiple posters)\")\n",
    "    \n",
    "    print(\"\\nüí° Pro Tips:\")\n",
    "    print(\"‚Ä¢ Use validation_images for images similar to training data\")\n",
    "    print(\"‚Ä¢ Use test_images for completely new/unseen images\")  \n",
    "    print(\"‚Ä¢ create_heatmaps=True gives the most insightful visualizations\")\n",
    "    print(\"‚Ä¢ Adjust poster_rows and poster_cols to fit your screen/report needs\")\n",
    "    print(\"‚Ä¢ Results are automatically timestamped to avoid overwrites\")\n",
    "\n",
    "# Run the example\n",
    "complete_training_with_inference_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924efbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the new threshold and pixel statistics extraction\n",
    "print(\"üß™ Testing the new _extract_model_inference_info function\\n\")\n",
    "\n",
    "# Create a mock model object to test the extraction logic\n",
    "class MockModel:\n",
    "    def __init__(self):\n",
    "        self.threshold = torch.tensor(0.5234)\n",
    "        self.normalization_metrics = type('obj', (object,), {\n",
    "            'pixel_min': 0.0,\n",
    "            'pixel_max': 1.0\n",
    "        })()\n",
    "\n",
    "# Test the function\n",
    "mock_model = MockModel()\n",
    "inference_info = _extract_model_inference_info(mock_model)\n",
    "\n",
    "print(f\"‚úÖ Extracted inference info:\")\n",
    "print(f\"   Threshold: {inference_info['threshold']}\")\n",
    "print(f\"   Pixel Min: {inference_info['pixel_metrics']['pixel_min']}\")\n",
    "print(f\"   Pixel Max: {inference_info['pixel_metrics']['pixel_max']}\")\n",
    "\n",
    "print(f\"\\nüéØ This information will now be available in training results!\")\n",
    "print(f\"   results['model_threshold'] = {inference_info['threshold']}\")\n",
    "print(f\"   results['pixel_metrics'] = {inference_info['pixel_metrics']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f55141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r'/home/ai_dsx.work/data/projects/be-vision-ad-tools/nbs')\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('04_training.flexible_anomaly_trainer.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb783d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
