{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-node training\n",
    "> Grid search training on multiple nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "425d9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training.multi_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "210c022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e759e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b7e623b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Union, Optional, Tuple\n",
    "from fastcore.script import call_parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86839eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, asdict\n",
    "import json\n",
    "import configparser\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c13d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "load_dotenv(dotenv_path=f'/home/ai_dsx.work/data/projects/be-vision-ad-tools/be-vision-ad-tools/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e1f3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRETNT_NB='/home/ai_dsx.work/data/projects/be-vision-ad-tools/nbs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ffebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e7e60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Import our training functions\n",
    "from be_vision_ad_tools.training.flexible_trainer import (\n",
    "    FlexibleTrainingConfig, train_anomaly_model, ModelType, BackboneType\n",
    ")\n",
    "from be_vision_ad_tools.training.hyperparameter_search import (\n",
    "    simple_hyperparameter_search, create_modular_batch_comparison_poster\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "59e57256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Any, Union, Optional, Tuple\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "from itertools import product\n",
    "import configparser\n",
    "import shutil\n",
    "import os\n",
    "import yaml\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11b3eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_training_tasks(\n",
    "    data_root: Union[str, Path],  # Root directory containing data\n",
    "    normal_dir: str = \"good\",     # Normal images subdirectory  \n",
    "    abnormal_dir: str = \"bad\",    # Abnormal images subdirectory\n",
    "    class_name: str = \"multinode_search\",  # Base class name\n",
    "    \n",
    "    # Parameter combinations to distribute\n",
    "    model_names: List[str] = None,        # Models to test\n",
    "    backbones: List[str] = None,          # Backbones to test\n",
    "    n_features_list: List[int] = None,    # Features to test\n",
    "    layers: List[List[str]] = None,       # Layers to test\n",
    "    \n",
    "    # Training settings\n",
    "    max_epochs: int = 10,                 # Training epochs\n",
    "    output_base: Union[str, Path] = None, # Base output directory\n",
    "    \n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate individual training tasks for multi-node execution.\n",
    "    \n",
    "    Each task represents one parameter combination that can be executed\n",
    "    independently on a separate node.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set defaults\n",
    "    if model_names is None:\n",
    "        model_names = ['padim']\n",
    "    if backbones is None:\n",
    "        backbones = ['wide_resnet50_2']\n",
    "    if n_features_list is None:\n",
    "        n_features_list = [64, 128]\n",
    "    if layers is None:\n",
    "        layers = [['layer1'], ['layer1', 'layer2', 'layer3']]\n",
    "    \n",
    "    if output_base is None:\n",
    "        output_base = Path(data_root) / 'multinode_results'\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = list(product(model_names, backbones, n_features_list, layers))\n",
    "    \n",
    "    print(f\"ğŸ§ª Generating {len(param_combinations)} training tasks\")\n",
    "    print(f\"ğŸ“¦ Models: {model_names}\")\n",
    "    print(f\"ğŸ—ï¸ Backbones: {backbones}\")\n",
    "    print(f\"ğŸ”¢ Features: {n_features_list}\")\n",
    "    print(f\"ğŸ“Š Layers: {layers}\")\n",
    "    \n",
    "    tasks = []\n",
    "    for i, (model_name, backbone, n_features, layer_list) in enumerate(param_combinations):\n",
    "        \n",
    "        # Create unique task identifier\n",
    "        task_id = f\"task_{i:03d}_{model_name}_{backbone}_{n_features}_{'-'.join(layer_list)}\"\n",
    "        \n",
    "        # Define output paths for this task\n",
    "        task_output = Path(output_base) / task_id\n",
    "        model_save_path = task_output / \"model\"\n",
    "        results_path = task_output / \"results\"\n",
    "        \n",
    "        task = {\n",
    "            'task_id': task_id,\n",
    "            'index': i,\n",
    "            'model_name': model_name,\n",
    "            'backbone': backbone,\n",
    "            'n_features': n_features,\n",
    "            'layers': layer_list,\n",
    "            'data_root': str(data_root),\n",
    "            'normal_dir': normal_dir,\n",
    "            'abnormal_dir': abnormal_dir,\n",
    "            'class_name': f\"{class_name}_{task_id}\",\n",
    "            'max_epochs': max_epochs,\n",
    "            'output_folder': str(results_path),\n",
    "            'save_path': str(model_save_path),\n",
    "            'task_output_base': str(task_output)\n",
    "        }\n",
    "        \n",
    "        tasks.append(task)\n",
    "    \n",
    "    print(f\"âœ… Generated {len(tasks)} training tasks\")\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1e2b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "#tasks = generate_training_tasks(\n",
    "    #data_root=\"/home/ai_dsx.work/data/projects/AD_tool_test/images\",\n",
    "    #normal_dir=\"good\",\n",
    "    #abnormal_dir=\"bad\",\n",
    "    #class_name=\"test_hyperparam\",\n",
    "    #output_base=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/multinode_results\"\n",
    "#)\n",
    "#tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "57682400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: true\n",
    "def test_generate_training_tasks():\n",
    "    \"\"\"Test the generate_training_tasks function with various parameter combinations.\"\"\"\n",
    "    from fastcore.test import test_eq, test_ne, test\n",
    "    import tempfile\n",
    "    \n",
    "    # Create a temporary directory for testing\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        \n",
    "        # Test basic functionality\n",
    "        tasks = generate_training_tasks(\n",
    "            data_root=temp_dir,\n",
    "            normal_dir=\"good\",\n",
    "            abnormal_dir=\"bad\",\n",
    "            class_name=\"test_hyperparam\",\n",
    "            output_base=None  # Should auto-generate path\n",
    "        )\n",
    "        \n",
    "        # Test that we get the expected number of tasks (default parameters)\n",
    "        # Default: 1 model * 1 backbone * 2 n_features * 2 layer combinations = 4 tasks\n",
    "        test_eq(len(tasks), 4)\n",
    "        \n",
    "        # Test task structure\n",
    "        first_task = tasks[0]\n",
    "        required_keys = ['task_id', 'index', 'model_name', 'backbone', 'n_features', \n",
    "                        'layers', 'data_root', 'normal_dir', 'abnormal_dir', \n",
    "                        'class_name', 'max_epochs', 'output_folder', 'save_path', \n",
    "                        'task_output_base']\n",
    "        \n",
    "        for key in required_keys:\n",
    "            assert key in first_task, f\"Task should contain '{key}' key\"\n",
    "        \n",
    "        # Test unique task IDs\n",
    "        task_ids = [task['task_id'] for task in tasks]\n",
    "        test_eq(len(task_ids), len(set(task_ids)))\n",
    "        \n",
    "        # Test index sequence\n",
    "        indices = [task['index'] for task in tasks]\n",
    "        test_eq(indices, list(range(len(tasks))))\n",
    "        \n",
    "        # Test with custom parameters\n",
    "        custom_tasks = generate_training_tasks(\n",
    "            data_root=temp_dir,\n",
    "            normal_dir=\"normal\",\n",
    "            abnormal_dir=\"anomaly\", \n",
    "            class_name=\"custom_test\",\n",
    "            model_names=['padim'],\n",
    "            backbones=['resnet18'],\n",
    "            n_features_list=[32],\n",
    "            layers=[['layer1']],\n",
    "            max_epochs=5\n",
    "        )\n",
    "        \n",
    "        test_eq(len(custom_tasks), 1)\n",
    "        test_eq(custom_tasks[0]['normal_dir'], \"normal\")\n",
    "        test_eq(custom_tasks[0]['abnormal_dir'], \"anomaly\")\n",
    "        test_eq(custom_tasks[0]['max_epochs'], 5)\n",
    "        print(\"âœ… All tests passed for generate_training_tasks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29e6e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test\n",
    "#test_generate_training_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8701d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82577fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b23b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_lsf_config(\n",
    "    session_name: str,  # Session name for identification\n",
    "    tasks: List[Dict[str, Any]],  # Tasks generated by generate_training_tasks\n",
    "    output_dir: Union[str, Path],  # Directory for LSF files\n",
    "    \n",
    "    # LSF Worker Configuration\n",
    "    worker_ui: str = \"python\",        # User interface (e.g., \"python\", \"R\")\n",
    "    worker_um: str = \"background\",    # User mode \n",
    "    threads_per_task: int = 1,        # Threads per task\n",
    "    mem_per_task: int = 8000,         # Memory per task (MB)\n",
    "    os_constraint: str = \"(LINUX80)\", # OS constraint\n",
    "    tasks_per_worker: int = 1,        # Tasks per worker (usually 1 for training)\n",
    "    num_workers: int = None,          # Number of workers (auto-calculated if None)\n",
    "    \n",
    "    # Session Configuration\n",
    "    keep_running: int = 0,            # Keep controller running after tasks\n",
    "    linger_time: int = 300,           # Time to keep workers alive for dynamic imports\n",
    "    \n",
    ") -> Tuple[Path, Path, Path]:\n",
    "    \"\"\"\n",
    "    Create LSF configuration files for multi-node training session.\n",
    "    \n",
    "    This function creates the LSF configuration file but does NOT create the task file\n",
    "    or connection file. The task file needs to be created separately using create_task_file()\n",
    "    function. The connection file is created automatically by LSF when the session starts.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (config_file_path, task_file_path, connection_file_path)\n",
    "        Note: Only config_file_path actually exists after this function runs\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Calculate number of workers if not specified\n",
    "    if num_workers is None:\n",
    "        num_workers = min(len(tasks), 50)  # Max 50 workers by default\n",
    "    \n",
    "    print(f\"ğŸ”§ Creating LSF configuration for {len(tasks)} tasks\")\n",
    "    print(f\"ğŸ‘¥ Workers: {num_workers}\")\n",
    "    print(f\"ğŸ“‹ Tasks per worker: {tasks_per_worker}\")\n",
    "    print(f\"ğŸ’¾ Memory per task: {mem_per_task}MB\")\n",
    "    \n",
    "    # Define file paths (but only create config file in this function)\n",
    "    config_file = output_dir / f\"{session_name}_session.cfg\"\n",
    "    task_file = output_dir / f\"{session_name}_tasks.txt\"\n",
    "    connection_file = output_dir / f\"{session_name}_connection.file\"\n",
    "    \n",
    "    # Generate LSF configuration\n",
    "    config = configparser.ConfigParser()\n",
    "    config.optionxform = str  # Preserve case\n",
    "    \n",
    "    # Common section\n",
    "    config['COMMON'] = {\n",
    "        'connection_file': str(connection_file),\n",
    "        'session_name': f'\"{session_name}\"'\n",
    "    }\n",
    "    \n",
    "    # Controller section\n",
    "    config['CONTROLLER'] = {\n",
    "        'keep_running': str(keep_running)\n",
    "    }\n",
    "    \n",
    "    # Worker section\n",
    "    worker_name = f\"{session_name}_worker\"\n",
    "    config[f'WORKER {worker_name}'] = {\n",
    "        'tasks': str(tasks_per_worker),\n",
    "        'workload': f'{session_name}_workload',\n",
    "        'linger_time': str(linger_time)\n",
    "    }\n",
    "    \n",
    "    # Workload section\n",
    "    config[f'WORKLOAD {session_name}_workload'] = {\n",
    "        'input_file': str(task_file),\n",
    "        'worker_ui': worker_ui,\n",
    "        'worker_um': worker_um,\n",
    "        'threads_per_task': str(threads_per_task),\n",
    "        'mem_per_task': str(mem_per_task),\n",
    "        'os': os_constraint\n",
    "    }\n",
    "    \n",
    "    # Schedule section\n",
    "    config['SCHEDULE _startup_'] = {\n",
    "        'workloads': f'({session_name}_workload)',\n",
    "        'workers': f'({worker_name}={num_workers})'\n",
    "    }\n",
    "    \n",
    "    # Write ONLY the configuration file\n",
    "    with open(config_file, 'w') as f:\n",
    "        config.write(f, space_around_delimiters=False)\n",
    "    \n",
    "    print(f\"âœ… Configuration saved: {config_file}\")\n",
    "    print(f\"ğŸ“ Task file path (not created yet): {task_file}\")\n",
    "    print(f\"ğŸ”— Connection file path (created by LSF): {connection_file}\")\n",
    "    print(f\"âš ï¸  Note: Use create_task_file() to create the actual task file\")\n",
    "    \n",
    "    return config_file, task_file, connection_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4866b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_file, task_file, connection_file = create_lsf_config(\n",
    "    #session_name=\"test_session\",\n",
    "    #tasks=tasks,\n",
    "    #output_dir=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/multinode_results\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b42e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7342eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_task_file(\n",
    "    tasks: List[Dict[str, Any]],  # Tasks generated by generate_training_tasks\n",
    "    task_file_path: Union[str, Path],  # Path to task file\n",
    "    training_script_path: Union[str, Path],  # Path to training script\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Create task file for LSF workload containing all training commands.\n",
    "    \n",
    "    Each line in the task file represents one training job that will be\n",
    "    executed by an LSF worker.\n",
    "    \"\"\"\n",
    "    \n",
    "    task_file_path = Path(task_file_path)\n",
    "    training_script_path = Path(training_script_path)\n",
    "    \n",
    "    print(f\"ğŸ“ Creating task file with {len(tasks)} training tasks\")\n",
    "    \n",
    "    # Generate task commands\n",
    "    task_commands = []\n",
    "    for task in tasks:\n",
    "        # Convert task to JSON string (properly escaped for shell)\n",
    "        task_json = json.dumps(task)\n",
    "        # Escape quotes for shell\n",
    "        task_json_escaped = task_json.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Create command line for this task\n",
    "        command = f'{training_script_path} \"{task_json_escaped}\"'\n",
    "        task_commands.append(command)\n",
    "    \n",
    "    # Write task file\n",
    "    with open(task_file_path, 'w') as f:\n",
    "        for command in task_commands:\n",
    "            f.write(command + '\\n')\n",
    "    \n",
    "    print(f\"âœ… Task file created: {task_file_path}\")\n",
    "    print(f\"ğŸ“‹ Contains {len(task_commands)} training commands\")\n",
    "    \n",
    "    return task_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444ef55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "987cc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_training_script(\n",
    "    script_path: Union[str, Path],  # Path where to save the training script\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Create a Python training script that can be executed by LSF workers.\n",
    "    \"\"\"\n",
    "    \n",
    "    script_path = Path(script_path)\n",
    "    script_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    script_content = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Multi-node training script for BE Vision AD Tools\n",
    "Executed by LSF workers with task parameters as JSON argument\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('/home/ai_dsx.work/data/projects/cv_tools')\n",
    "sys.path.append('/home/ai_warstein/homes/goni/custom_libs')\n",
    "sys.path.append('/home/ai_dsx.work/data/projects/be-vision-ad-tools')\n",
    "\n",
    "from be_vision_ad_tools.training.flexible_trainer import (\n",
    "    FlexibleTrainingConfig, train_anomaly_model, ModelType, BackboneType\n",
    ")\n",
    "\n",
    "def execute_single_training_task(task_json_str):\n",
    "    \"\"\"Execute a single training task from JSON parameters\"\"\"\n",
    "    \n",
    "    # Parse task parameters\n",
    "    task = json.loads(task_json_str)\n",
    "    \n",
    "    print(f'ğŸš€ Starting task: {task[\"task_id\"]}')\n",
    "    print(f'ğŸ“¦ Model: {task[\"model_name\"]} + {task[\"backbone\"]}')\n",
    "    print(f'ğŸ”¢ Features: {task[\"n_features\"]}, Layers: {task[\"layers\"]}')\n",
    "    print(f'ğŸ“ Output: {task[\"task_output_base\"]}')\n",
    "    \n",
    "    try:\n",
    "        # Create output directories\n",
    "        Path(task['output_folder']).mkdir(parents=True, exist_ok=True)\n",
    "        Path(task['save_path']).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create training configuration\n",
    "        config = FlexibleTrainingConfig(\n",
    "            data_root=task['data_root'],\n",
    "            normal_dir=task['normal_dir'],\n",
    "            abnormal_dir=task['abnormal_dir'],\n",
    "            model_name=task['model_name'],\n",
    "            backbone=task['backbone'],\n",
    "            layers=task['layers'],\n",
    "            n_features=task['n_features'],\n",
    "            max_epochs=task['max_epochs'],\n",
    "            class_name=task['class_name'],\n",
    "            save_path=task['save_path']\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        print(f'ğŸ¯ Training {task[\"model_name\"]} model...')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        result = train_anomaly_model(config)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        if result and result.get('success', False):\n",
    "            # Save detailed results\n",
    "            task_result = {\n",
    "                'task_id': task['task_id'],\n",
    "                'success': True,\n",
    "                'model_name': task['model_name'],\n",
    "                'backbone': task['backbone'],\n",
    "                'n_features': task['n_features'],\n",
    "                'layers': task['layers'],\n",
    "                'training_time_seconds': training_time,\n",
    "                'model_path': result.get('model_path'),\n",
    "                'config_used': task,\n",
    "                'training_results': result,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Save result to JSON file\n",
    "            result_file = Path(task['task_output_base']) / 'task_result.json'\n",
    "            with open(result_file, 'w') as f:\n",
    "                json.dump(task_result, f, indent=2, default=str)\n",
    "            \n",
    "            print(f'âœ… Task {task[\"task_id\"]} completed successfully in {training_time:.1f}s')\n",
    "            print(f'ğŸ’¾ Results saved: {result_file}')\n",
    "            \n",
    "        else:\n",
    "            raise Exception('Training failed - no success result returned')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Task {task[\"task_id\"]} failed: {str(e)}')\n",
    "        \n",
    "        # Save error result\n",
    "        error_result = {\n",
    "            'task_id': task['task_id'],\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'config_used': task,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        error_file = Path(task['task_output_base']) / 'task_error.json'\n",
    "        error_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(error_file, 'w') as f:\n",
    "            json.dump(error_result, f, indent=2, default=str)\n",
    "        \n",
    "        raise  # Re-raise to signal failure to LSF\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python training_script.py <task_json>\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    task_json = sys.argv[1]\n",
    "    execute_single_training_task(task_json)\n",
    "'''\n",
    "    \n",
    "    # Write the script\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    # Make it executable\n",
    "    script_path.chmod(0o755)\n",
    "    \n",
    "    print(f\"âœ… Training script created: {script_path}\")\n",
    "    return script_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eaad28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = '/home/ai_dsx.work/data/projects/AD_tool_test/images/multinode_results/py_script.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_script(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "469a6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#create_task_file(\n",
    "    #tasks=tasks,\n",
    "    #task_file_path=task_file,\n",
    "    #training_script_path=script_path\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d744f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "data_root = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/images')\n",
    "normal_dir = \"good\"\n",
    "abnormal_dir = \"bad\"\n",
    "class_name = \"test_hyperparam\"\n",
    "time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "output_base = Path(data_root / f'multinode_results_{time_str}')\n",
    "Path(output_base).mkdir(parents=True, exist_ok=True)\n",
    "model_names = ['padim']\n",
    "backbones = ['wide_resnet50_2']\n",
    "n_features_list = [64]\n",
    "layers = [['layer1','layer2', 'layer3'],['layer1','layer2']]\n",
    "max_epochs = 10\n",
    "\n",
    "# part 1\n",
    "\n",
    "tasks = generate_training_tasks(\n",
    "        data_root=data_root,\n",
    "        normal_dir=normal_dir,\n",
    "        abnormal_dir=abnormal_dir,\n",
    "        class_name=class_name,\n",
    "        model_names=model_names,\n",
    "        backbones=backbones,\n",
    "        n_features_list=n_features_list,\n",
    "        layers=layers,\n",
    "        max_epochs=max_epochs,\n",
    "        output_base=output_base\n",
    "    )\n",
    "# part 2\n",
    "session_name =f\"anomaly_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "lsf_dir = output_base / 'lsf_files'\n",
    "mem_per_task = 8000\n",
    "num_workers = None\n",
    "config_file, task_file, connection_file = create_lsf_config(\n",
    "        session_name=session_name,\n",
    "        tasks=tasks,\n",
    "        output_dir=lsf_dir,\n",
    "        mem_per_task=mem_per_task,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "# part 3\n",
    "training_script = create_training_script(\n",
    "    script_path=lsf_dir / 'multinode_training.py'\n",
    ")\n",
    "\n",
    "# part 4\n",
    "task_file_path = create_task_file(\n",
    "    tasks=tasks,\n",
    "    task_file_path=task_file,\n",
    "    training_script_path=training_script\n",
    ")\n",
    "print(task_file_path)\n",
    "# part 5\n",
    "\n",
    "cmd = f\"lsf_tflex --session {config_file}\"\n",
    "print(f\"Executing: {cmd}\")\n",
    "result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… LSF session submitted successfully!\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"âŒ Failed to submit LSF session:\")\n",
    "    print(result.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86194fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53343773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Create output directories\n",
    "Path(task['output_folder']).mkdir(parents=True, exist_ok=True)\n",
    "Path(task['save_path']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create training configuration\n",
    "config = FlexibleTrainingConfig(\n",
    "    data_root=task['data_root'],\n",
    "    normal_dir=task['normal_dir'],\n",
    "    abnormal_dir=task['abnormal_dir'],\n",
    "    model_name=task['model_name'],\n",
    "    backbone=task['backbone'],\n",
    "    layers=task['layers'],\n",
    "    n_features=task['n_features'],\n",
    "    max_epochs=task['max_epochs'],\n",
    "    class_name=task['class_name'],\n",
    "    save_path=task['save_path']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(f'ğŸ¯ Training {task[\"model_name\"]} model...')\n",
    "start_time = time.time()\n",
    "\n",
    "result = train_anomaly_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20f9c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def collect_training_results(\n",
    "    output_base: Union[str, Path],  # Base directory containing task results\n",
    "    wait_for_completion: bool = True,  # Wait for all tasks to complete\n",
    "    max_wait_time: int = 3600,         # Maximum wait time in seconds\n",
    "    check_interval: int = 30,          # Check interval in seconds\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Collect and combine results from all distributed training tasks.\n",
    "    \n",
    "    This function monitors the output directory and waits for all tasks\n",
    "    to complete, then combines their results into a unified format.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_base = Path(output_base)\n",
    "    \n",
    "    print(f\"ğŸ“Š Collecting training results from: {output_base}\")\n",
    "    \n",
    "    if wait_for_completion:\n",
    "        print(f\"â³ Waiting for training completion (max {max_wait_time}s)...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            # Find all task directories\n",
    "            task_dirs = [d for d in output_base.iterdir() if d.is_dir() and d.name.startswith('task_')]\n",
    "            \n",
    "            # Check completion status\n",
    "            completed_tasks = []\n",
    "            failed_tasks = []\n",
    "            pending_tasks = []\n",
    "            \n",
    "            for task_dir in task_dirs:\n",
    "                result_file = task_dir / 'task_result.json'\n",
    "                error_file = task_dir / 'task_error.json'\n",
    "                \n",
    "                if result_file.exists():\n",
    "                    completed_tasks.append(task_dir)\n",
    "                elif error_file.exists():\n",
    "                    failed_tasks.append(task_dir)\n",
    "                else:\n",
    "                    pending_tasks.append(task_dir)\n",
    "            \n",
    "            total_tasks = len(task_dirs)\n",
    "            completed_count = len(completed_tasks)\n",
    "            failed_count = len(failed_tasks)\n",
    "            pending_count = len(pending_tasks)\n",
    "            \n",
    "            print(f\"ğŸ“ˆ Progress: {completed_count}/{total_tasks} completed, \"\n",
    "                  f\"{failed_count} failed, {pending_count} pending\")\n",
    "            \n",
    "            # Check if all tasks are done\n",
    "            if pending_count == 0:\n",
    "                print(\"âœ… All tasks completed!\")\n",
    "                break\n",
    "            \n",
    "            # Check timeout\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed > max_wait_time:\n",
    "                print(f\"â° Timeout reached ({max_wait_time}s). Collecting available results...\")\n",
    "                break\n",
    "            \n",
    "            # Wait before next check\n",
    "            time.sleep(check_interval)\n",
    "    \n",
    "    # Collect all results\n",
    "    print(\"ğŸ“‹ Collecting all available results...\")\n",
    "    \n",
    "    all_results = []\n",
    "    successful_trainings = 0\n",
    "    failed_trainings = 0\n",
    "    \n",
    "    task_dirs = [d for d in output_base.iterdir() if d.is_dir() and d.name.startswith('task_')]\n",
    "    \n",
    "    for task_dir in task_dirs:\n",
    "        result_file = task_dir / 'task_result.json'\n",
    "        error_file = task_dir / 'task_error.json'\n",
    "        \n",
    "        if result_file.exists():\n",
    "            try:\n",
    "                with open(result_file, 'r') as f:\n",
    "                    result = json.load(f)\n",
    "                all_results.append(result)\n",
    "                successful_trainings += 1\n",
    "                print(f\"âœ… {result['task_id']}: {result['training_time_seconds']:.1f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading {result_file}: {e}\")\n",
    "                failed_trainings += 1\n",
    "                \n",
    "        elif error_file.exists():\n",
    "            try:\n",
    "                with open(error_file, 'r') as f:\n",
    "                    error_result = json.load(f)\n",
    "                all_results.append(error_result)\n",
    "                failed_trainings += 1\n",
    "                print(f\"âŒ {error_result['task_id']}: {error_result.get('error', 'Unknown error')}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading {error_file}: {e}\")\n",
    "                failed_trainings += 1\n",
    "        else:\n",
    "            print(f\"â³ {task_dir.name}: No result file found\")\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    total_tasks = len(task_dirs)\n",
    "    success_rate = (successful_trainings / total_tasks * 100) if total_tasks > 0 else 0\n",
    "    \n",
    "    # Get successful results only\n",
    "    successful_results = [r for r in all_results if r.get('success', False)]\n",
    "    \n",
    "    # Calculate timing statistics\n",
    "    if successful_results:\n",
    "        training_times = [r['training_time_seconds'] for r in successful_results]\n",
    "        avg_time = sum(training_times) / len(training_times)\n",
    "        total_training_time = sum(training_times)\n",
    "    else:\n",
    "        avg_time = 0\n",
    "        total_training_time = 0\n",
    "    \n",
    "    # Create combined results in the same format as simple_hyperparameter_search\n",
    "    combined_results = {\n",
    "        'search_completed': True,\n",
    "        'total_combinations_tested': total_tasks,\n",
    "        'successful_trainings': successful_trainings,\n",
    "        'failed_trainings': failed_trainings,\n",
    "        'success_rate': success_rate,\n",
    "        'average_training_time': avg_time,\n",
    "        'total_training_time': total_training_time,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'results': all_results,\n",
    "        'successful_results': successful_results,\n",
    "        'output_base': str(output_base)\n",
    "    }\n",
    "    \n",
    "    # Save combined results\n",
    "    summary_file = output_base / 'multinode_training_summary.json'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(combined_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ğŸ“Š MULTI-NODE TRAINING RESULTS SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"âœ… Successful trainings: {successful_trainings}/{total_tasks}\")\n",
    "    print(f\"âŒ Failed trainings: {failed_trainings}/{total_tasks}\")\n",
    "    print(f\"ğŸ“ˆ Success rate: {success_rate:.1f}%\")\n",
    "    if successful_trainings > 0:\n",
    "        print(f\"â±ï¸  Average training time: {avg_time:.1f}s\")\n",
    "        print(f\"â±ï¸  Total training time: {total_training_time:.1f}s\")\n",
    "    print(f\"ğŸ’¾ Summary saved: {summary_file}\")\n",
    "    \n",
    "    return combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b352c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data_root = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/images')\n",
    "normal_dir = \"good\"\n",
    "abnormal_dir = \"bad\"\n",
    "class_name = \"test_hyperparam\"\n",
    "output_base = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/images/multinode_results')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c8130",
   "metadata": {},
   "source": [
    "##### Collect training results after training completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea923870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "task_dirs = [d for d in Path(output_base).iterdir() if d.is_dir() and d.name.startswith('task_')]\n",
    "sn_task = task_dirs[0]\n",
    "print(sn_task)\n",
    "result_file = sn_task / 'task_result.json'\n",
    "error_file = sn_task / 'task_error.json'\n",
    "result_file.exists()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dd1340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_base=\"/home/ai_dsx.work/data/projects/AD_tool_test/multi_node_results\"\n",
    "#max_wait_time=3600\n",
    "#check_interval=30\n",
    "#trn_res = collect_training_results(\n",
    "    #output_base=output_base,\n",
    "    #wait_for_completion=True,\n",
    "    #max_wait_time=max_wait_time,\n",
    "    #check_interval=check_interval\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae97de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_images='/home/ai_dsx.work/data/projects/AD_tool_test/images/bad'\n",
    "search_results=trn_res['results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f9b726e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def multinode_diff_parameter_and_save_poster(\n",
    "    data_root: Union[str, Path],  # Data root path\n",
    "    normal_dir: str = \"good\",     # Normal directory name\n",
    "    abnormal_dir: str = \"bad\",    # Abnormal directory name\n",
    "    class_name: str = \"multinode_search\",  # Class name\n",
    "    test_images: Union[str, Path, List] = None,  # Test images path\n",
    "    \n",
    "    # Parameter combinations for grid search\n",
    "    model_names: List[str] = None,        # Model names\n",
    "    backbones: List[str] = None,          # Backbones\n",
    "    n_features_list: List[int] = None,    # Number of features\n",
    "    layers: List[List[str]] = None,       # Layers\n",
    "    max_epochs: int = 10,                 # Max epochs\n",
    "    \n",
    "    # Multi-node configuration\n",
    "    session_name: str = None,             # LSF session name\n",
    "    num_workers: int = None,              # Number of LSF workers\n",
    "    mem_per_task: int = 8000,             # Memory per task (MB)\n",
    "    \n",
    "    # Output settings\n",
    "    output_base: Union[str, Path] = None, # Base output directory\n",
    "    max_models: int = 4,                  # Max models in poster\n",
    "    max_test_images: int = 10,            # Max test images\n",
    "    run_validation_tests: bool = False,   # Run validation tests\n",
    "    show_original: bool = False,          # Show original images\n",
    "    device: str = \"auto\",                 # Device for inference\n",
    "    \n",
    "    # Advanced settings\n",
    "    wait_for_completion: bool = True,     # Wait for all tasks to complete\n",
    "    max_wait_time: int = 3600,            # Maximum wait time\n",
    "    auto_submit: bool = True,            # Automatically submit LSF jobs\n",
    "    \n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Multi-node version of diff_parameter_and_save_poster.\n",
    "    \n",
    "    This function distributes hyperparameter search across multiple nodes\n",
    "    using LSF, then combines results and creates comparison posters.\n",
    "    \n",
    "    ğŸš€ WORKFLOW:\n",
    "    1. Generate parameter combinations as individual tasks\n",
    "    2. Create LSF configuration and task files\n",
    "    3. Create training script for workers\n",
    "    4. Submit jobs to LSF (if auto_submit=True)\n",
    "    5. Wait for completion and collect results\n",
    "    6. Generate comparison poster from combined results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ MULTI-NODE HYPERPARAMETER SEARCH\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ¯ Distributing training across multiple LSF nodes\")\n",
    "    print(\"ğŸ—ï¸ Using lsf_tflex for workload management\")\n",
    "    \n",
    "    # Set defaults\n",
    "    data_root = Path(data_root)\n",
    "    if output_base is None:\n",
    "        output_base = data_root / f'multinode_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "    if session_name is None:\n",
    "        session_name = f\"anomaly_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    if test_images is None:\n",
    "        test_images = data_root / \"test\"  # Default test directory\n",
    "    \n",
    "    output_base = Path(output_base)\n",
    "    lsf_dir = output_base / 'lsf_files'\n",
    "    \n",
    "    # STEP 1: Generate training tasks\n",
    "    print(f\"\\nğŸ“‹ STEP 1: Generating training tasks\")\n",
    "    tasks = generate_training_tasks(\n",
    "        data_root=data_root,\n",
    "        normal_dir=normal_dir,\n",
    "        abnormal_dir=abnormal_dir,\n",
    "        class_name=class_name,\n",
    "        model_names=model_names,\n",
    "        backbones=backbones,\n",
    "        n_features_list=n_features_list,\n",
    "        layers=layers,\n",
    "        max_epochs=max_epochs,\n",
    "        output_base=output_base\n",
    "    )\n",
    "    \n",
    "    # STEP 2: Create LSF configuration\n",
    "    print(f\"\\nğŸ”§ STEP 2: Creating LSF configuration\")\n",
    "    config_file, task_file, connection_file = create_lsf_config(\n",
    "        session_name=session_name,\n",
    "        tasks=tasks,\n",
    "        output_dir=lsf_dir,\n",
    "        mem_per_task=mem_per_task,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # STEP 3: Create training script\n",
    "    print(f\"\\nğŸ“ STEP 3: Creating training script\")\n",
    "    training_script = create_training_script(\n",
    "        script_path=lsf_dir / 'multinode_training.py'\n",
    "    )\n",
    "    \n",
    "    # STEP 4: Create task file\n",
    "    print(f\"\\nğŸ“‹ STEP 4: Creating task file\")\n",
    "    task_file_path = create_task_file(\n",
    "        tasks=tasks,\n",
    "        task_file_path=task_file,\n",
    "        training_script_path=training_script\n",
    "    )\n",
    "    \n",
    "    # STEP 5: Provide instructions or auto-submit\n",
    "    print(f\"\\nğŸ¯ STEP 5: Job submission\")\n",
    "    if auto_submit:\n",
    "        print(\"ğŸš€ Auto-submitting LSF jobs...\")\n",
    "        try:\n",
    "            # Submit the LSF session\n",
    "            cmd = f\"lsf_tflex --session {config_file}\"\n",
    "            print(f\"Executing: {cmd}\")\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"âœ… LSF session submitted successfully!\")\n",
    "                print(result.stdout)\n",
    "            else:\n",
    "                print(\"âŒ Failed to submit LSF session:\")\n",
    "                print(result.stderr)\n",
    "                return {'success': False, 'error': result.stderr}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error submitting jobs: {e}\")\n",
    "            return {'success': False, 'error': str(e)}\n",
    "    else:\n",
    "        print(\"ğŸ“‹ Manual submission required. Run these commands:\")\n",
    "        print(f\"   cd {lsf_dir}\")\n",
    "        print(f\"   lsf_tflex --session {config_file}\")\n",
    "        print(f\"   # Monitor with: lsf_tflex --session {config_file} --status\")\n",
    "        \n",
    "        if not wait_for_completion:\n",
    "            return {\n",
    "                'success': True,\n",
    "                'config_file': str(config_file),\n",
    "                'task_file': str(task_file),\n",
    "                'training_script': str(training_script),\n",
    "                'output_base': str(output_base),\n",
    "                'session_name': session_name,\n",
    "                'total_tasks': len(tasks)\n",
    "            }\n",
    "    \n",
    "    # STEP 6: Wait for completion and collect results\n",
    "    print(f\"\\nğŸ“Š STEP 6: Collecting results\")\n",
    "    combined_results = collect_training_results(\n",
    "        output_base=output_base,\n",
    "        wait_for_completion=wait_for_completion,\n",
    "        max_wait_time=max_wait_time\n",
    "    )\n",
    "    \n",
    "    # STEP 7: Create comparison poster\n",
    "    print(f\"\\nğŸ¨ STEP 7: Creating comparison poster\")\n",
    "    if combined_results['successful_trainings'] > 0:\n",
    "        try:\n",
    "            # Generate output filename\n",
    "            output_file = output_base / f\"multinode_comparison_poster_{session_name}.png\"\n",
    "            \n",
    "            comparison_res = create_modular_batch_comparison_poster(\n",
    "                search_results=combined_results,\n",
    "                test_images=test_images,\n",
    "                max_models=max_models,\n",
    "                max_test_images=max_test_images,\n",
    "                run_validation_tests=run_validation_tests,\n",
    "                show_original=show_original,\n",
    "                device=device,\n",
    "                output_file=str(output_file)\n",
    "            )\n",
    "            \n",
    "            if comparison_res['success']:\n",
    "                print(f\"âœ… Comparison poster created: {output_file}\")\n",
    "                stats = comparison_res['batch_statistics']\n",
    "                print(f\"âš¡ {stats['total_inference_time']:.1f}s total inference time\")\n",
    "                \n",
    "                # Combine all results\n",
    "                final_results = {\n",
    "                    'success': True,\n",
    "                    'session_name': session_name,\n",
    "                    'training_results': combined_results,\n",
    "                    'poster_results': comparison_res,\n",
    "                    'poster_file': str(output_file),\n",
    "                    'config_files': {\n",
    "                        'lsf_config': str(config_file),\n",
    "                        'task_file': str(task_file),\n",
    "                        'training_script': str(training_script)\n",
    "                    },\n",
    "                    'total_tasks': len(tasks),\n",
    "                    'output_base': str(output_base)\n",
    "                }\n",
    "                \n",
    "                return final_results\n",
    "            else:\n",
    "                print(\"âŒ Failed to create comparison poster\")\n",
    "                return {'success': False, 'error': 'Poster creation failed'}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating poster: {e}\")\n",
    "            return {'success': False, 'error': str(e)}\n",
    "    else:\n",
    "        print(\"âŒ No successful training results to create poster from\")\n",
    "        return {'success': False, 'error': 'No successful training results'}\n",
    "    \n",
    "    print(f\"\\nğŸ‰ MULTI-NODE TRAINING COMPLETE!\")\n",
    "    return {'success': True, 'training_results': combined_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78343fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_layers_argument(layers_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse layer string into list of layer names.\n",
    "    \n",
    "    Examples:\n",
    "        \"layer1\" -> [\"layer1\"]\n",
    "        \"layer1,layer2\" -> [\"layer1\", \"layer2\"]\n",
    "        \"layer1,layer2,layer3\" -> [\"layer1\", \"layer2\", \"layer3\"]\n",
    "    \"\"\"\n",
    "    return [layer.strip() for layer in layers_str.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7ec8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_configuration_summary(args):\n",
    "    \"\"\"Print a summary of the training configuration\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ MULTI-NODE TRAINING CONFIGURATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ Data Root: {args.data_root}\")\n",
    "    print(f\"âœ… Normal Dir: {args.normal_dir}\")\n",
    "    print(f\"âŒ Abnormal Dir: {args.abnormal_dir}\")\n",
    "    print(f\"ğŸ·ï¸  Class Name: {args.class_name}\")\n",
    "    print(f\"ğŸ§ª Test Images: {args.test_images or 'Auto-detect'}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ğŸ¤– MODEL CONFIGURATION:\")\n",
    "    print(f\"   Models: {args.model_names}\")\n",
    "    print(f\"   Backbones: {args.backbones}\")\n",
    "    print(f\"   Features: {args.n_features_list}\")\n",
    "    print(f\"   Layers: {args.layers}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate total combinations\n",
    "    total_combinations = (len(args.model_names) * \n",
    "                         len(args.backbones) * \n",
    "                         len(args.n_features_list) * \n",
    "                         len(args.layers))\n",
    "    \n",
    "    print(\"ğŸ“Š TRAINING SCALE:\")\n",
    "    print(f\"   Total Combinations: {total_combinations}\")\n",
    "    print(f\"   Max Epochs: {args.max_epochs}\")\n",
    "    print(f\"   LSF Workers: {args.num_workers}\")\n",
    "    print(f\"   Memory per Task: {args.mem_per_task} MB\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ğŸ“‚ OUTPUT CONFIGURATION:\")\n",
    "    print(f\"   Output Base: {args.output_base or '<data_root>/multinode_results'}\")\n",
    "    print(f\"   Session Name: {args.session_name or 'Auto-generated'}\")\n",
    "    print(f\"   Max Models in Poster: {args.max_models}\")\n",
    "    print(f\"   Max Test Images: {args.max_test_images}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"âš™ï¸  EXECUTION FLAGS:\")\n",
    "    print(f\"   Auto Submit: {args.auto_submit}\")\n",
    "    print(f\"   Wait for Completion: {args.wait_for_completion}\")\n",
    "    print(f\"   Run Validation: {args.run_validation}\")\n",
    "    print(f\"   Show Original: {args.show_original}\")\n",
    "    print(f\"   Device: {args.device}\")\n",
    "    print(f\"   Dry Run: {args.dry_run}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26e1ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def validate_arguments(args):\n",
    "    \"\"\"Validate command line arguments\"\"\"\n",
    "    \n",
    "    # Check data root exists\n",
    "    if not Path(args.data_root).exists():\n",
    "        raise ValueError(f\"Data root directory does not exist: {args.data_root}\")\n",
    "    \n",
    "    # Check normal directory exists\n",
    "    normal_path = Path(args.data_root) / args.normal_dir\n",
    "    if not normal_path.exists():\n",
    "        raise ValueError(f\"Normal directory does not exist: {normal_path}\")\n",
    "    \n",
    "    # Check abnormal directory exists  \n",
    "    abnormal_path = Path(args.data_root) / args.abnormal_dir\n",
    "    if not abnormal_path.exists():\n",
    "        raise ValueError(f\"Abnormal directory does not exist: {abnormal_path}\")\n",
    "    \n",
    "    # Validate memory per task\n",
    "    if args.mem_per_task < 1000:\n",
    "        raise ValueError(\"Memory per task should be at least 1000 MB\")\n",
    "    \n",
    "    # Validate number of workers\n",
    "    if args.num_workers < 1:\n",
    "        raise ValueError(\"Number of workers should be at least 1\")\n",
    "    \n",
    "    print(\"âœ… All arguments validated successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63e636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "13fe9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_cli_list(list_str):\n",
    "    \"\"\"\n",
    "    Parse a string into a list, supporting both comma and space separation.\n",
    "    \n",
    "    Examples:\n",
    "        parse_cli_list(\"layer1,layer2,layer3\")     # ['layer1', 'layer2', 'layer3']\n",
    "        parse_cli_list(\"layer1 layer2 layer3\")     # ['layer1', 'layer2', 'layer3']\n",
    "        parse_cli_list(\"layer1\")                   # ['layer1']\n",
    "    \"\"\"\n",
    "    if not list_str: return []\n",
    "    \n",
    "    # If there are commas, split by comma\n",
    "    if ',' in list_str:\n",
    "        return [item.strip() for item in list_str.split(',') if item.strip()]\n",
    "    \n",
    "    # Otherwise split by whitespace\n",
    "    return [item.strip() for item in list_str.split() if item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754bbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c491eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b27279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_cli_nested_lists(\n",
    "    arg_str # \"layer1,layer2;layer3,layer4\"  -> [['layer1', 'layer2'], ['layer3', 'layer4']]\n",
    "    # \"layer1,layer2|layer3,layer4\"  -> [['layer1', 'layer2'], ['layer3', 'layer4']]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Parse a string from command line into nested list structure.\n",
    "    \n",
    "    Supports:\n",
    "    - Semicolon separates lists: \"layer1,layer2;layer3,layer4\"\n",
    "    - Pipe separates lists: \"layer1,layer2|layer3,layer4\"  \n",
    "    - Within each list, comma or space separation works\n",
    "    \n",
    "    \"\"\"\n",
    "    if not arg_str: return []\n",
    "    \n",
    "    # Determine list separator (semicolon or pipe)\n",
    "    list_separator = ';' if ';' in arg_str else '|'\n",
    "    \n",
    "    # Split into individual list strings\n",
    "    list_strings = [s.strip() for s in arg_str.split(list_separator) if s.strip()]\n",
    "    \n",
    "    # Parse each list using the existing parser\n",
    "    return [parse_cli_list(list_str) for list_str in list_strings]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80ba670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_cli_models(\n",
    "    arg_str # \"padim;fastflow|patchcore\"  -> ['padim', 'fastflow', 'patchcore']\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Parse a string from command line into a list of model names.\n",
    "    \n",
    "    Supports:\n",
    "    - Semicolon separates models: \"padim;fastflow;patchcore\"\n",
    "    - Pipe separates models: \"padim|fastflow|patchcore\"\n",
    "    - Returns a flat list of strings for individual model names\n",
    "    \n",
    "    Examples:\n",
    "        parse_cli_models(\"padim;fastflow\")     # ['padim', 'fastflow']\n",
    "        parse_cli_models(\"padim|fastflow\")     # ['padim', 'fastflow']\n",
    "        parse_cli_models(\"padim\")              # ['padim']\n",
    "    \"\"\"\n",
    "    if not arg_str: return []\n",
    "    \n",
    "    # Determine separator (semicolon or pipe)\n",
    "    separator = ';' if ';' in arg_str else '|'\n",
    "    \n",
    "    # Split and clean up model names\n",
    "    return [model.strip() for model in arg_str.split(separator) if model.strip()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92ae3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_cli_numbers(\n",
    "    arg_str # \"64;128|256\"  -> [64, 128, 256]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Parse a string from command line into a list of integers.\n",
    "    \n",
    "    Supports:\n",
    "    - Semicolon separates numbers: \"64;128;256\"\n",
    "    - Pipe separates numbers: \"64|128|256\"\n",
    "    - Comma separates numbers: \"64,128,256\"\n",
    "    - Returns a flat list of integers\n",
    "    \n",
    "    Examples:\n",
    "        parse_cli_numbers(\"64;128\")     # [64, 128]\n",
    "        parse_cli_numbers(\"64|128\")     # [64, 128]\n",
    "        parse_cli_numbers(\"64,128\")     # [64, 128]\n",
    "        parse_cli_numbers(\"64\")         # [64]\n",
    "    \"\"\"\n",
    "    if not arg_str: return []\n",
    "    \n",
    "    # Determine separator (semicolon, pipe, or comma)\n",
    "    separator = ';' if ';' in arg_str else ('|' if '|' in arg_str else ',')\n",
    "    \n",
    "    # Split and convert to integers\n",
    "    return [int(num.strip()) for num in arg_str.split(separator) if num.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f3e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_cli_nested_lists('layer1,layer2;layer1,layer2,layer3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones='wide_resnet50_2;resnet18'\n",
    "parse_cli_models(backbones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "519b6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class MultiNodeConfig:\n",
    "    \"\"\"Configuration class for multi-node training parameters.\"\"\"\n",
    "    data_root: str = 'data_root'\n",
    "    normal_dir: str = 'normal'\n",
    "    abnormal_dir: str = 'abnormal'\n",
    "    class_name: Optional[str] = None\n",
    "    test_images: str = 'test_images'\n",
    "    model_names: str = 'padim'\n",
    "    backbones: str = 'resnet18;wide_resnet50_2'\n",
    "    n_features_list: str = '64;320'\n",
    "    layers: str = \"layer1,layer2;layer1,layer2,layer3\"\n",
    "    max_epochs: int = 100\n",
    "    output_base: str = 'output_base'\n",
    "    max_models: int = 10\n",
    "    max_test_images: int = 100\n",
    "    run_validation: bool = False\n",
    "    show_original: bool = True\n",
    "    device: str = 'auto'\n",
    "    auto_submit: bool = True\n",
    "    wait_for_completion: bool = True\n",
    "    max_wait_time: int = 3600\n",
    "    session_name: Optional[str] = None\n",
    "    num_workers: int = 4\n",
    "    mem_per_task: int = 8000\n",
    "    verbose: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b6116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7e2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8de23403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_config_from_file(\n",
    "    config_path: Union[str, Path]\n",
    "    ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load configuration from JSON, YAML, or INI file.\n",
    "    \n",
    "    \"\"\"\n",
    "    config_path = Path(config_path)\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "    \n",
    "    suffix = config_path.suffix.lower()\n",
    "    \n",
    "    if suffix == '.json':\n",
    "        import json\n",
    "        with open(config_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    elif suffix in ['.yaml', '.yml']:\n",
    "        try:\n",
    "            with open(config_path, 'r') as f:\n",
    "                return yaml.safe_load(f) or {}\n",
    "        except ImportError:\n",
    "            raise ValueError(\"PyYAML is required to load YAML config files. Install with: pip install pyyaml\")\n",
    "    \n",
    "    elif suffix in ['.ini', '.cfg']:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_path)\n",
    "        \n",
    "        # Convert ConfigParser to dictionary\n",
    "        config_dict = {}\n",
    "        for section in config.sections():\n",
    "            for key, value in config[section].items():\n",
    "                # Try to convert to appropriate types\n",
    "                try:\n",
    "                    # Try boolean conversion first\n",
    "                    if value.lower() in ['true', 'false']:\n",
    "                        config_dict[key] = config.getboolean(section, key)\n",
    "                    # Try integer conversion\n",
    "                    elif value.isdigit() or (value.startswith('-') and value[1:].isdigit()):\n",
    "                        config_dict[key] = config.getint(section, key)\n",
    "                    # Keep as string\n",
    "                    else:\n",
    "                        config_dict[key] = value\n",
    "                except ValueError:\n",
    "                    config_dict[key] = value\n",
    "        \n",
    "        return config_dict\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported config file format: {suffix}. Supported formats: .json, .yaml, .yml, .ini, .cfg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2efd199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sample_config_file(\n",
    "    output_path: Union[str, Path], \n",
    "    format_type: str = 'json') -> None:\n",
    "    \"\"\"\n",
    "    Create a sample configuration file with default parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    config = MultiNodeConfig()\n",
    "    config_dict = asdict(config)\n",
    "    \n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    if format_type.lower() == 'json':\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(config_dict, f, indent=2)\n",
    "    \n",
    "    elif format_type.lower() in ['yaml', 'yml']:\n",
    "        try:\n",
    "            with open(output_path, 'w') as f:\n",
    "                yaml.dump(config_dict, f, default_flow_style=False, indent=2)\n",
    "        except ImportError:\n",
    "            raise ValueError(\"PyYAML is required to create YAML config files. Install with: pip install pyyaml\")\n",
    "    \n",
    "    elif format_type.lower() in ['ini', 'cfg']:\n",
    "        config_parser = configparser.ConfigParser()\n",
    "        config_parser['DEFAULT'] = {}\n",
    "        \n",
    "        # Add all config items to DEFAULT section\n",
    "        for key, value in config_dict.items():\n",
    "            config_parser['DEFAULT'][key] = str(value)\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            config_parser.write(f)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported format: {format_type}. Supported formats: json, yaml, ini\")\n",
    "    \n",
    "    print(f\"âœ… Sample config file created: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9307a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85d715e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/sample_multinode_config.yaml')\n",
    "config_file_ = create_sample_config_file(config_path, 'yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#@call_parse\n",
    "def create_multinode_config(\n",
    "    output_path: str, # Path where to save the config file\n",
    "    format: str='json', # Config file format ('json', 'yaml', or 'ini')\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a sample configuration file for multi-node training.\n",
    "    \n",
    "    Examples:\n",
    "        create_multinode_config config.json\n",
    "        create_multinode_config config.yaml --format yaml\n",
    "        create_multinode_config config.ini --format ini\n",
    "    \"\"\"\n",
    "    try:\n",
    "        create_sample_config_file(output_path, format)\n",
    "        print(f\"âœ… Sample configuration file created at: {output_path}\")\n",
    "        print(f\"ğŸ“ Edit this file with your specific parameters, then use:\")\n",
    "        print(f\"   multi_node_train_ --config_file {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating config file: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5ce08",
   "metadata": {},
   "source": [
    "## Testing Config File Functionality\n",
    "\n",
    "Let's test the new config file support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def multi_node_train_with_config_precedence(\n",
    "    # Config file support\n",
    "    config_file: str = None,  # Path to configuration file (JSON, YAML, or INI format)\n",
    "    \n",
    "    # Original parameters with special sentinel values to detect CLI usage\n",
    "    data_root: str = None,  # Path to the dataset root directory\n",
    "    normal_dir: str = None,  # Path to the normal class directory\n",
    "    abnormal_dir: str = None,  # Path to the abnormal class directory\n",
    "    class_name: str = None,  # Name of the class to train on\n",
    "    test_images: str = None,  # Path to the test images directory\n",
    "    model_names: str = None,  # List of model names to train\n",
    "    backbones: str = None,  # List of backbone architectures to use\n",
    "    n_features_list: str = None,  # List of feature dimensions to use\n",
    "    layers: str = None,  # List of layers\n",
    "    max_epochs: int = None,  # Maximum number of training epochs\n",
    "    output_base: str = None,  # Base directory for output files\n",
    "    max_models: int = None,  # Maximum number of models to include in the poster\n",
    "    max_test_images: int = None,  # Maximum number of test images to include in the poster\n",
    "    run_validation: bool = None,  # Run validation tests after training\n",
    "    show_original: bool = None,  # Show original images in the poster\n",
    "    device: str = None,  # Device to use for training\n",
    "    auto_submit: bool = None,  # Automatically submit jobs to LSF\n",
    "    wait_for_completion: bool = None,  # Wait for jobs to complete\n",
    "    max_wait_time: int = None,  # Maximum wait time for job completion\n",
    "    session_name: str = None,  # Name of the LSF session\n",
    "    num_workers: int = None,  # Number of workers per task\n",
    "    mem_per_task: int = None,  # Memory per task (in MB)\n",
    "    verbose: bool = False,  # Enable verbose output\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-node training with proper config file precedence using fastcore's call_parse.\n",
    "    \n",
    "    Precedence order (highest to lowest):\n",
    "    1. CLI arguments (explicitly provided by user)\n",
    "    2. Config file values\n",
    "    3. Built-in defaults\n",
    "    \n",
    "    Examples:\n",
    "        # Using config file only\n",
    "        multi_node_train --config_file config.json\n",
    "        \n",
    "        # Using config file with CLI overrides  \n",
    "        multi_node_train --config_file config.json --max_epochs 200 --device cuda\n",
    "        \n",
    "        # Traditional usage (backward compatible)\n",
    "        multi_node_train --data_root /path/to/data --model_names padim\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define our built-in defaults (these are the real defaults we want to use)\n",
    "    DEFAULTS = {\n",
    "        'data_root': 'data_root',\n",
    "        'normal_dir': 'normal',\n",
    "        'abnormal_dir': 'abnormal', \n",
    "        'class_name': None,\n",
    "        'test_images': 'test_images',\n",
    "        'model_names': 'padim',\n",
    "        'backbones': 'resnet18;wide_resnet50_2',\n",
    "        'n_features_list': '64;320',\n",
    "        'layers': \"layer1,layer2;layer1,layer2,layer3\",\n",
    "        'max_epochs': 100,\n",
    "        'output_base': 'output_base',\n",
    "        'max_models': 10,\n",
    "        'max_test_images': 100,\n",
    "        'run_validation': False,\n",
    "        'show_original': True,\n",
    "        'device': 'auto',\n",
    "        'auto_submit': True,\n",
    "        'wait_for_completion': True,\n",
    "        'max_wait_time': 3600,\n",
    "        'session_name': None,\n",
    "        'num_workers': 4,\n",
    "        'mem_per_task': 8000,\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    # Collect all function parameters (this shows what user explicitly provided)\n",
    "    import inspect\n",
    "    frame = inspect.currentframe()\n",
    "    provided_args = {k: v for k, v in frame.f_locals.items() \n",
    "                    if k in DEFAULTS and v is not None}\n",
    "    \n",
    "    # Also handle boolean verbose separately since it has a default of False\n",
    "    if 'verbose' in frame.f_locals:\n",
    "        provided_args['verbose'] = frame.f_locals['verbose']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"ğŸ–¥ï¸  CLI arguments explicitly provided: {list(provided_args.keys())}\")\n",
    "    \n",
    "    try:\n",
    "        # Start with built-in defaults\n",
    "        final_config = DEFAULTS.copy()\n",
    "        \n",
    "        # Load and apply config file values (if provided)\n",
    "        config_data = {}\n",
    "        if config_file:\n",
    "            if verbose:\n",
    "                print(f\"ğŸ“ Loading configuration from: {config_file}\")\n",
    "            \n",
    "            try:\n",
    "                config_data = load_config_from_file(config_file)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"ğŸ”§ Config file values found: {list(config_data.keys())}\")\n",
    "                \n",
    "                # Apply config file values (override defaults)\n",
    "                for key, value in config_data.items():\n",
    "                    if key in final_config:\n",
    "                        if verbose and final_config[key] != value:\n",
    "                            print(f\"   {key}: {final_config[key]} -> {value} (from config)\")\n",
    "                        final_config[key] = value\n",
    "                    elif verbose:\n",
    "                        print(f\"   âš ï¸  Unknown config parameter ignored: {key}\")\n",
    "                        \n",
    "                if verbose:\n",
    "                    print(f\"âœ… Configuration loaded successfully\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error loading config file: {e}\")\n",
    "                return\n",
    "        \n",
    "        # Apply CLI arguments (highest precedence - overrides both defaults and config)\n",
    "        if verbose and provided_args:\n",
    "            print(f\"ğŸ–¥ï¸  Applying CLI overrides:\")\n",
    "        \n",
    "        for key, value in provided_args.items():\n",
    "            if key != 'config_file':  # Skip the config_file parameter itself\n",
    "                if verbose and final_config.get(key) != value:\n",
    "                    print(f\"   {key}: {final_config.get(key)} -> {value} (from CLI)\")\n",
    "                final_config[key] = value\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nğŸš€ Final configuration:\")\n",
    "            for key, value in final_config.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # Parse CLI parameters (existing logic)\n",
    "        parsed_layers = parse_cli_nested_lists(final_config['layers'])\n",
    "        model_names_parsed = parse_cli_models(final_config['model_names'])\n",
    "        backbones_parsed = parse_cli_models(final_config['backbones'])\n",
    "        n_features_parsed = parse_cli_numbers(final_config['n_features_list'])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nğŸ” PARSED CONFIGURATIONS:\")\n",
    "            print(f\"   Model names: {model_names_parsed}\")\n",
    "            print(f\"   Backbones: {backbones_parsed}\")\n",
    "            print(f\"   Features: {n_features_parsed}\")\n",
    "            print(f\"   Layers: {parsed_layers}\")\n",
    "\n",
    "        # Create output directory with timestamp\n",
    "        from datetime import datetime \n",
    "        date_now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = Path(f\"{final_config['output_base']}_multinode_results_{date_now}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Training Summary:\")\n",
    "        print(f\"   Auto submit: {final_config['auto_submit']}\")\n",
    "        print(f\"   Wait for completion: {final_config['wait_for_completion']}\")\n",
    "        print(f\"   Output path: {output_path}\")\n",
    "        \n",
    "        # Call the main training function with final config\n",
    "        result = multinode_diff_parameter_and_save_poster(\n",
    "            data_root=Path(final_config['data_root']),\n",
    "            normal_dir=final_config['normal_dir'],\n",
    "            abnormal_dir=final_config['abnormal_dir'],\n",
    "            class_name=final_config['class_name'],\n",
    "            test_images=final_config['test_images'],\n",
    "            model_names=model_names_parsed,\n",
    "            backbones=backbones_parsed,\n",
    "            n_features_list=n_features_parsed,\n",
    "            layers=parsed_layers,\n",
    "            max_epochs=final_config['max_epochs'],\n",
    "            session_name=final_config['session_name'],\n",
    "            num_workers=final_config['num_workers'],\n",
    "            mem_per_task=final_config['mem_per_task'],\n",
    "            output_base=output_path,\n",
    "            max_models=final_config['max_models'],\n",
    "            max_test_images=final_config['max_test_images'],\n",
    "            run_validation_tests=final_config['run_validation'],\n",
    "            show_original=final_config['show_original'],\n",
    "            device=final_config['device'],\n",
    "            auto_submit=final_config['auto_submit'],\n",
    "            wait_for_completion=final_config['wait_for_completion'],\n",
    "            max_wait_time=final_config['max_wait_time']\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸  Training interrupted by user\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error: {e}\")\n",
    "        if verbose:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e1ae680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/sample_multinode_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3e4ba1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_node_train_with_config_precedence(\n",
    "    config_file=config_file_path,\n",
    "    verbose=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b9e91c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/home/ai_dsx.work/data/projects/be-vision-ad-tools/nbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d63756e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('08_training.multi_node.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
