{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Inference System\n",
    "\n",
    "> Intelligent inference system that automatically selects between serial, parallel, and HPC multinode execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.unified_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook provides a unified inference system that intelligently chooses between three execution strategies:\n",
    "\n",
    "1. **Jupyter Notebook Mode**: Simple for-loop execution for interactive development\n",
    "2. **HPC Multinode Mode**: Distributed execution across cluster nodes using `bsub`\n",
    "3. **Parallel Mode**: Local parallel execution using multiprocessing.Pool\n",
    "\n",
    "The system automatically detects the execution environment and selects the optimal strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Dict, Any, Optional, Set,Callable\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from platform import system\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if system() == 'Linux':\n",
    "    os.chdir(r'/home/ai_dsx.work/data/projects/be-vision-ad-tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Import from existing notebooks\n",
    "from be_vision_ad_tools.inference.prediction_system import (\n",
    "    predict_image_list_from_file_enhanced\n",
    ")\n",
    "\n",
    "from be_vision_ad_tools.inference.multinode_inference import *\n",
    "\n",
    "from be_vision_ad_tools.inference.multinode_from_aiop_tool import (\n",
    "    HPC_Job,\n",
    "    DistributeHPC,\n",
    "    print_status\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CORE = \"/home/ai_dsx.work/data/projects/AD_tool_test/images/\"\n",
    "\n",
    "MODEL_PATH= Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/models/exports/TEST_MULITNODE_task_000_padim_resnet18_18_layer1/weights/torch/model.pt')\n",
    "GOOD_IM_PATH= Path(DATA_CORE, 'good')\n",
    "BAD_IM_PATH= Path(DATA_CORE, 'bad')\n",
    "OUTPUT_DIR = Path(r'/home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009')\n",
    "good_im_list = GOOD_IM_PATH.ls()\n",
    "bad_im_list = BAD_IM_PATH.ls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Folder Handling\n",
    "\n",
    "Functions to handle both flat and nested folder structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resolve_test_folders_smart(\n",
    "    test_folders: Union[str, Path, List[Union[str, Path]]]  # Folder(s), file(s), or mixed\n",
    ") -> List[Path]:  # Returns list of image paths\n",
    "    \"\"\"Resolve test_folders to image paths - handles lists, flat folders, and nested folders.\"\"\"\n",
    "    \n",
    "    if not isinstance(test_folders, list):\n",
    "        test_folders = [test_folders]\n",
    "    \n",
    "    image_paths = []\n",
    "    \n",
    "    for folder_or_file in test_folders:\n",
    "        path = Path(folder_or_file)\n",
    "        \n",
    "        if not path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Warning: '{folder_or_file}' does not exist\")\n",
    "            continue\n",
    "        \n",
    "        if path.is_file() and is_image_file(path):\n",
    "            # It's an image file\n",
    "            image_paths.append(path)\n",
    "            \n",
    "        elif path.is_dir():\n",
    "            # It's a directory - use smart folder scanning\n",
    "            try:\n",
    "                folder_info = scan_folder_structure(path)\n",
    "                image_paths.extend(folder_info['all_image_paths'])\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Failed to scan '{folder_or_file}': {e}\")\n",
    "                # Fallback to old behavior\n",
    "                for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']:\n",
    "                    image_paths.extend(path.glob(ext))\n",
    "                    image_paths.extend(path.glob(ext.upper()))\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Warning: '{folder_or_file}' is not a valid file or directory\")\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    unique_paths = sorted(set(image_paths))\n",
    "    \n",
    "    print(f\"üìÅ Resolved {len(unique_paths)} images from {len(test_folders)} input path(s)\")\n",
    "    return unique_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>resolve_test_folders_smart</h3>\n",
       "<blockquote><pre><code>resolve_test_folders_smart (test_folders:Union[str,pathlib.Path,List[Union[str,pathlib.Path]]])</code></pre></blockquote><p><i>Resolve test_folders to image paths - handles lists, flat folders, and nested folders.</i></p><table>\n",
       "    <thead><tr><th></th> <th>Type</th> <th>Details</th> <th></th></tr></thead>\n",
       "    <tbody><tr><td>test_folders</td> <td>Union</td> <td>Folder(s), file(s), or mixed</td> <td></td></tr><tr><td>Returns</td> <td>List</td> <td>Returns list of image paths</td> <td></td></tr></tbody>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(resolve_test_folders_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Resolved 85 images from 85 input path(s)\n"
     ]
    }
   ],
   "source": [
    "all_images = resolve_test_folders_smart(\n",
    "    test_folders=list(good_im_list),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Detected NESTED structure in: /home/ai_dsx.work/data/projects/AD_tool_test/images\n",
      "   üìÇ Lot 'good': 85 images\n",
      "   üìÇ Lot 'bad': 2 images\n",
      "   üìÇ Lot 'hyperparameter_models': 1 images\n",
      "\n",
      "‚úÖ Scan complete: 88 total images\n",
      "üìÅ Resolved 88 images from 1 input path(s)\n"
     ]
    }
   ],
   "source": [
    "all_images_ = resolve_test_folders_smart(\n",
    "    test_folders=DATA_CORE\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Detection\n",
    "\n",
    "These functions detect the execution environment to choose the optimal inference strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def in_jupyter_notebook() -> bool:\n",
    "    \"\"\"Check if code is running in a Jupyter notebook.\"\"\"\n",
    "    try:\n",
    "        # Check for IPython shell\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True  # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type\n",
    "    except NameError:\n",
    "        return False  # Probably standard Python interpreter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_jupyter_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def has_bsub_command() -> bool:\n",
    "    \"\"\"Check if bsub command is available (HPC environment).\"\"\"\n",
    "    return shutil.which(\"bsub\") is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_bsub_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def detect_execution_environment() -> str:\n",
    "    \"\"\"Detect execution environment and return appropriate mode.\"\"\"\n",
    "    if in_jupyter_notebook():\n",
    "        return \"jupyter\"\n",
    "    elif has_bsub_command():\n",
    "        return \"hpc\"\n",
    "    else:\n",
    "        return \"parallel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jupyter'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_execution_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìì In Jupyter: True\n",
      "üñ•Ô∏è  Has bsub: True\n",
      "üéØ Detected mode: jupyter\n",
      "‚úÖ Environment detection tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test environment detection\n",
    "def test_environment_detection():\n",
    "    \"\"\"Test environment detection functions.\"\"\"\n",
    "    \n",
    "    # Test Jupyter detection\n",
    "    jupyter_result = in_jupyter_notebook()\n",
    "    print(f\"üìì In Jupyter: {jupyter_result}\")\n",
    "    \n",
    "    # Test HPC detection\n",
    "    hpc_result = has_bsub_command()\n",
    "    print(f\"üñ•Ô∏è  Has bsub: {hpc_result}\")\n",
    "    \n",
    "    # Test overall detection\n",
    "    mode = detect_execution_environment()\n",
    "    print(f\"üéØ Detected mode: {mode}\")\n",
    "    \n",
    "    assert mode in [\"jupyter\", \"hpc\", \"parallel\"], f\"Invalid mode: {mode}\"\n",
    "    print(\"‚úÖ Environment detection tests passed\")\n",
    "\n",
    "test_environment_detection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Strategies\n",
    "\n",
    "Three different execution strategies for different environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: Serial Execution (Jupyter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>predict_image_list_from_file_enhanced</h3>\n",
       "<blockquote><pre><code>predict_image_list_from_file_enhanced (model_path:Union[str,pathlib.Path], image_list_file:Union[str,pathlib.Path], batch_id:Optional[str]=None, output_dir:Union[str,pathlib.Path,NoneType]=None, save_heatmap:bool=False, heatmap_style:str='side_by_side', device:str='auto', save_results:bool=True, show_heatmap:bool=False, compress:bool=True, jpeg_quality:int=95, preprocessing_fn:Optional[Callable]=None, preprocessing_kwargs:Optional[Dict[str,Any]]=None)</code></pre></blockquote><p><i>Process images from text file</i></p><table>\n",
       "    <thead><tr><th></th> <th>Type</th> <th>Default</th> <th>Details</th> <th></th></tr></thead>\n",
       "    <tbody><tr><td>model_path</td> <td>Union</td> <td></td> <td>path to the model(.ckpt, .pt, .onnx, .xml)</td> <td></td></tr><tr><td>image_list_file</td> <td>Union</td> <td></td> <td>text file with one image path per line</td> <td></td></tr><tr><td>batch_id</td> <td>Optional</td> <td>None</td> <td>unique identifier for this batch (for parallel processing)</td> <td></td></tr><tr><td>output_dir</td> <td>Union</td> <td>None</td> <td>directory to save the heatmap</td> <td></td></tr><tr><td>save_heatmap</td> <td>bool</td> <td>False</td> <td>whether to save heatmap visualizations</td> <td></td></tr><tr><td>heatmap_style</td> <td>str</td> <td>side_by_side</td> <td>\"heatmap_only\", \"combined\", \"side_by_side\", \"cv2_side_by_side\", \"cv2_heatmap_only\"</td> <td></td></tr><tr><td>device</td> <td>str</td> <td>auto</td> <td>device to use for prediction(\"auto\", \"cpu\", \"cuda\")</td> <td></td></tr><tr><td>save_results</td> <td>bool</td> <td>True</td> <td>whether to save JSON results</td> <td></td></tr><tr><td>show_heatmap</td> <td>bool</td> <td>False</td> <td>Whether to show heatmap</td> <td></td></tr><tr><td>compress</td> <td>bool</td> <td>True</td> <td>Whether to compress the image (JPEG format)</td> <td></td></tr><tr><td>jpeg_quality</td> <td>int</td> <td>95</td> <td>JPEG compression quality (0-100, higher is better)</td> <td></td></tr><tr><td>preprocessing_fn</td> <td>Optional</td> <td>None</td> <td>Preprocessing function applied to the images before prediction</td> <td></td></tr><tr><td>preprocessing_kwargs</td> <td>Optional</td> <td>None</td> <td>Preprocessing kwargs for the preprocessing function</td> <td></td></tr><tr><td>Returns</td> <td>Dict</td> <td></td> <td>dictionary with prediction results and file paths</td> <td></td></tr></tbody>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(predict_image_list_from_file_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_jupyter_inference(\n",
    "    model_path: Union[str, Path], # Path to the model file\n",
    "    image_path: Union[str, Path, List[Path]], # List of image paths to process\n",
    "    output_dir: Union[str, Path] = \"inference_results\", # Output directory\n",
    "    save_heatmaps: bool = False, # Whether to save heatmaps\n",
    "    heatmap_style: str = \"side_by_side\", # Style of heatmap to save\n",
    "    jpeg_quality: int = 95,\n",
    "    compress: bool = True,\n",
    "    preprocessing_fn=None, # Preprocessing function\n",
    "    preprocessing_kwargs=None, # Preprocessing kwargs\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Execute inference serially using simple for-loop (Jupyter mode).\"\"\"\n",
    "\n",
    "    image_paths = resolve_test_folders_smart(image_path)\n",
    "    \n",
    "    print(f\"üìì Running in Jupyter mode (serial for-loop)\")\n",
    "    print(f\"   Processing {len(image_paths)} images sequentially...\")\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create temporary batch file with all images\n",
    "    batch_file = output_dir / \"jupyter_batch_images.txt\"\n",
    "    create_batch_list_file(image_paths, batch_file)\n",
    "    \n",
    "    # Use existing prediction system\n",
    "    results = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=batch_file,\n",
    "        batch_id=\"jupyter_batch\",\n",
    "        output_dir=output_dir,\n",
    "        save_results=save_heatmaps,\n",
    "        heatmap_style=heatmap_style,\n",
    "        compress=compress,\n",
    "        jpeg_quality=jpeg_quality,\n",
    "        preprocessing_fn=preprocessing_fn,\n",
    "        preprocessing_kwargs=preprocessing_kwargs,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Jupyter inference complete: {len(image_paths)} images processed\")\n",
    "    \n",
    "    return {\n",
    "        \"mode\": \"jupyter\",\n",
    "        \"total_images\": len(image_paths),\n",
    "        \"output_dir\": str(output_dir),\n",
    "        \"results\": results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from be_vision_ad_tools.inference.prediction_system import (\n",
    "    predict_image_list_from_file_enhanced,\n",
    "    predict_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_half_black_image(\n",
    "    image: np.ndarray, # Input image as numpy array\n",
    "    side: str = \"left\" # Side to make black: \"left\", \"right\", \"top\", or \"bottom\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create an image with half of it blacked out.\"\"\"\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"image must be a numpy array\")\n",
    "    \n",
    "    if side not in [\"left\", \"right\", \"top\", \"bottom\"]:\n",
    "        raise ValueError(f\"Invalid side: {side}. Must be one of: left, right, top, bottom\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    result = image.copy()\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    if side == \"left\":\n",
    "        result[:, :width//2] = 0\n",
    "    elif side == \"right\":\n",
    "        result[:, width//2:] = 0\n",
    "    elif side == \"top\":\n",
    "        result[:height//2, :] = 0\n",
    "    elif side == \"bottom\":\n",
    "        result[height//2:, :] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 18:59:20,908 - be_vision_ad_tools.inference.prediction_system - INFO - Predicting with .pt model on 3042400443552714.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìì Running in Jupyter mode (serial for-loop)\n",
      "   Processing 2 images sequentially...\n",
      "üöÄ ENHANCED PREDICT IMAGE LIST FROM FILE\n",
      "üéØ Reading image list from: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009/jupyter_batch_images.txt\n",
      "üìÇ Loaded 2 image paths\n",
      "üé® Style: side_by_side\n",
      "üîç Processing 2 images from list\n",
      "üì¶ Batch ID: jupyter_batch\n",
      "üéØ Using model: model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 18:59:21,297 - be_vision_ad_tools.inference.prediction_system - INFO - Prediction: NORMAL (Score: 0.2050)\n",
      "2025-11-07 18:59:21,298 - be_vision_ad_tools.inference.prediction_system - INFO - Predicting with .pt model on 3042400444552714.png\n",
      "2025-11-07 18:59:21,674 - be_vision_ad_tools.inference.prediction_system - INFO - Prediction: ANOMALY (Score: 1.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Batch Processing Summary:\n",
      "   Batch ID: jupyter_batch\n",
      "   Images in List: 2\n",
      "   Valid Images: 2\n",
      "   Successfully Processed: 2\n",
      "   Failed: 0\n",
      "   Normal: 1 (50.0%)\n",
      "   Anomalies: 1 (50.0%)\n",
      "   Average Score: 0.6025\n",
      "Saving results to JSON, output directory: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009/batch_jupyter_batch\n",
      "üíæ Results saved to: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009/batch_jupyter_batch/batch_results_jupyter_batch.json\n",
      "‚úÖ Jupyter inference complete: 2 images processed\n"
     ]
    }
   ],
   "source": [
    "rs = run_jupyter_inference(\n",
    "    model_path=MODEL_PATH,\n",
    "    image_paths=bad_im_list,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_heatmaps=True,\n",
    "    heatmap_style=\"side_by_side\",\n",
    "    #preprocessing_fn=create_half_black_image,\n",
    "    #preprocessing_kwargs={\"side\": \"left\"}\n",
    "    jpeg_quality=95,\n",
    "    compress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['statistics', 'results'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs['results'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: HPC Multinode Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hpc_inference(\n",
    "    model_path: Union[str, Path],\n",
    "    image_path: Union[str, Path, List[Path]],\n",
    "    output_dir: Union[str, Path] = \"inference_results\",\n",
    "    save_heatmaps: bool = False,\n",
    "    heatmap_style: str = \"side_by_side\",\n",
    "    compress: bool = True,\n",
    "    jpeg_quality: int = 95,\n",
    "    batch_size: int = 10,\n",
    "    num_nodes: int = 10,\n",
    "    preprocessing_fn=None,\n",
    "    preprocessing_kwargs=None,\n",
    "    **kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"Execute inference using HPC multinode execution.\"\"\"\n",
    "    \n",
    "    print(f\"üñ•Ô∏è  Running HPC multinode inference\")\n",
    "    bsub_rs = distribute_folder_inference(\n",
    "                                        root_path=image_path,\n",
    "                                        model_path=model_path,\n",
    "                                        output_dir=output_dir,\n",
    "                                        save_heatmaps=save_heatmaps,\n",
    "                                        heatmap_style=heatmap_style,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_nodes=num_nodes,\n",
    "                                        compress=compress,\n",
    "                                        jpeg_quality=jpeg_quality,\n",
    "                                        preprocessing_fn=preprocessing_fn,\n",
    "                                        preprocessing_kwargs=preprocessing_kwargs,\n",
    "                                        **kwargs\n",
    "                                    )\n",
    "\n",
    "    print(f\"‚úÖ HPC inference complete: {len(Path(image_path).ls())} images processed\")\n",
    "    \n",
    "    return {\n",
    "        \"mode\": \"hpc\",\n",
    "        \"total_images\": len(Path(image_path).ls()),\n",
    "        \"output_dir\": str(output_dir),\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"results\": bsub_rs\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Running HPC multinode inference\n",
      "üöÄ SMART FOLDER INFERENCE DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "üìã Step 1: Validating inputs...\n",
      "‚úÖ Model found: /home/ai_dsx.work/data/projects/AD_tool_test/models/exports/TEST_MULITNODE_task_000_padim_resnet18_18_layer1/weights/torch/model.pt\n",
      "‚úÖ Root path valid: /home/ai_dsx.work/data/projects/AD_tool_test/images/bad\n",
      "‚úÖ Batch size valid: 10\n",
      "‚úÖ Number of nodes valid: 10\n",
      "‚úÖ Output directory: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009\n",
      "\n",
      "üì° Step 2: Scanning folder structure...\n",
      "üìÑ Detected FLAT structure in: /home/ai_dsx.work/data/projects/AD_tool_test/images/bad\n",
      "   üì∑ Total images: 2\n",
      "\n",
      "‚úÖ Scan complete: 2 total images\n",
      "\n",
      "üî® Step 3: Creating smart batches...\n",
      "\n",
      "üè≠ Step 4: Creating HPC jobs...\n",
      "\n",
      "======================================================================\n",
      "üéØ INFERENCE JOB DISTRIBUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìÅ Data Structure:\n",
      "   Type: FLAT\n",
      "   Total Images: 2\n",
      "\n",
      "üì¶ Batch Configuration:\n",
      "   Total Batches: 1\n",
      "   Batch Sizes: min=2, max=2, avg=2\n",
      "\n",
      "üè≠ HPC Jobs:\n",
      "   Total Jobs Created: 1\n",
      "   Jobs per Node (approx): 0.1\n",
      "\n",
      "üñ•Ô∏è  Compute Resources:\n",
      "   Number of Nodes: 10\n",
      "   Cores per Job: 4\n",
      "\n",
      "üíæ Output:\n",
      "   Directory: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009\n",
      "   Batch Lists: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009/batch_lists\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Setup Complete - Ready for Execution!\n",
      "======================================================================\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è  Step 5: Submitting jobs to 10 nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total:   0%|                                             | 0/19 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:1, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[1m\u001b[36mRUNNING:2, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:3, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:4, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:5, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:6, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:7, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:8, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:0\u001b[0m:   0%|                                 | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:0\u001b[0m:   0%|                                | 0/19 [00:02<?, ?it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:1\u001b[0m:   5%|‚ñà‚ñé                      | 1/19 [00:10<02:28,  8.23s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:2\u001b[0m:  11%|‚ñà‚ñà‚ñã                      | 2/19 [00:10<02:19,  8.23s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:2\u001b[0m:  11%|‚ñà‚ñà‚ñå                     | 2/19 [00:10<00:59,  3.50s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:2\u001b[0m:  11%|‚ñà‚ñà‚ñå                     | 2/19 [00:11<00:59,  3.50s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:2\u001b[0m:  11%|‚ñà‚ñà‚ñå                     | 2/19 [00:11<00:59,  3.50s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:3\u001b[0m:  16%|‚ñà‚ñà‚ñà‚ñâ                     | 3/19 [00:14<01:01,  3.86s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:3\u001b[0m:  16%|‚ñà‚ñà‚ñà‚ñä                    | 3/19 [00:14<01:01,  3.86s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:4\u001b[0m:  21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 4/19 [00:15<00:57,  3.86s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:4\u001b[0m:  21%|‚ñà‚ñà‚ñà‚ñà‚ñà                   | 4/19 [00:15<00:57,  3.86s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:4\u001b[0m:  21%|‚ñà‚ñà‚ñà‚ñà‚ñà                   | 4/19 [00:15<00:36,  2.41s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:4\u001b[0m:  21%|‚ñà‚ñà‚ñà‚ñà‚ñà                   | 4/19 [00:15<00:36,  2.41s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:5\u001b[0m:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 5/19 [00:15<00:23,  1.64s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:5\u001b[0m:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 5/19 [00:15<00:23,  1.64s/it]\u001b[0m\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:6\u001b[0m:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 6/19 [00:15<00:14,  1.12s/it]\u001b[0m\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:6\u001b[0m:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 6/19 [00:15<00:14,  1.12s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:7\u001b[0m:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 7/19 [00:15<00:13,  1.12s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:7\u001b[0m:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 7/19 [00:15<00:13,  1.12s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:7\u001b[0m:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 7/19 [00:15<00:13,  1.12s/it]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:7\u001b[0m:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 7/19 [00:15<00:09,  1.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:7\u001b[0m:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 7/19 [00:15<00:09,  1.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:8\u001b[0m:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 8/19 [00:16<00:07,  1.55it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:8\u001b[0m:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 8/19 [00:16<00:07,  1.55it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:9\u001b[0m:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 9/19 [00:16<00:05,  1.93it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:10, DONE:9\u001b[0m:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 9/19 [00:16<00:05,  1.93it/s]\u001b[0m\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:16<00:04,  2.23it/s]\u001b[0m\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:9, DONE:10\u001b[0m:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 10/19 [00:18<00:04,  2.23it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[1m\u001b[36mRUNNING:8, DONE:11\u001b[0m:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 11/19 [00:25<00:24,  3.04s/it]\u001b[0m\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[1m\u001b[36mRUNNING:7, DONE:12\u001b[0m:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 12/19 [00:25<00:15,  2.22s/it]\u001b[0m\n",
      "\u001b[A\n",
      "\u001b[1m\u001b[36mRUNNING:6, DONE:13\u001b[0m:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 13/19 [00:26<00:10,  1.76s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:5, DONE:14\u001b[0m:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 14/19 [00:29<00:10,  2.09s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:4, DONE:15\u001b[0m:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 15/19 [00:30<00:06,  1.69s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:3, DONE:16\u001b[0m:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 16/19 [00:30<00:03,  1.22s/it]\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:2, DONE:17\u001b[0m:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 17/19 [00:30<00:02,  1.22s/it]\u001b[0m\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Total:   0%|                                             | 0/19 [00:00<?, ?it/s]0,  1.44it/s]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:0, DONE:19\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:31<00:00,  1.41it/s]\u001b[0m\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[36mRUNNING:0, DONE:19\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:31<00:00,  1.67s/it]\u001b[0m\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]\n",
      "\u001b[0m: : 0it [00:31, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Job execution completed!\n",
      "‚úÖ HPC inference complete: 2 images processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rs_ = run_hpc_inference(\n",
    "    model_path=MODEL_PATH,\n",
    "    image_path=BAD_IM_PATH,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_heatmaps=True,\n",
    "    heatmap_style=\"side_by_side\",\n",
    "    batch_size=10,\n",
    "    num_nodes=10,\n",
    "    compress=True,\n",
    "    jpeg_quality=95,\n",
    "    preprocessing_fn=None,\n",
    "    preprocessing_kwargs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. run_jupyter_inference\n",
    "2. distribute_folder_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3: Parallel Execution (Python Script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _process_batch_worker(args: tuple) -> Dict[str, Any]:\n",
    "    \"\"\"Worker function for parallel batch processing.\"\"\"\n",
    "    model_path, batch_images, batch_id, output_dir, save_heatmaps, heatmap_style, compress, jpeg_quality, preprocessing_fn, preprocessing_kwargs, kwargs = args\n",
    "    \n",
    "    # Create batch file\n",
    "    batch_list_file = Path(output_dir) / \"batch_lists\" / f\"{batch_id}_images.txt\"\n",
    "    create_batch_list_file(batch_images, batch_list_file)\n",
    "    \n",
    "    # Process batch\n",
    "    results = predict_image_list_from_file(\n",
    "        model_path=model_path,\n",
    "        image_list_file=batch_list_file,\n",
    "        batch_id=batch_id,\n",
    "        output_dir=output_dir,\n",
    "        save_results=save_heatmaps,\n",
    "        heatmap_style=heatmap_style,\n",
    "        compress=compress,\n",
    "        jpeg_quality=jpeg_quality,\n",
    "        preprocessing_fn=preprocessing_fn,\n",
    "        preprocessing_kwargs=preprocessing_kwargs,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"batch_id\": batch_id,\n",
    "        \"num_images\": len(batch_images),\n",
    "        \"results\": results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_parallel_inference(\n",
    "    model_path: Union[str, Path],\n",
    "    image_path: Union[str, Path, List[Path]],\n",
    "    batch_size: int = 100,\n",
    "    num_workers: Optional[int] = None,\n",
    "    output_dir: Union[str, Path] = \"parallel_results\",\n",
    "    save_heatmaps: bool = False,\n",
    "    heatmap_style: str = \"side_by_side\",\n",
    "    compress: bool = True,\n",
    "    jpeg_quality: int = 95,\n",
    "    num_nodes: int = 10,\n",
    "    preprocessing_fn=None,\n",
    "    preprocessing_kwargs=None,\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Execute inference in parallel using multiprocessing.Pool.\"\"\"\n",
    "\n",
    "    print(\"üöÄ SMART FOLDER INFERENCE DISTRIBUTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Step 1: Validate inputs (fail fast)\n",
    "    print(\"\\nüìã Step 1: Validating inputs...\")\n",
    "    model_path, root_path = validate_inference_inputs(\n",
    "        model_path=model_path,\n",
    "        root_path=image_path,\n",
    "        batch_size=batch_size,\n",
    "        num_nodes=num_nodes\n",
    "    )\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Output directory: {output_dir}\")\n",
    "    \n",
    "    # Step 2: Scan folder structure (auto-detect flat vs nested)\n",
    "    print(f\"\\nüì° Step 2: Scanning folder structure...\")\n",
    "    folder_info = scan_folder_structure(root_path)\n",
    "    \n",
    "    # Step 3: Create smart batches\n",
    "    print(f\"\\nüî® Step 3: Creating smart batches...\")\n",
    "    batches = create_smart_batches(folder_info, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    # Split into batches\n",
    "    image_batches = create_smart_batches(\n",
    "        Path(image_path), batch_size=batch_size)\n",
    "    \n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()\n",
    "    \n",
    "    print(f\"‚ö° Running in parallel mode with {num_workers} workers\")\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Prepare worker arguments\n",
    "    worker_args = []\n",
    "    for i, batch in enumerate(image_batches):\n",
    "        batch_id = f\"batch_{i+1:04d}\"\n",
    "        batch_kwargs = {\n",
    "            \"save_heatmaps\": save_heatmaps,\n",
    "            \"heatmap_style\": heatmap_style,\n",
    "            \"compress\": compress,\n",
    "            \"jpeg_quality\": jpeg_quality,\n",
    "            \"preprocessing_fn\": preprocessing_fn,\n",
    "            \"preprocessing_kwargs\": preprocessing_kwargs,\n",
    "            **kwargs\n",
    "        }\n",
    "        worker_args.append((model_path, batch, batch_id, output_path, batch_kwargs))\n",
    "    \n",
    "    # Execute in parallel\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        batch_results = list(tqdm(\n",
    "            pool.imap(_process_batch_worker, worker_args),\n",
    "            total=len(worker_args),\n",
    "            desc=\"Processing batches\"\n",
    "        ))\n",
    "    \n",
    "    print(f\"‚úÖ Parallel inference complete: {len(image_batches)} batches processed\")\n",
    "    \n",
    "    return {\n",
    "        \"mode\": \"parallel\",\n",
    "        \"total_images\": len(image_paths),\n",
    "        \"num_batches\": len(image_batches),\n",
    "        \"num_workers\": num_workers,\n",
    "        \"output_dir\": str(output_path),\n",
    "        \"results\": batch_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SMART FOLDER INFERENCE DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "üìã Step 1: Validating inputs...\n",
      "‚úÖ Model found: /home/ai_dsx.work/data/projects/AD_tool_test/models/exports/TEST_MULITNODE_task_000_padim_resnet18_18_layer1/weights/torch/model.pt\n",
      "‚úÖ Root path valid: /home/ai_dsx.work/data/projects/AD_tool_test/images/bad\n",
      "‚úÖ Batch size valid: 100\n",
      "‚úÖ Number of nodes valid: 10\n",
      "‚úÖ Output directory: /home/ai_dsx.work/data/projects/AD_tool_test/inference_results20251009\n",
      "\n",
      "üì° Step 2: Scanning folder structure...\n",
      "üìÑ Detected FLAT structure in: /home/ai_dsx.work/data/projects/AD_tool_test/images/bad\n",
      "   üì∑ Total images: 2\n",
      "\n",
      "‚úÖ Scan complete: 2 total images\n",
      "\n",
      "üî® Step 3: Creating smart batches...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'PosixPath' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rs_ = \u001b[43mrun_parallel_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBAD_IM_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_heatmaps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheatmap_style\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mside_by_side\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjpeg_quality\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreprocessing_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreprocessing_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mrun_parallel_inference\u001b[39m\u001b[34m(model_path, image_path, batch_size, num_workers, output_dir, save_heatmaps, heatmap_style, compress, jpeg_quality, num_nodes, preprocessing_fn, preprocessing_kwargs, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m batches = create_smart_batches(folder_info, batch_size)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Split into batches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m image_batches = \u001b[43mcreate_smart_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m     num_workers = cpu_count()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcreate_smart_batches\u001b[39m\u001b[34m(folder_info, batch_size)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_smart_batches\u001b[39m(\n\u001b[32m      3\u001b[39m     folder_info: Dict[\u001b[38;5;28mstr\u001b[39m, Any],  \u001b[38;5;66;03m# Folder structure from scan_folder_structure\u001b[39;00m\n\u001b[32m      4\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m  \u001b[38;5;66;03m# Maximum images per batch\u001b[39;00m\n\u001b[32m      5\u001b[39m ) -> List[List[Path]]:  \u001b[38;5;66;03m# Returns list of batches (each batch is list of image paths)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create balanced batches from folder structure with smart lot handling.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     structure_type = \u001b[43mfolder_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m structure_type == \u001b[33m\"\u001b[39m\u001b[33mnested\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     11\u001b[39m         batches = _create_batches_from_nested_structure(folder_info, batch_size)\n",
      "\u001b[31mTypeError\u001b[39m: 'PosixPath' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "rs_ = run_parallel_inference(\n",
    "    model_path=MODEL_PATH,\n",
    "    image_path=BAD_IM_PATH,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_heatmaps=True,\n",
    "    heatmap_style=\"side_by_side\",\n",
    "    compress=True,\n",
    "    jpeg_quality=95,\n",
    "    preprocessing_fn=None,\n",
    "    preprocessing_kwargs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified Interface\n",
    "\n",
    "The main function that intelligently routes to the appropriate execution strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def unified_inference(\n",
    "    model_path: Union[str, Path],\n",
    "    test_folders: Union[str, Path, List[Union[str, Path]]],\n",
    "    batch_size: int = 100,\n",
    "    execution_mode: str = \"auto\",\n",
    "    num_nodes: int = 4,\n",
    "    num_workers: Optional[int] = None,\n",
    "    output_dir: Optional[Union[str, Path]] = None,\n",
    "    save_heatmaps: bool = False,\n",
    "    heatmap_style: str = \"cv2_side_by_side\",\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Unified inference function that automatically selects execution strategy.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained model\n",
    "        test_folders: Image folder(s) or file path(s)\n",
    "        batch_size: Maximum images per batch\n",
    "        execution_mode: \"auto\", \"jupyter\", \"hpc\", or \"parallel\"\n",
    "        num_nodes: Number of HPC nodes (for HPC mode)\n",
    "        num_workers: Number of parallel workers (for parallel mode, default: cpu_count())\n",
    "        output_dir: Output directory for results\n",
    "        save_heatmaps: Whether to save visualization heatmaps\n",
    "        heatmap_style: Visualization style\n",
    "        **kwargs: Additional arguments passed to inference functions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with inference results and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting Unified Inference System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Auto-detect or validate execution mode\n",
    "    if execution_mode == \"auto\":\n",
    "        execution_mode = detect_execution_environment()\n",
    "        print(f\"üéØ Auto-detected mode: {execution_mode}\")\n",
    "    else:\n",
    "        if execution_mode not in [\"jupyter\", \"hpc\", \"parallel\"]:\n",
    "            raise ValueError(f\"Invalid execution_mode: {execution_mode}\")\n",
    "        print(f\"üéØ Using specified mode: {execution_mode}\")\n",
    "    \n",
    "    # Resolve image paths (handles lists, flat folders, and nested folders)\n",
    "    image_paths = resolve_test_folders_smart(test_folders)\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No valid images found in test_folders\")\n",
    "    \n",
    "    # Set default output directory based on mode\n",
    "    if output_dir is None:\n",
    "        output_dir = f\"{execution_mode}_inference_results\"\n",
    "    \n",
    "    # Execute based on detected/specified mode\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if execution_mode == \"jupyter\":\n",
    "        results = run_jupyter_inference(\n",
    "            model_path=model_path,\n",
    "            image_paths=image_paths,\n",
    "            output_dir=output_dir,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    elif execution_mode == \"hpc\":\n",
    "        results = run_hpc_multinode_inference(\n",
    "            model_path=model_path,\n",
    "            image_paths=image_paths,\n",
    "            batch_size=batch_size,\n",
    "            num_nodes=num_nodes,\n",
    "            output_dir=output_dir,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    elif execution_mode == \"parallel\":\n",
    "        results = run_parallel_inference(\n",
    "            model_path=model_path,\n",
    "            image_paths=image_paths,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            output_dir=output_dir,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üéâ Unified inference complete!\")\n",
    "    print(f\"   Mode: {results['mode']}\")\n",
    "    print(f\"   Images: {results['total_images']}\")\n",
    "    print(f\"   Output: {results['output_dir']}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Auto-detect and run with flat folder\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=\"test_images/\",  # Flat folder - all images in one directory\n",
    "#     batch_size=50,\n",
    "#     save_heatmaps=True\n",
    "# )\n",
    "\n",
    "# Example 1b: Auto-detect and run with nested folder\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=\"production_images/\",  # Nested folder - images in subfolders\n",
    "#     batch_size=50,\n",
    "#     save_heatmaps=True\n",
    "# )\n",
    "\n",
    "# Example 1c: Auto-detect and run with list of images\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=[\"img1.jpg\", \"img2.png\", \"folder1/\"],  # Mixed: files and folders\n",
    "#     batch_size=50,\n",
    "#     save_heatmaps=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Force Jupyter mode\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=[\"folder1/\", \"folder2/\"],\n",
    "#     execution_mode=\"jupyter\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Force HPC multinode mode\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=\"large_dataset/\",\n",
    "#     execution_mode=\"hpc\",\n",
    "#     batch_size=100,\n",
    "#     num_nodes=8\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Force parallel mode with custom workers\n",
    "# results = unified_inference(\n",
    "#     model_path=\"path/to/model.pt\",\n",
    "#     test_folders=\"test_images/\",\n",
    "#     execution_mode=\"parallel\",\n",
    "#     batch_size=50,\n",
    "#     num_workers=8\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests and Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unified_inference_modes():\n",
    "    \"\"\"Test that unified inference can route to different modes.\"\"\"\n",
    "    \n",
    "    # Test mode validation\n",
    "    try:\n",
    "        unified_inference(\n",
    "            model_path=\"fake.pt\",\n",
    "            test_folders=[],\n",
    "            execution_mode=\"invalid_mode\"\n",
    "        )\n",
    "        assert False, \"Should raise ValueError for invalid mode\"\n",
    "    except ValueError as e:\n",
    "        assert \"Invalid execution_mode\" in str(e)\n",
    "        print(\"‚úÖ Mode validation works\")\n",
    "    \n",
    "    # Test empty image paths\n",
    "    try:\n",
    "        unified_inference(\n",
    "            model_path=\"fake.pt\",\n",
    "            test_folders=[],\n",
    "            execution_mode=\"jupyter\"\n",
    "        )\n",
    "        assert False, \"Should raise ValueError for empty images\"\n",
    "    except ValueError as e:\n",
    "        assert \"No valid images\" in str(e)\n",
    "        print(\"‚úÖ Empty images validation works\")\n",
    "    \n",
    "    print(\"‚úÖ All unified inference tests passed\")\n",
    "\n",
    "def test_resolve_test_folders_smart():\n",
    "    \"\"\"Test smart folder resolution with different input types.\"\"\"\n",
    "    \n",
    "    # Test with non-existent path (should warn but not fail)\n",
    "    result = resolve_test_folders_smart([\"non_existent_folder\"])\n",
    "    test_eq(len(result), 0)\n",
    "    print(\"‚úÖ Handles non-existent paths gracefully\")\n",
    "    \n",
    "    # Test with empty list\n",
    "    result = resolve_test_folders_smart([])\n",
    "    test_eq(len(result), 0)\n",
    "    print(\"‚úÖ Handles empty list\")\n",
    "    \n",
    "    print(\"‚úÖ Smart folder resolution tests passed\")\n",
    "\n",
    "# Run tests\n",
    "test_unified_inference_modes()\n",
    "test_resolve_test_folders_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
