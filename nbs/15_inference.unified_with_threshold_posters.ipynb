{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Inference with Threshold Organization and Poster Creation\n",
    "\n",
    "> Complete inference system that supports Jupyter, Parallel, and HPC modes with automatic threshold-based organization and indexed poster generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.unified_with_threshold_posters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook combines:\n",
    "1. **Unified Inference** - Automatic selection between Jupyter, Parallel, and HPC execution modes\n",
    "2. **Threshold Organization** - Organize images into folders based on anomaly scores\n",
    "3. **Poster Creation** - Generate indexed posters for easy image review and reference\n",
    "\n",
    "### Execution Modes:\n",
    "- **Jupyter Mode**: Serial execution for interactive development\n",
    "- **Parallel Mode**: Local multiprocessing for faster execution\n",
    "- **HPC Mode**: Distributed execution across cluster nodes using `bsub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Dict, Any, Optional, Set, Callable, Tuple\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Import from existing modules\n",
    "from vision_ad_tool.inference.prediction_system import (\n",
    "    predict_image_list_from_file_enhanced,\n",
    "    predict_image_list\n",
    ")\n",
    "\n",
    "from vision_ad_tool.inference.multinode_inference import (\n",
    "    create_smart_batches,\n",
    "    scan_folder_structure,\n",
    "    create_batch_list_file,\n",
    "    is_image_file,\n",
    "    distribute_folder_inference\n",
    ")\n",
    "\n",
    "from vision_ad_tool.inference.anomaly_score_organizer import (\n",
    "    create_image_index_dataframe,\n",
    "    organize_images_by_score,\n",
    "    create_posters_for_score_folders\n",
    ")\n",
    "\n",
    "from vision_ad_tool.inference.unified_inference import (\n",
    "    in_jupyter_notebook,\n",
    "    has_bsub_command,\n",
    "    detect_execution_environment,\n",
    "    resolve_test_folders_smart\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Execution Functions\n",
    "\n",
    "These functions handle the three different execution modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_jupyter_inference_with_organization(\n",
    "    model_path: Union[str, Path],  # Path to the model file\n",
    "    image_list: Union[str, Path, List[Path]],  # Image paths or list file\n",
    "    output_dir: Union[str, Path],  # Output directory\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    create_posters: bool = True,  # Whether to create posters\n",
    "    images_per_poster: int = 20,  # Images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Image size in poster\n",
    "    grid_cols: int = 5,  # Grid columns\n",
    "    save_heatmaps: bool = False,  # Save heatmaps\n",
    "    heatmap_style: str = \"side_by_side\",  # Heatmap style\n",
    "    copy_mode: bool = True,  # Copy or move files\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Execute inference in Jupyter mode with threshold organization and poster creation.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with execution results, organization stats, and poster paths\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ““ JUPYTER MODE: Serial Execution with Organization\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Resolve image paths\n",
    "    if isinstance(image_list, (str, Path)):\n",
    "        image_list_path = Path(image_list)\n",
    "        if image_list_path.is_file():\n",
    "            # It's a file - use directly\n",
    "            batch_file = image_list_path\n",
    "        elif image_list_path.is_dir():\n",
    "            # It's a directory - create batch file\n",
    "            image_paths = resolve_test_folders_smart(image_list)\n",
    "            batch_file = output_dir / \"jupyter_batch_images.txt\"\n",
    "            create_batch_list_file(image_paths, batch_file)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid image_list: {image_list}\")\n",
    "    else:\n",
    "        # It's a list - create batch file\n",
    "        batch_file = output_dir / \"jupyter_batch_images.txt\"\n",
    "        create_batch_list_file(image_list, batch_file)\n",
    "    \n",
    "    # Step 0: Create image index dataframe\n",
    "    print(\"\\nğŸ“Š Step 0: Creating image index dataframe...\")\n",
    "    image_index_df = create_image_index_dataframe(batch_file)\n",
    "    df_path = output_dir / \"image_index.csv\"\n",
    "    image_index_df.to_csv(df_path, index=False)\n",
    "    print(f\"ğŸ’¾ Saved: {df_path}\")\n",
    "    \n",
    "    # Step 1: Run predictions\n",
    "    print(\"\\nğŸ“Š Step 1: Running predictions...\")\n",
    "    prediction_output = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=batch_file,\n",
    "        batch_id=\"jupyter_batch\",\n",
    "        output_dir=output_dir,\n",
    "        save_results=True,\n",
    "        save_heatmap=save_heatmaps,\n",
    "        heatmap_style=heatmap_style,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    prediction_results = prediction_output.get('results', [])\n",
    "    \n",
    "    if not prediction_results:\n",
    "        print(\"âš ï¸  No prediction results to organize!\")\n",
    "        return {\n",
    "            'mode': 'jupyter',\n",
    "            'image_index_df': image_index_df,\n",
    "            'prediction_results': prediction_output,\n",
    "            'organization_stats': None,\n",
    "            'poster_paths': None\n",
    "        }\n",
    "    \n",
    "    # Step 2: Organize by score\n",
    "    print(\"\\nğŸ“ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=prediction_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Step 3: Create posters\n",
    "    poster_paths = None\n",
    "    if create_posters:\n",
    "        print(\"\\nğŸ–¼ï¸  Step 3: Creating indexed posters...\")\n",
    "        poster_paths = create_posters_for_score_folders(\n",
    "            output_dir=output_dir,\n",
    "            image_index_df=image_index_df,\n",
    "            score_thresholds=score_thresholds,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols\n",
    "        )\n",
    "    \n",
    "    print(\"\\nâœ… Jupyter mode complete!\")\n",
    "    \n",
    "    return {\n",
    "        'mode': 'jupyter',\n",
    "        'image_index_df': image_index_df,\n",
    "        'image_index_df_path': str(df_path),\n",
    "        'prediction_results': prediction_output,\n",
    "        'organization_stats': organization_stats,\n",
    "        'poster_paths': poster_paths,\n",
    "        'output_dir': str(output_dir)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_parallel_inference_with_organization(\n",
    "    model_path: Union[str, Path],  # Path to the model file\n",
    "    image_path: Union[str, Path, List[Path]],  # Images or directory\n",
    "    output_dir: Union[str, Path],  # Output directory\n",
    "    batch_size: int = 100,  # Batch size\n",
    "    num_workers: Optional[int] = None,  # Number of workers\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    create_posters: bool = True,  # Whether to create posters\n",
    "    images_per_poster: int = 20,  # Images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Image size in poster\n",
    "    grid_cols: int = 5,  # Grid columns\n",
    "    save_heatmaps: bool = False,  # Save heatmaps\n",
    "    heatmap_style: str = \"side_by_side\",  # Heatmap style\n",
    "    copy_mode: bool = True,  # Copy or move files\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Execute inference in Parallel mode with threshold organization and poster creation.\n",
    "    \n",
    "    This mode uses multiprocessing.Pool for local parallel execution.\n",
    "    \"\"\"\n",
    "    print(\"\\nâš¡ PARALLEL MODE: Multiprocessing Execution with Organization\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # For parallel mode, we first run the distributed inference\n",
    "    # then collect all results and organize them\n",
    "    \n",
    "    print(\"\\nğŸ“Š Step 0-1: Running parallel inference (integrated)...\")\n",
    "    print(\"Note: Parallel mode runs predictions using multiprocessing\")\n",
    "    print(\"Results will be collected and then organized by threshold\")\n",
    "    \n",
    "    # Use the existing distribute_folder_inference with parallel setup\n",
    "    # We'll need to collect results afterwards for organization\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create image list file\n",
    "    image_paths = resolve_test_folders_smart(image_path)\n",
    "    batch_file = output_dir / \"parallel_batch_images.txt\"\n",
    "    create_batch_list_file(image_paths, batch_file)\n",
    "    \n",
    "    # Create image index\n",
    "    image_index_df = create_image_index_dataframe(batch_file)\n",
    "    df_path = output_dir / \"image_index.csv\"\n",
    "    image_index_df.to_csv(df_path, index=False)\n",
    "    \n",
    "    # Run predictions using the batch file\n",
    "    prediction_output = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=batch_file,\n",
    "        batch_id=\"parallel_batch\",\n",
    "        output_dir=output_dir,\n",
    "        save_results=True,\n",
    "        save_heatmap=save_heatmaps,\n",
    "        heatmap_style=heatmap_style,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    prediction_results = prediction_output.get('results', [])\n",
    "    \n",
    "    if not prediction_results:\n",
    "        print(\"âš ï¸  No prediction results to organize!\")\n",
    "        return {\n",
    "            'mode': 'parallel',\n",
    "            'image_index_df': image_index_df,\n",
    "            'prediction_results': prediction_output,\n",
    "            'organization_stats': None,\n",
    "            'poster_paths': None\n",
    "        }\n",
    "    \n",
    "    # Organize by score\n",
    "    print(\"\\nğŸ“ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=prediction_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Create posters\n",
    "    poster_paths = None\n",
    "    if create_posters:\n",
    "        print(\"\\nğŸ–¼ï¸  Step 3: Creating indexed posters...\")\n",
    "        poster_paths = create_posters_for_score_folders(\n",
    "            output_dir=output_dir,\n",
    "            image_index_df=image_index_df,\n",
    "            score_thresholds=score_thresholds,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols\n",
    "        )\n",
    "    \n",
    "    print(\"\\nâœ… Parallel mode complete!\")\n",
    "    \n",
    "    return {\n",
    "        'mode': 'parallel',\n",
    "        'num_workers': num_workers or cpu_count(),\n",
    "        'image_index_df': image_index_df,\n",
    "        'image_index_df_path': str(df_path),\n",
    "        'prediction_results': prediction_output,\n",
    "        'organization_stats': organization_stats,\n",
    "        'poster_paths': poster_paths,\n",
    "        'output_dir': str(output_dir)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_hpc_inference_with_organization(\n",
    "    model_path: Union[str, Path],  # Path to the model file\n",
    "    image_path: Union[str, Path],  # Images directory\n",
    "    output_dir: Union[str, Path],  # Output directory\n",
    "    batch_size: int = 100,  # Batch size\n",
    "    num_nodes: int = 10,  # Number of HPC nodes\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    create_posters: bool = True,  # Whether to create posters\n",
    "    images_per_poster: int = 20,  # Images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Image size in poster\n",
    "    grid_cols: int = 5,  # Grid columns\n",
    "    save_heatmaps: bool = False,  # Save heatmaps\n",
    "    heatmap_style: str = \"side_by_side\",  # Heatmap style\n",
    "    copy_mode: bool = True,  # Copy or move files\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Execute inference in HPC mode with threshold organization and poster creation.\n",
    "    \n",
    "    This mode distributes work across HPC cluster nodes using bsub.\n",
    "    After HPC jobs complete, results are organized and posters are created.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ–¥ï¸  HPC MODE: Distributed Cluster Execution with Organization\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create image list file\n",
    "    image_paths = resolve_test_folders_smart(image_path)\n",
    "    batch_file = output_dir / \"hpc_batch_images.txt\"\n",
    "    create_batch_list_file(image_paths, batch_file)\n",
    "    \n",
    "    # Create image index\n",
    "    print(\"\\nğŸ“Š Step 0: Creating image index dataframe...\")\n",
    "    image_index_df = create_image_index_dataframe(batch_file)\n",
    "    df_path = output_dir / \"image_index.csv\"\n",
    "    image_index_df.to_csv(df_path, index=False)\n",
    "    print(f\"ğŸ’¾ Saved: {df_path}\")\n",
    "    \n",
    "    # Run HPC distributed inference\n",
    "    print(\"\\nğŸ“Š Step 1: Running HPC distributed inference...\")\n",
    "    hpc_results = distribute_folder_inference(\n",
    "        root_path=image_path,\n",
    "        model_path=model_path,\n",
    "        output_dir=output_dir,\n",
    "        save_heatmaps=save_heatmaps,\n",
    "        heatmap_style=heatmap_style,\n",
    "        batch_size=batch_size,\n",
    "        num_nodes=num_nodes,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    # After HPC jobs complete, we need to collect results\n",
    "    # This would typically involve reading the result JSON files from each batch\n",
    "    print(\"\\nğŸ“¥ Collecting HPC results...\")\n",
    "    \n",
    "    # Load all batch results\n",
    "    all_results = []\n",
    "    batch_results_dir = output_dir / \"batch_lists\"\n",
    "    if batch_results_dir.exists():\n",
    "        for result_file in batch_results_dir.glob(\"**/batch_results_*.json\"):\n",
    "            try:\n",
    "                with open(result_file, 'r') as f:\n",
    "                    batch_data = json.load(f)\n",
    "                    if 'results' in batch_data:\n",
    "                        all_results.extend(batch_data['results'])\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Error loading {result_file}: {e}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"âš ï¸  No HPC results found to organize!\")\n",
    "        return {\n",
    "            'mode': 'hpc',\n",
    "            'num_nodes': num_nodes,\n",
    "            'image_index_df': image_index_df,\n",
    "            'hpc_results': hpc_results,\n",
    "            'organization_stats': None,\n",
    "            'poster_paths': None\n",
    "        }\n",
    "    \n",
    "    # Organize by score\n",
    "    print(\"\\nğŸ“ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=all_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Create posters\n",
    "    poster_paths = None\n",
    "    if create_posters:\n",
    "        print(\"\\nğŸ–¼ï¸  Step 3: Creating indexed posters...\")\n",
    "        poster_paths = create_posters_for_score_folders(\n",
    "            output_dir=output_dir,\n",
    "            image_index_df=image_index_df,\n",
    "            score_thresholds=score_thresholds,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols\n",
    "        )\n",
    "    \n",
    "    print(\"\\nâœ… HPC mode complete!\")\n",
    "    \n",
    "    return {\n",
    "        'mode': 'hpc',\n",
    "        'num_nodes': num_nodes,\n",
    "        'image_index_df': image_index_df,\n",
    "        'image_index_df_path': str(df_path),\n",
    "        'hpc_results': hpc_results,\n",
    "        'organization_stats': organization_stats,\n",
    "        'poster_paths': poster_paths,\n",
    "        'output_dir': str(output_dir)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified Interface\n",
    "\n",
    "The main function that automatically detects the environment and routes to the appropriate execution mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def unified_inference_with_threshold_posters(\n",
    "    model_path: Union[str, Path],  # Path to trained model\n",
    "    test_folders: Union[str, Path, List[Union[str, Path]]],  # Image folder(s) or file path(s)\n",
    "    output_dir: Optional[Union[str, Path]] = None,  # Output directory\n",
    "    execution_mode: str = \"auto\",  # \"auto\", \"jupyter\", \"hpc\", or \"parallel\"\n",
    "    batch_size: int = 100,  # Batch size\n",
    "    num_nodes: int = 10,  # Number of HPC nodes (for HPC mode)\n",
    "    num_workers: Optional[int] = None,  # Number of workers (for parallel mode)\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    create_posters: bool = True,  # Whether to create posters\n",
    "    images_per_poster: int = 20,  # Images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Image size in posters\n",
    "    grid_cols: int = 5,  # Grid columns in posters\n",
    "    save_heatmaps: bool = False,  # Save visualization heatmaps\n",
    "    heatmap_style: str = \"side_by_side\",  # Heatmap style\n",
    "    copy_mode: bool = True,  # Copy (True) or move (False) images\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Unified inference with automatic execution mode selection, threshold organization, and poster creation.\n",
    "    \n",
    "    This is the main entry point that:\n",
    "    1. Auto-detects or uses specified execution mode (Jupyter/Parallel/HPC)\n",
    "    2. Runs predictions using the selected mode\n",
    "    3. Organizes images into score-based threshold folders\n",
    "    4. Creates indexed posters for easy review\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained anomaly detection model\n",
    "        test_folders: Image folder(s), file path(s), or mixed\n",
    "        output_dir: Output directory (auto-generated if None)\n",
    "        execution_mode: Execution mode - \"auto\" detects environment, or specify \"jupyter\"/\"hpc\"/\"parallel\"\n",
    "        batch_size: Maximum images per batch\n",
    "        num_nodes: Number of HPC nodes (HPC mode only)\n",
    "        num_workers: Number of parallel workers (Parallel mode only, defaults to cpu_count())\n",
    "        score_thresholds: List of threshold values for organizing images\n",
    "            Examples:\n",
    "            - [0.5, 1.0] for simple two-folder setup\n",
    "            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization\n",
    "        create_posters: Whether to create image posters\n",
    "        images_per_poster: Number of images per poster\n",
    "        image_size: Size of each image in poster\n",
    "        grid_cols: Number of columns in poster grid\n",
    "        save_heatmaps: Whether to save visualization heatmaps\n",
    "        heatmap_style: Style of heatmap visualization\n",
    "        copy_mode: Whether to copy (True) or move (False) images when organizing\n",
    "        **kwargs: Additional arguments passed to inference functions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - mode: Execution mode used\n",
    "        - image_index_df: DataFrame with image indices\n",
    "        - prediction_results: Full prediction results\n",
    "        - organization_stats: Statistics about image organization\n",
    "        - poster_paths: Paths to created posters\n",
    "        - output_dir: Output directory path\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸš€ UNIFIED INFERENCE WITH THRESHOLD ORGANIZATION AND POSTERS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Auto-detect or validate execution mode\n",
    "    if execution_mode == \"auto\":\n",
    "        execution_mode = detect_execution_environment()\n",
    "        print(f\"ğŸ¯ Auto-detected mode: {execution_mode.upper()}\")\n",
    "    else:\n",
    "        if execution_mode not in [\"jupyter\", \"hpc\", \"parallel\"]:\n",
    "            raise ValueError(f\"Invalid execution_mode: {execution_mode}. Must be 'auto', 'jupyter', 'hpc', or 'parallel'\")\n",
    "        print(f\"ğŸ¯ Using specified mode: {execution_mode.upper()}\")\n",
    "    \n",
    "    # Set default output directory based on mode\n",
    "    if output_dir is None:\n",
    "        output_dir = f\"{execution_mode}_threshold_posters_results\"\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸ“‚ Output directory: {output_dir}\")\n",
    "    print(f\"ğŸ“Š Score thresholds: {score_thresholds}\")\n",
    "    print(f\"ğŸ–¼ï¸  Create posters: {create_posters}\")\n",
    "    \n",
    "    # Execute based on mode\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    if execution_mode == \"jupyter\":\n",
    "        results = run_jupyter_inference_with_organization(\n",
    "            model_path=model_path,\n",
    "            image_list=test_folders,\n",
    "            output_dir=output_dir,\n",
    "            score_thresholds=score_thresholds,\n",
    "            create_posters=create_posters,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            copy_mode=copy_mode,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    elif execution_mode == \"parallel\":\n",
    "        results = run_parallel_inference_with_organization(\n",
    "            model_path=model_path,\n",
    "            image_path=test_folders,\n",
    "            output_dir=output_dir,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            score_thresholds=score_thresholds,\n",
    "            create_posters=create_posters,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            copy_mode=copy_mode,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    elif execution_mode == \"hpc\":\n",
    "        results = run_hpc_inference_with_organization(\n",
    "            model_path=model_path,\n",
    "            image_path=test_folders,\n",
    "            output_dir=output_dir,\n",
    "            batch_size=batch_size,\n",
    "            num_nodes=num_nodes,\n",
    "            score_thresholds=score_thresholds,\n",
    "            create_posters=create_posters,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols,\n",
    "            save_heatmaps=save_heatmaps,\n",
    "            heatmap_style=heatmap_style,\n",
    "            copy_mode=copy_mode,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ‰ UNIFIED INFERENCE COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ… Execution mode: {results['mode'].upper()}\")\n",
    "    print(f\"ğŸ“‚ Output directory: {results['output_dir']}\")\n",
    "    \n",
    "    if 'image_index_df_path' in results:\n",
    "        print(f\"ğŸ“Š Image index CSV: {results['image_index_df_path']}\")\n",
    "    \n",
    "    if results.get('organization_stats'):\n",
    "        org_stats = results['organization_stats']\n",
    "        print(f\"ğŸ“ Images organized: {org_stats.get('total_processed', 0)}\")\n",
    "        print(f\"ğŸ“Š Folders created: {len(org_stats.get('folder_stats', {}))}\")\n",
    "    \n",
    "    if results.get('poster_paths'):\n",
    "        total_posters = sum(len(p) for p in results['poster_paths'].values())\n",
    "        print(f\"ğŸ–¼ï¸  Posters created: {total_posters}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example 1: Auto-detect mode with simple two-folder organization\n",
    "results = unified_inference_with_threshold_posters(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    test_folders=\"path/to/images\",\n",
    "    score_thresholds=[0.5, 1.0],  # Simple: normal vs anomaly\n",
    "    create_posters=True,\n",
    "    images_per_poster=20\n",
    ")\n",
    "\n",
    "# Example 2: Force Jupyter mode with detailed organization\n",
    "results = unified_inference_with_threshold_posters(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    test_folders=\"path/to/images\",\n",
    "    execution_mode=\"jupyter\",\n",
    "    score_thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    create_posters=True,\n",
    "    save_heatmaps=True\n",
    ")\n",
    "\n",
    "# Example 3: HPC mode for large datasets\n",
    "results = unified_inference_with_threshold_posters(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    test_folders=\"path/to/large/dataset\",\n",
    "    execution_mode=\"hpc\",\n",
    "    batch_size=200,\n",
    "    num_nodes=20,\n",
    "    score_thresholds=[0.5, 1.0],\n",
    "    images_per_poster=50,\n",
    "    grid_cols=10\n",
    ")\n",
    "\n",
    "# Example 4: Parallel mode with custom workers\n",
    "results = unified_inference_with_threshold_posters(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    test_folders=[\"folder1/\", \"folder2/\", \"folder3/\"],\n",
    "    execution_mode=\"parallel\",\n",
    "    num_workers=8,\n",
    "    score_thresholds=[0.25, 0.5, 0.75, 1.0],\n",
    "    create_posters=True,\n",
    "    copy_mode=False  # Move files instead of copying\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Structure\n",
    "\n",
    "After running, you get:\n",
    "\n",
    "```\n",
    "output_dir/\n",
    "â”œâ”€â”€ image_index.csv              # CSV with all image indices for reference\n",
    "â”œâ”€â”€ 0.3/\n",
    "â”‚   â”œâ”€â”€ image1.jpg\n",
    "â”‚   â”œâ”€â”€ image2.jpg\n",
    "â”‚   â”œâ”€â”€ poster_001.png           # Poster with indexed images\n",
    "â”‚   â””â”€â”€ metadata.json\n",
    "â”œâ”€â”€ 0.5/\n",
    "â”‚   â”œâ”€â”€ image3.jpg\n",
    "â”‚   â”œâ”€â”€ poster_001.png\n",
    "â”‚   â””â”€â”€ metadata.json\n",
    "â”œâ”€â”€ 0.7/\n",
    "â”‚   â”œâ”€â”€ image4.jpg\n",
    "â”‚   â”œâ”€â”€ poster_001.png\n",
    "â”‚   â”œâ”€â”€ poster_002.png           # Multiple posters if needed\n",
    "â”‚   â””â”€â”€ metadata.json\n",
    "â””â”€â”€ 1.0/\n",
    "    â”œâ”€â”€ image5.jpg\n",
    "    â”œâ”€â”€ poster_001.png\n",
    "    â””â”€â”€ metadata.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
