{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.anomaly_score_organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Organizer\n",
    "\n",
    "> Organize and save images based on their anomaly scores into customizable threshold folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\nimport os\nimport json\nimport shutil\nfrom pathlib import Path\nfrom typing import Union, List, Dict, Any, Optional, Tuple\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image, ImageDraw, ImageFont\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfrom fastcore.all import *\nfrom fastcore.test import *"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Import from existing modules\n",
    "from vision_ad_tool.inference.prediction_system import (\n",
    "    predict_image_list_from_file_enhanced,\n",
    "    predict_image_list\n",
    ")\n",
    "\n",
    "from vision_ad_tool.inference.multinode_inference import (\n",
    "    create_smart_batches,\n",
    "    scan_folder_structure,\n",
    "    create_batch_list_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def determine_score_folder(\n",
    "    anomaly_score: float,  # Anomaly score (0.0 to 1.0)\n",
    "    score_thresholds: List[float]  # List of score thresholds (e.g., [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    ") -> str:  # Returns the folder name based on the score\n",
    "    \"\"\"\n",
    "    Determine which folder an image should go to based on its anomaly score.\n",
    "    \n",
    "    The image is placed in the folder corresponding to the smallest threshold that is >= the score.\n",
    "    \n",
    "    Example:\n",
    "        score_thresholds = [0.5, 1.0]\n",
    "        - score 0.3 -> folder \"0.5\"\n",
    "        - score 0.7 -> folder \"1.0\"\n",
    "    \"\"\"\n",
    "    # Sort thresholds to ensure correct ordering\n",
    "    sorted_thresholds = sorted(score_thresholds)\n",
    "    \n",
    "    # Find the appropriate folder\n",
    "    for threshold in sorted_thresholds:\n",
    "        if anomaly_score <= threshold:\n",
    "            return str(threshold)\n",
    "    \n",
    "    # If score exceeds all thresholds, use the last one\n",
    "    return str(sorted_thresholds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_score_folders(\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float]  # List of score thresholds\n",
    ") -> Dict[str, Path]:  # Returns dict mapping threshold strings to folder paths\n",
    "    \"\"\"\n",
    "    Create subdirectories for each score threshold.\n",
    "    \n",
    "    Returns a dictionary mapping threshold values to their folder paths.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    folder_map = {}\n",
    "    \n",
    "    for threshold in score_thresholds:\n",
    "        folder_name = str(threshold)\n",
    "        folder_path = output_dir / folder_name\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        folder_map[folder_name] = folder_path\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(folder_map)} score folders in {output_dir}\")\n",
    "    for threshold, path in sorted(folder_map.items()):\n",
    "        print(f\"   üìÅ {threshold}: {path}\")\n",
    "    \n",
    "    return folder_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_image_by_score(\n",
    "    image_path: Union[str, Path],  # Path to the source image\n",
    "    anomaly_score: float,  # Anomaly score for the image\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    "    copy_mode: bool = True  # If True, copy files; if False, move files\n",
    ") -> Path:  # Returns the destination path\n",
    "    \"\"\"\n",
    "    Save (copy or move) an image to the appropriate score folder.\n",
    "    \n",
    "    Returns the destination path where the image was saved.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "    \n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    # Determine target folder\n",
    "    folder_name = determine_score_folder(anomaly_score, score_thresholds)\n",
    "    target_folder = output_dir / folder_name\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create destination path\n",
    "    dest_path = target_folder / image_path.name\n",
    "    \n",
    "    # Copy or move the file\n",
    "    if copy_mode:\n",
    "        shutil.copy2(image_path, dest_path)\n",
    "    else:\n",
    "        shutil.move(str(image_path), str(dest_path))\n",
    "    \n",
    "    return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def organize_images_by_score(\n",
    "    prediction_results: List[Dict[str, Any]],  # List of prediction results from predict_image_list\n",
    "    output_dir: Union[str, Path],  # Base output directory\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    copy_mode: bool = True,  # If True, copy files; if False, move files\n",
    "    save_metadata: bool = True  # If True, save metadata JSON for each folder\n",
    ") -> Dict[str, Any]:  # Returns organization statistics\n",
    "    \"\"\"\n",
    "    Organize images into folders based on their anomaly scores.\n",
    "    \n",
    "    Args:\n",
    "        prediction_results: List of prediction results, each containing 'image_path' and 'anomaly_score'\n",
    "        output_dir: Base directory where score folders will be created\n",
    "        score_thresholds: List of threshold values (e.g., [0.5, 1.0] for simple two-folder setup)\n",
    "        copy_mode: Whether to copy (True) or move (False) images\n",
    "        save_metadata: Whether to save JSON metadata for each folder\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with organization statistics\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\nüóÇÔ∏è  ORGANIZING IMAGES BY ANOMALY SCORE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìÇ Output directory: {output_dir}\")\n",
    "    print(f\"üìä Score thresholds: {score_thresholds}\")\n",
    "    print(f\"üìã Total images: {len(prediction_results)}\")\n",
    "    print(f\"üîÑ Mode: {'COPY' if copy_mode else 'MOVE'}\")\n",
    "    \n",
    "    # Create score folders\n",
    "    folder_map = create_score_folders(output_dir, score_thresholds)\n",
    "    \n",
    "    # Track statistics\n",
    "    folder_stats = {str(t): {'count': 0, 'images': [], 'scores': []} for t in score_thresholds}\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(\"\\nüì¶ Processing images...\")\n",
    "    \n",
    "    # Process each image\n",
    "    for result in tqdm(prediction_results, desc=\"Organizing images\"):\n",
    "        try:\n",
    "            image_path = result.get('image_path')\n",
    "            anomaly_score = result.get('anomaly_score')\n",
    "            \n",
    "            if image_path is None or anomaly_score is None:\n",
    "                print(f\"‚ö†Ô∏è  Skipping result with missing data: {result}\")\n",
    "                failed_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Save image to appropriate folder\n",
    "            dest_path = save_image_by_score(\n",
    "                image_path=image_path,\n",
    "                anomaly_score=anomaly_score,\n",
    "                output_dir=output_dir,\n",
    "                score_thresholds=score_thresholds,\n",
    "                copy_mode=copy_mode\n",
    "            )\n",
    "            \n",
    "            # Update statistics\n",
    "            folder_name = determine_score_folder(anomaly_score, score_thresholds)\n",
    "            folder_stats[folder_name]['count'] += 1\n",
    "            folder_stats[folder_name]['images'].append(str(dest_path))\n",
    "            folder_stats[folder_name]['scores'].append(float(anomaly_score))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {result.get('image_path', 'unknown')}: {e}\")\n",
    "            failed_count += 1\n",
    "    \n",
    "    # Save metadata for each folder if requested\n",
    "    if save_metadata:\n",
    "        print(\"\\nüíæ Saving metadata...\")\n",
    "        for folder_name, stats in folder_stats.items():\n",
    "            if stats['count'] > 0:\n",
    "                metadata_path = folder_map[folder_name] / \"metadata.json\"\n",
    "                metadata = {\n",
    "                    'threshold': folder_name,\n",
    "                    'count': stats['count'],\n",
    "                    'avg_score': float(np.mean(stats['scores'])) if stats['scores'] else 0.0,\n",
    "                    'min_score': float(np.min(stats['scores'])) if stats['scores'] else 0.0,\n",
    "                    'max_score': float(np.max(stats['scores'])) if stats['scores'] else 0.0,\n",
    "                    'images': stats['images']\n",
    "                }\n",
    "                with open(metadata_path, 'w') as f:\n",
    "                    json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nüìä ORGANIZATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for threshold in sorted(score_thresholds):\n",
    "        folder_name = str(threshold)\n",
    "        count = folder_stats[folder_name]['count']\n",
    "        if count > 0:\n",
    "            avg_score = np.mean(folder_stats[folder_name]['scores'])\n",
    "            print(f\"üìÅ Folder '{folder_name}': {count} images (avg score: {avg_score:.4f})\")\n",
    "    \n",
    "    if failed_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Failed: {failed_count} images\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Organization complete!\")\n",
    "    \n",
    "    return {\n",
    "        'output_dir': str(output_dir),\n",
    "        'score_thresholds': score_thresholds,\n",
    "        'folder_stats': {k: {'count': v['count'], \n",
    "                             'avg_score': float(np.mean(v['scores'])) if v['scores'] else 0.0}\n",
    "                        for k, v in folder_stats.items()},\n",
    "        'total_processed': len(prediction_results) - failed_count,\n",
    "        'failed_count': failed_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef create_posters_for_score_folders(\n    output_dir: Union[str, Path],  # Base output directory with score folders\n    image_index_df: pd.DataFrame,  # Dataframe with image indices\n    score_thresholds: List[float],  # List of score thresholds\n    images_per_poster: int = 20,  # Number of images per poster\n    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster\n    grid_cols: int = 5,  # Number of columns in the grid\n    annotate_with_index: bool = True,  # Whether to add index numbers\n    font_size: int = 30  # Font size for index numbers\n) -> Dict[str, List[Path]]:  # Returns dict mapping folder names to poster paths\n    \"\"\"\n    Create posters for all score folders.\n    \n    This function processes each score folder and creates one or more posters\n    depending on the number of images in each folder.\n    \n    Args:\n        output_dir: Base directory containing score folders\n        image_index_df: DataFrame with image indices\n        score_thresholds: List of threshold values\n        images_per_poster: How many images per poster\n        image_size: Size of each image in the poster\n        grid_cols: Number of columns in the grid\n        annotate_with_index: Whether to annotate images with indices\n        font_size: Font size for annotations\n    \n    Returns:\n        Dictionary mapping folder names to list of poster paths\n    \"\"\"\n    output_dir = Path(output_dir)\n    poster_paths = {}\n    \n    print(\"\\nüñºÔ∏è  CREATING POSTERS FOR SCORE FOLDERS\")\n    print(\"=\"*70)\n    \n    for threshold in score_thresholds:\n        folder_name = str(threshold)\n        folder_path = output_dir / folder_name\n        \n        if not folder_path.exists():\n            print(f\"‚ö†Ô∏è  Folder {folder_name} does not exist, skipping...\")\n            continue\n        \n        # Get all images in folder (excluding metadata.json)\n        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n        images_in_folder = []\n        for ext in image_extensions:\n            images_in_folder.extend(folder_path.glob(f\"*{ext}\"))\n            images_in_folder.extend(folder_path.glob(f\"*{ext.upper()}\"))\n        \n        images_in_folder = sorted(set(images_in_folder))\n        \n        if not images_in_folder:\n            print(f\"üìÅ Folder '{folder_name}': No images found\")\n            continue\n        \n        print(f\"\\nüìÅ Processing folder '{folder_name}': {len(images_in_folder)} images\")\n        \n        # Calculate number of posters needed\n        num_posters = int(np.ceil(len(images_in_folder) / images_per_poster))\n        folder_poster_paths = []\n        \n        # Create posters\n        for poster_idx in range(num_posters):\n            start_idx = poster_idx * images_per_poster\n            end_idx = min((poster_idx + 1) * images_per_poster, len(images_in_folder))\n            \n            # Create a temporary folder for this subset\n            poster_output_path = folder_path / f\"poster_{poster_idx + 1:03d}.png\"\n            \n            # Get subset of images for this poster\n            poster_images = images_in_folder[start_idx:end_idx]\n            \n            # Create temporary folder with subset\n            temp_folder = folder_path / f\"_temp_poster_{poster_idx}\"\n            temp_folder.mkdir(exist_ok=True)\n            \n            # Copy images to temp folder\n            for img in poster_images:\n                shutil.copy2(img, temp_folder / img.name)\n            \n            # Create poster\n            try:\n                poster_path = create_poster_from_folder(\n                    folder_path=temp_folder,\n                    image_index_df=image_index_df,\n                    output_path=poster_output_path,\n                    images_per_poster=images_per_poster,\n                    poster_index=poster_idx,\n                    image_size=image_size,\n                    grid_cols=grid_cols,\n                    annotate_with_index=annotate_with_index,\n                    font_size=font_size,\n                    title=f\"Score Folder {folder_name}\"\n                )\n                \n                if poster_path:\n                    folder_poster_paths.append(poster_path)\n                    print(f\"  ‚úÖ Created poster {poster_idx + 1}/{num_posters}: {len(poster_images)} images\")\n            \n            finally:\n                # Clean up temp folder\n                shutil.rmtree(temp_folder, ignore_errors=True)\n        \n        if folder_poster_paths:\n            poster_paths[folder_name] = folder_poster_paths\n            print(f\"üìä Folder '{folder_name}': Created {len(folder_poster_paths)} poster(s)\")\n    \n    print(\"\\n‚úÖ Poster creation complete!\")\n    print(f\"   Total folders processed: {len(poster_paths)}\")\n    print(f\"   Total posters created: {sum(len(p) for p in poster_paths.values())}\")\n    \n    return poster_paths",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef predict_and_organize_by_score(\n    model_path: Union[str, Path],  # Path to the trained model\n    image_list_file: Union[str, Path],  # Text file with image paths (one per line)\n    output_dir: Union[str, Path],  # Base output directory for organized images\n    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n    batch_id: Optional[str] = None,  # Optional batch identifier\n    copy_mode: bool = True,  # If True, copy files; if False, move files\n    save_metadata: bool = True,  # If True, save metadata JSON for each folder\n    create_posters: bool = True,  # If True, create posters for each score folder\n    images_per_poster: int = 20,  # Number of images per poster\n    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster\n    grid_cols: int = 5,  # Number of columns in poster grid\n    annotate_with_index: bool = True,  # Whether to add index numbers to images in posters\n    font_size: int = 30,  # Font size for index annotations\n    device: str = \"auto\",  # Device for inference (\"auto\", \"cpu\", \"cuda\")\n    **kwargs  # Additional arguments passed to prediction function\n) -> Dict[str, Any]:  # Returns combined prediction and organization results\n    \"\"\"\n    Complete workflow: Predict anomaly scores, organize images, and create indexed posters.\n    \n    This is the main function that combines:\n    1. Image index dataframe creation\n    2. Smart batch creation\n    3. Prediction using predict_image_list_from_file_enhanced\n    4. Image organization based on anomaly scores\n    5. Poster creation with index annotations (optional)\n    \n    Args:\n        model_path: Path to the trained anomaly detection model\n        image_list_file: Text file containing paths to images (one per line)\n        output_dir: Directory where score-based folders will be created\n        score_thresholds: List of threshold values (customize to your needs)\n            Examples:\n            - [0.5, 1.0] for simple two-folder setup\n            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization\n        batch_id: Optional identifier for this batch\n        copy_mode: Whether to copy (True) or move (False) images\n        save_metadata: Whether to save JSON metadata for each folder\n        create_posters: Whether to create image posters for each score folder\n        images_per_poster: Number of images to include in each poster\n        image_size: Size to resize each image to in posters\n        grid_cols: Number of columns in the poster grid\n        annotate_with_index: Whether to annotate images with their dataframe index\n        font_size: Font size for index annotations\n        device: Device to use for inference\n        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)\n    \n    Returns:\n        Dictionary containing:\n        - image_index_df: DataFrame with image indices\n        - prediction_results: Full prediction results\n        - organization_stats: Statistics about image organization\n        - poster_paths: Paths to created posters (if create_posters=True)\n    \"\"\"\n    print(\"\\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE WITH INDEXED POSTERS\")\n    print(\"=\"*70)\n    \n    # Step 0: Create image index dataframe\n    print(\"\\nüìä Step 0: Creating image index dataframe...\")\n    image_index_df = create_image_index_dataframe(image_list_file)\n    \n    # Save the dataframe\n    output_dir_path = Path(output_dir)\n    output_dir_path.mkdir(parents=True, exist_ok=True)\n    df_path = output_dir_path / \"image_index.csv\"\n    image_index_df.to_csv(df_path, index=False)\n    print(f\"üíæ Saved image index dataframe to {df_path}\")\n    \n    # Step 1: Run predictions\n    print(\"\\nüìä Step 1: Running predictions...\")\n    prediction_output = predict_image_list_from_file_enhanced(\n        model_path=model_path,\n        image_list_file=image_list_file,\n        batch_id=batch_id,\n        output_dir=output_dir,\n        device=device,\n        save_results=True,\n        **kwargs\n    )\n    \n    # Extract results\n    prediction_results = prediction_output.get('results', [])\n    \n    if not prediction_results:\n        print(\"‚ö†Ô∏è  No prediction results to organize!\")\n        return {\n            'image_index_df': image_index_df,\n            'prediction_results': prediction_output,\n            'organization_stats': None,\n            'poster_paths': None\n        }\n    \n    print(f\"‚úÖ Predictions complete: {len(prediction_results)} images processed\")\n    \n    # Step 2: Organize images by score\n    print(\"\\nüìÅ Step 2: Organizing images by score...\")\n    organization_stats = organize_images_by_score(\n        prediction_results=prediction_results,\n        output_dir=output_dir,\n        score_thresholds=score_thresholds,\n        copy_mode=copy_mode,\n        save_metadata=save_metadata\n    )\n    \n    # Step 3: Create posters (optional)\n    poster_paths = None\n    if create_posters:\n        print(\"\\nüñºÔ∏è  Step 3: Creating indexed posters...\")\n        poster_paths = create_posters_for_score_folders(\n            output_dir=output_dir,\n            image_index_df=image_index_df,\n            score_thresholds=score_thresholds,\n            images_per_poster=images_per_poster,\n            image_size=image_size,\n            grid_cols=grid_cols,\n            annotate_with_index=annotate_with_index,\n            font_size=font_size\n        )\n    \n    print(\"\\nüéâ WORKFLOW COMPLETE!\")\n    print(\"=\"*70)\n    print(f\"üìä Image index dataframe: {df_path}\")\n    print(f\"üìÅ Organized images: {output_dir}\")\n    if poster_paths:\n        total_posters = sum(len(p) for p in poster_paths.values())\n        print(f\"üñºÔ∏è  Created {total_posters} poster(s)\")\n    \n    return {\n        'image_index_df': image_index_df,\n        'image_index_df_path': str(df_path),\n        'prediction_results': prediction_output,\n        'organization_stats': organization_stats,\n        'poster_paths': poster_paths\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef annotate_image_with_index(\n    image: Union[Image.Image, np.ndarray],  # PIL Image or numpy array\n    index: int,  # Index number to display\n    font_size: int = 40,  # Font size for the index number\n    position: str = \"top_left\",  # Position: \"top_left\", \"top_right\", \"bottom_left\", \"bottom_right\"\n    text_color: Tuple[int, int, int] = (255, 255, 0),  # RGB color for text (yellow)\n    bg_color: Tuple[int, int, int, int] = (0, 0, 0, 180)  # RGBA color for background (semi-transparent black)\n) -> Image.Image:  # Returns annotated PIL Image\n    \"\"\"\n    Add an index number to an image.\n    \n    Args:\n        image: Input image (PIL Image or numpy array)\n        index: Index number to display\n        font_size: Size of the font\n        position: Where to place the index number\n        text_color: RGB tuple for text color\n        bg_color: RGBA tuple for background color (includes alpha for transparency)\n    \n    Returns:\n        PIL Image with index number annotated\n    \"\"\"\n    # Convert to PIL Image if numpy array\n    if isinstance(image, np.ndarray):\n        image = Image.fromarray(image)\n    \n    # Make a copy to avoid modifying original\n    img_copy = image.copy().convert(\"RGBA\")\n    \n    # Create a transparent overlay\n    overlay = Image.new('RGBA', img_copy.size, (255, 255, 255, 0))\n    draw = ImageDraw.Draw(overlay)\n    \n    # Try to use a nice font, fall back to default if not available\n    try:\n        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", font_size)\n    except:\n        try:\n            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n        except:\n            font = ImageFont.load_default()\n    \n    # Prepare text\n    text = f\"#{index}\"\n    \n    # Get text bounding box\n    bbox = draw.textbbox((0, 0), text, font=font)\n    text_width = bbox[2] - bbox[0]\n    text_height = bbox[3] - bbox[1]\n    \n    # Add padding\n    padding = 10\n    box_width = text_width + 2 * padding\n    box_height = text_height + 2 * padding\n    \n    # Calculate position\n    img_width, img_height = img_copy.size\n    \n    if position == \"top_left\":\n        x, y = padding, padding\n    elif position == \"top_right\":\n        x, y = img_width - box_width - padding, padding\n    elif position == \"bottom_left\":\n        x, y = padding, img_height - box_height - padding\n    elif position == \"bottom_right\":\n        x, y = img_width - box_width - padding, img_height - box_height - padding\n    else:\n        x, y = padding, padding  # default to top_left\n    \n    # Draw semi-transparent background rectangle\n    draw.rectangle(\n        [x, y, x + box_width, y + box_height],\n        fill=bg_color\n    )\n    \n    # Draw text\n    draw.text(\n        (x + padding, y + padding),\n        text,\n        font=font,\n        fill=text_color\n    )\n    \n    # Composite the overlay onto the image\n    result = Image.alpha_composite(img_copy, overlay)\n    \n    # Convert back to RGB\n    return result.convert(\"RGB\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef create_image_index_dataframe(\n    image_list: Union[List[Union[str, Path]], str, Path]  # List of images or path to text file\n) -> pd.DataFrame:  # Returns dataframe with index and image paths\n    \"\"\"\n    Create a dataframe with index numbers for all images.\n    \n    This dataframe is used to track and reference images by index number\n    when creating posters.\n    \n    Args:\n        image_list: Either a list of image paths or a path to text file containing image paths\n    \n    Returns:\n        DataFrame with columns: ['index', 'image_path', 'image_name']\n    \"\"\"\n    # Handle input - could be list or file path\n    if isinstance(image_list, (str, Path)):\n        # Read from file\n        image_list_path = Path(image_list)\n        if image_list_path.exists() and image_list_path.is_file():\n            images = []\n            with open(image_list_path, 'r') as f:\n                for line in f:\n                    line = line.strip()\n                    if line and not line.startswith('#'):\n                        images.append(line)\n        else:\n            raise FileNotFoundError(f\"Image list file not found: {image_list}\")\n    else:\n        images = [str(img) for img in image_list]\n    \n    # Create dataframe\n    df = pd.DataFrame({\n        'index': range(len(images)),\n        'image_path': images,\n        'image_name': [Path(img).name for img in images]\n    })\n    \n    print(f\"üìä Created image index dataframe with {len(df)} images\")\n    \n    return df",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Image Indexing and Poster Creation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Workflow Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_and_organize_by_score(\n",
    "    model_path: Union[str, Path],  # Path to the trained model\n",
    "    image_list_file: Union[str, Path],  # Text file with image paths (one per line)\n",
    "    output_dir: Union[str, Path],  # Base output directory for organized images\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    batch_id: Optional[str] = None,  # Optional batch identifier\n",
    "    copy_mode: bool = True,  # If True, copy files; if False, move files\n",
    "    save_metadata: bool = True,  # If True, save metadata JSON for each folder\n",
    "    device: str = \"auto\",  # Device for inference (\"auto\", \"cpu\", \"cuda\")\n",
    "    **kwargs  # Additional arguments passed to prediction function\n",
    ") -> Dict[str, Any]:  # Returns combined prediction and organization results\n",
    "    \"\"\"\n",
    "    Complete workflow: Predict anomaly scores and organize images into score-based folders.\n",
    "    \n",
    "    This is the main function that combines:\n",
    "    1. Smart batch creation\n",
    "    2. Prediction using predict_image_list_from_file_enhanced\n",
    "    3. Image organization based on anomaly scores\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained anomaly detection model\n",
    "        image_list_file: Text file containing paths to images (one per line)\n",
    "        output_dir: Directory where score-based folders will be created\n",
    "        score_thresholds: List of threshold values (customize to your needs)\n",
    "            Examples:\n",
    "            - [0.5, 1.0] for simple two-folder setup\n",
    "            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization\n",
    "        batch_id: Optional identifier for this batch\n",
    "        copy_mode: Whether to copy (True) or move (False) images\n",
    "        save_metadata: Whether to save JSON metadata for each folder\n",
    "        device: Device to use for inference\n",
    "        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - prediction_results: Full prediction results\n",
    "        - organization_stats: Statistics about image organization\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Step 1: Run predictions\n",
    "    print(\"\\nüìä Step 1: Running predictions...\")\n",
    "    prediction_output = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=image_list_file,\n",
    "        batch_id=batch_id,\n",
    "        output_dir=output_dir,\n",
    "        device=device,\n",
    "        save_results=True,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    # Extract results\n",
    "    prediction_results = prediction_output.get('results', [])\n",
    "    \n",
    "    if not prediction_results:\n",
    "        print(\"‚ö†Ô∏è  No prediction results to organize!\")\n",
    "        return {\n",
    "            'prediction_results': prediction_output,\n",
    "            'organization_stats': None\n",
    "        }\n",
    "    \n",
    "    print(f\"‚úÖ Predictions complete: {len(prediction_results)} images processed\")\n",
    "    \n",
    "    # Step 2: Organize images by score\n",
    "    print(\"\\nüìÅ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=prediction_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=save_metadata\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ WORKFLOW COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'prediction_results': prediction_output,\n",
    "        'organization_stats': organization_stats\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example 1: Simple two-folder organization (low vs high anomaly)\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.5, 1.0],  # Two folders: 0.5 (normal) and 1.0 (anomaly)\n",
    "    copy_mode=True\n",
    ")\n",
    "\n",
    "# Example 2: Fine-grained organization with 8 score folders\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    copy_mode=True,\n",
    "    save_heatmap=True,\n",
    "    heatmap_style=\"side_by_side\"\n",
    ")\n",
    "\n",
    "# Example 3: Custom thresholds\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.25, 0.5, 0.75, 1.0],  # Four folders\n",
    "    copy_mode=False  # Move files instead of copying\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test determine_score_folder\n",
    "test_eq(determine_score_folder(0.3, [0.5, 1.0]), \"0.5\")\n",
    "test_eq(determine_score_folder(0.7, [0.5, 1.0]), \"1.0\")\n",
    "test_eq(determine_score_folder(0.45, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), \"0.5\")\n",
    "test_eq(determine_score_folder(0.85, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), \"0.9\")\n",
    "print(\"‚úÖ All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}