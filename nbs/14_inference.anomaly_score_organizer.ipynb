{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.anomaly_score_organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Organizer\n",
    "\n",
    "> Organize and save images based on their anomaly scores into customizable threshold folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from typing import Union, List, Dict, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup for Trial and Error\n",
    "\n",
    "> Helper functions to set up training and testing data for experimentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def setup_trial_data(\n",
    "    data_root: Union[str, Path],  # Root directory containing data\n",
    "    normal_dir: str = \"good\",  # Normal images subdirectory\n",
    "    abnormal_dir: str = \"bad\",  # Abnormal images subdirectory\n",
    "    train_split: float = 0.7,  # Training split ratio\n",
    "    val_split: float = 0.15,  # Validation split ratio\n",
    "    test_split: float = 0.15,  # Test split ratio\n",
    "    output_dir: Optional[Union[str, Path]] = None,  # Output directory for data lists\n",
    "    seed: int = 42  # Random seed for reproducibility\n",
    ") -> Dict[str, Path]:  # Returns dict with paths to train/val/test image list files\n",
    "    \"\"\"\n",
    "    Set up training, validation, and test data splits for trial and error.\n",
    "\n",
    "    Creates text files with image paths for each split that can be used\n",
    "    for training and inference.\n",
    "\n",
    "    Example:\n",
    "        data_paths = setup_trial_data(\n",
    "            data_root=\"/path/to/data\",\n",
    "            normal_dir=\"good\",\n",
    "            abnormal_dir=\"bad\",\n",
    "            train_split=0.7,\n",
    "            val_split=0.15,\n",
    "            test_split=0.15\n",
    "        )\n",
    "        # Use data_paths['train_normal'] for training normal images\n",
    "    \"\"\"\n",
    "    data_root = Path(data_root)\n",
    "    if not data_root.exists():\n",
    "        raise FileNotFoundError(f\"Data root not found: {data_root}\")\n",
    "\n",
    "    normal_path = data_root / normal_dir\n",
    "    abnormal_path = data_root / abnormal_dir\n",
    "\n",
    "    if not normal_path.exists():\n",
    "        raise FileNotFoundError(f\"Normal directory not found: {normal_path}\")\n",
    "    if not abnormal_path.exists():\n",
    "        raise FileNotFoundError(f\"Abnormal directory not found: {abnormal_path}\")\n",
    "\n",
    "    # Validate splits\n",
    "    if abs(train_split + val_split + test_split - 1.0) > 1e-6:\n",
    "        raise ValueError(f\"Splits must sum to 1.0, got {train_split + val_split + test_split}\")\n",
    "\n",
    "    # Set output directory\n",
    "    if output_dir is None:\n",
    "        output_dir = data_root / \"data_splits\"\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all images\n",
    "    normal_images = get_images_(normal_path)\n",
    "    abnormal_images = get_images_(abnormal_path)\n",
    "\n",
    "    print(f\"üìä Found {len(normal_images)} normal images\")\n",
    "    print(f\"üìä Found {len(abnormal_images)} abnormal images\")\n",
    "\n",
    "    # Shuffle with seed for reproducibility\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    random.shuffle(normal_images)\n",
    "    random.shuffle(abnormal_images)\n",
    "\n",
    "    # Split normal images\n",
    "    n_train_norm = int(len(normal_images) * train_split)\n",
    "    n_val_norm = int(len(normal_images) * val_split)\n",
    "\n",
    "    train_normal = normal_images[:n_train_norm]\n",
    "    val_normal = normal_images[n_train_norm:n_train_norm + n_val_norm]\n",
    "    test_normal = normal_images[n_train_norm + n_val_norm:]\n",
    "\n",
    "    # Split abnormal images\n",
    "    n_train_abnorm = int(len(abnormal_images) * train_split)\n",
    "    n_val_abnorm = int(len(abnormal_images) * val_split)\n",
    "\n",
    "    train_abnormal = abnormal_images[:n_train_abnorm]\n",
    "    val_abnormal = abnormal_images[n_train_abnorm:n_train_abnorm + n_val_abnorm]\n",
    "    test_abnormal = abnormal_images[n_train_abnorm + n_val_abnorm:]\n",
    "\n",
    "    # Save to files\n",
    "    def save_image_list(images: List[Path], filepath: Path) -> None:\n",
    "        \"\"\"Save list of image paths to text file.\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            for img in images:\n",
    "                f.write(f\"{img}\\n\")\n",
    "\n",
    "    result_paths = {}\n",
    "\n",
    "    # Training data\n",
    "    train_normal_file = output_dir / \"train_normal.txt\"\n",
    "    train_abnormal_file = output_dir / \"train_abnormal.txt\"\n",
    "    save_image_list(train_normal, train_normal_file)\n",
    "    save_image_list(train_abnormal, train_abnormal_file)\n",
    "    result_paths['train_normal'] = train_normal_file\n",
    "    result_paths['train_abnormal'] = train_abnormal_file\n",
    "\n",
    "    # Validation data\n",
    "    val_normal_file = output_dir / \"val_normal.txt\"\n",
    "    val_abnormal_file = output_dir / \"val_abnormal.txt\"\n",
    "    save_image_list(val_normal, val_normal_file)\n",
    "    save_image_list(val_abnormal, val_abnormal_file)\n",
    "    result_paths['val_normal'] = val_normal_file\n",
    "    result_paths['val_abnormal'] = val_abnormal_file\n",
    "\n",
    "    # Test data\n",
    "    test_normal_file = output_dir / \"test_normal.txt\"\n",
    "    test_abnormal_file = output_dir / \"test_abnormal.txt\"\n",
    "    save_image_list(test_normal, test_normal_file)\n",
    "    save_image_list(test_abnormal, test_abnormal_file)\n",
    "    result_paths['test_normal'] = test_normal_file\n",
    "    result_paths['test_abnormal'] = test_abnormal_file\n",
    "\n",
    "    # Combined test file (for inference)\n",
    "    test_all_file = output_dir / \"test_all.txt\"\n",
    "    save_image_list(test_normal + test_abnormal, test_all_file)\n",
    "    result_paths['test_all'] = test_all_file\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n‚úÖ Data splits created in {output_dir}\")\n",
    "    print(f\"   Train: {len(train_normal)} normal, {len(train_abnormal)} abnormal\")\n",
    "    print(f\"   Val:   {len(val_normal)} normal, {len(val_abnormal)} abnormal\")\n",
    "    print(f\"   Test:  {len(test_normal)} normal, {len(test_abnormal)} abnormal\")\n",
    "\n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'data_root': str(data_root),\n",
    "        'normal_dir': normal_dir,\n",
    "        'abnormal_dir': abnormal_dir,\n",
    "        'splits': {\n",
    "            'train': train_split,\n",
    "            'val': val_split,\n",
    "            'test': test_split\n",
    "        },\n",
    "        'counts': {\n",
    "            'train_normal': len(train_normal),\n",
    "            'train_abnormal': len(train_abnormal),\n",
    "            'val_normal': len(val_normal),\n",
    "            'val_abnormal': len(val_abnormal),\n",
    "            'test_normal': len(test_normal),\n",
    "            'test_abnormal': len(test_abnormal)\n",
    "        },\n",
    "        'seed': seed\n",
    "    }\n",
    "\n",
    "    metadata_file = output_dir / \"data_split_metadata.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    result_paths['metadata'] = metadata_file\n",
    "\n",
    "    return result_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_image_fast(\n",
    "    image_path: Union[str, Path],  # Path to image\n",
    "    cache: bool = True  # Whether to cache loaded images\n",
    ") -> Image.Image:  # Returns PIL Image\n",
    "    \"\"\"\n",
    "    Fast image loading with optional caching.\n",
    "\n",
    "    Uses efficient PIL loading and optional LRU cache for repeated access.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "\n",
    "    if cache:\n",
    "        return _load_image_cached(str(image_path))\n",
    "    else:\n",
    "        return Image.open(image_path).convert('RGB')\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def _load_image_cached(image_path_str: str) -> Image.Image:\n",
    "    \"\"\"Cached image loader (internal use).\"\"\"\n",
    "    return Image.open(image_path_str).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_image_with_metadata(\n",
    "    image: Image.Image,  # PIL Image to save\n",
    "    output_path: Union[str, Path],  # Output path\n",
    "    metadata: Optional[Dict[str, Any]] = None,  # Optional metadata dict\n",
    "    format: str = \"JPEG\",  # Image format\n",
    "    quality: int = 95,  # JPEG quality (1-100)\n",
    "    optimize: bool = True  # Whether to optimize image\n",
    ") -> Path:  # Returns saved path\n",
    "    \"\"\"\n",
    "    Save image with optional metadata for reproducibility.\n",
    "\n",
    "    Saves image and optionally creates a JSON file with metadata\n",
    "    in the same directory.\n",
    "\n",
    "    Example:\n",
    "        img = Image.open(\"test.jpg\")\n",
    "        save_image_with_metadata(\n",
    "            img, \"output/test.jpg\",\n",
    "            metadata={\"anomaly_score\": 0.75, \"model\": \"padim\"}\n",
    "        )\n",
    "        # Creates output/test.jpg and output/test_metadata.json\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save image\n",
    "    if format == \"JPEG\":\n",
    "        image.save(output_path, format=format, quality=quality, optimize=optimize)\n",
    "    else:\n",
    "        image.save(output_path, format=format, optimize=optimize)\n",
    "\n",
    "    # Save metadata if provided\n",
    "    if metadata is not None:\n",
    "        metadata_path = output_path.with_suffix('.json').with_name(\n",
    "            output_path.stem + '_metadata.json'\n",
    "        )\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_poster_from_folder(\n",
    "    folder_path: Union[str, Path],  # Folder containing images\n",
    "    image_index_df: pd.DataFrame,  # DataFrame with image indices\n",
    "    output_path: Union[str, Path],  # Path to save poster\n",
    "    images_per_poster: int = 20,  # Number of images per poster\n",
    "    poster_index: int = 0,  # Index of this poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Size of each image\n",
    "    grid_cols: int = 5,  # Number of columns\n",
    "    annotate_with_index: bool = True,  # Whether to annotate with index\n",
    "    font_size: int = 30,  # Font size for annotations\n",
    "    title: Optional[str] = None  # Poster title\n",
    ") -> Optional[Path]:  # Returns path to saved poster or None\n",
    "    \"\"\"\n",
    "    Create a poster from images in a folder with optional index annotations.\n",
    "\n",
    "    This function efficiently loads images, resizes them, and creates a grid poster.\n",
    "    Uses fast image loading for better performance.\n",
    "\n",
    "    Example:\n",
    "        poster_path = create_poster_from_folder(\n",
    "            folder_path=\"output/0.5\",\n",
    "            image_index_df=df,\n",
    "            output_path=\"poster.png\",\n",
    "            images_per_poster=20,\n",
    "            grid_cols=5\n",
    "        )\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    if not folder_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  Folder not found: {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    # Get all images in folder\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(folder_path.glob(f\"*{ext}\"))\n",
    "        images.extend(folder_path.glob(f\"*{ext.upper()}\"))\n",
    "\n",
    "    images = sorted(set(images))\n",
    "\n",
    "    if not images:\n",
    "        print(f\"‚ö†Ô∏è  No images found in {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    # Limit to images_per_poster\n",
    "    images = images[:images_per_poster]\n",
    "\n",
    "    # Calculate grid dimensions\n",
    "    grid_rows = int(np.ceil(len(images) / grid_cols))\n",
    "\n",
    "    # Create figure\n",
    "    fig_width = grid_cols * (image_size[0] / 100)\n",
    "    fig_height = grid_rows * (image_size[1] / 100) + 1  # Extra space for title\n",
    "\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(fig_width, fig_height))\n",
    "\n",
    "    # Handle single row/col case\n",
    "    if grid_rows == 1 and grid_cols == 1:\n",
    "        axes = [[axes]]\n",
    "    elif grid_rows == 1:\n",
    "        axes = [axes]\n",
    "    elif grid_cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "\n",
    "    # Set title\n",
    "    if title:\n",
    "        fig.suptitle(f\"{title} - Poster {poster_index + 1}\", fontsize=14, weight='bold')\n",
    "\n",
    "    # Load and display images\n",
    "    for idx, img_path in enumerate(images):\n",
    "        row = idx // grid_cols\n",
    "        col = idx % grid_cols\n",
    "        ax = axes[row][col]\n",
    "\n",
    "        try:\n",
    "            # Fast image loading\n",
    "            img = load_image_fast(img_path, cache=False)\n",
    "            img = img.resize(image_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Annotate with index if requested\n",
    "            if annotate_with_index:\n",
    "                # Find index in dataframe\n",
    "                img_name = img_path.name\n",
    "                df_match = image_index_df[image_index_df['image_name'] == img_name]\n",
    "                if not df_match.empty:\n",
    "                    img_index = df_match.iloc[0]['index']\n",
    "                    img = annotate_image_with_index(img, img_index, font_size=font_size)\n",
    "\n",
    "            ax.imshow(np.array(img))\n",
    "            ax.set_title(img_path.stem[:20], fontsize=8)  # Truncate long names\n",
    "            ax.axis('off')\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Error\\n{img_path.name}\",\n",
    "                   ha='center', va='center', transform=ax.transAxes,\n",
    "                   fontsize=8, color='red')\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Hide empty cells\n",
    "    for idx in range(len(images), grid_rows * grid_cols):\n",
    "        row = idx // grid_cols\n",
    "        col = idx % grid_cols\n",
    "        axes[row][col].axis('off')\n",
    "\n",
    "    # Save poster\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Import from existing modules\n",
    "from be_vision_ad_tools.inference.prediction_system import (\n",
    "    predict_image_list_from_file_enhanced,\n",
    "    predict_image_list\n",
    ")\n",
    "\n",
    "from be_vision_ad_tools.inference.multinode_inference import (\n",
    "    create_smart_batches,\n",
    "    scan_folder_structure,\n",
    "    create_batch_list_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hasan/Schreibtisch/projects/data/malacca/model.pt\n",
      "True\n",
      "/home/hasan/Schreibtisch/projects/data/malacca/g_imgs/2462401115552714.png\n",
      "OUTPUT_DIR: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DATA_ROOT = os.getenv('DATA_PATH')\n",
    "good_im_path= Path(DATA_ROOT,'malacca','g_imgs')\n",
    "bad_im_path= Path(DATA_ROOT,'malacca','b_imgs')\n",
    "MODEL_PATH = Path(DATA_ROOT, 'malacca','model.pt')\n",
    "print(MODEL_PATH)\n",
    "print(MODEL_PATH.exists())\n",
    "sm_img = Path(good_im_path).ls()[0]\n",
    "print(sm_img)\n",
    "OUTPUT_DIR = Path(DATA_ROOT,'malacca','output')\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(f'OUTPUT_DIR: {OUTPUT_DIR.exists()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_im_path.exists(),bad_im_path.exists()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_thrs = [0.5, 1]\n",
    "sorted_score_thrs = sorted(score_thrs)\n",
    "sorted_score_thrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "anomaly_score = 0.788\n",
    "fn_name = None\n",
    "for score_thr in sorted_score_thrs:\n",
    "\tif anomaly_score <= score_thr:\n",
    "\t\tprint(score_thr)\n",
    "\t\tprint(str(score_thr))\n",
    "fn_name = str(sorted_score_thrs[-1])\n",
    "print(fn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize_score_thresholds(\n",
    "    score_thresholds: Optional[List[float]]  # List of score thresholds or None\n",
    ") -> List[float]:  # Returns sorted list of thresholds\n",
    "    \"\"\"\n",
    "    Normalize and sort score thresholds.\n",
    "\n",
    "    Returns default thresholds if None provided, otherwise returns sorted list.\n",
    "    \"\"\"\n",
    "    if score_thresholds is None:\n",
    "        return [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    return sorted(score_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 1]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_score_thresholds(\n",
    "\tscore_thresholds=[0.5,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def determine_score_folder(\n",
    "    anomaly_score: float,  # Anomaly score (0.0 to 1.0)\n",
    "    score_thresholds: List[float]  # List of score thresholds (e.g., [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    ") -> str:  # Returns the folder name based on the score\n",
    "    \"\"\"\n",
    "    Determine which folder an image should go to based on its anomaly score.\n",
    "\n",
    "    Example:\n",
    "        score_thresholds = [0.5, 1.0]\n",
    "        - score 0.3 -> folder \"0.5\"\n",
    "        - score 0.7 -> folder \"1.0\"\n",
    "    \"\"\"\n",
    "    sorted_thresholds = normalize_score_thresholds(score_thresholds)\n",
    "\n",
    "    # Find the appropriate folder\n",
    "    for threshold in sorted_thresholds:\n",
    "        if anomaly_score <= threshold:\n",
    "            return str(threshold)\n",
    "\n",
    "    # If score exceeds all thresholds, use the last one\n",
    "    return str(sorted_thresholds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_thresholds = [0.5, 1]\n",
    "determine_score_folder(anomaly_score, score_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_image_parent_folder(\n",
    "    image_path: Union[str, Path]  # Path to the image\n",
    ") -> str:  # Returns parent folder name\n",
    "    \"\"\"\n",
    "    Extract parent folder name from image path.\n",
    "\n",
    "    Example: 'first/second/image.png' -> 'second'\n",
    "    \"\"\"\n",
    "    return Path(image_path).parent.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hasan/Schreibtisch/projects/data/malacca/g_imgs/2462401115552714.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'g_imgs'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sm_img)\n",
    "get_image_parent_folder(sm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def build_target_folder_path(\n",
    "    output_dir: Path,  # Base output directory\n",
    "    parent_folder: str,  # Parent folder name from image path\n",
    "    folder_name: str  # Score-based folder name\n",
    ") -> Path:  # Returns target folder path\n",
    "    \"\"\"\n",
    "    Build target folder path from components.\n",
    "\n",
    "    Creates: output_dir/parent_folder/folder_name\n",
    "    \"\"\"\n",
    "    return Path(output_dir, parent_folder, folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn_path: /home/hasan/Schreibtisch/projects/data/malacca/output/g_imgs/0.5\n"
     ]
    }
   ],
   "source": [
    "parent_folder = get_image_parent_folder(sm_img)\n",
    "folder_name = '0.5'\n",
    "\n",
    "fn_path = build_target_folder_path(\n",
    "\tOUTPUT_DIR, parent_folder, folder_name)\n",
    "print(f'fn_path: {fn_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def copy_or_move_file(\n",
    "    source_path: Union[str, Path],  # Source file path\n",
    "    dest_path: Union[str, Path],    # Destination file path\n",
    "    copy_mode: bool = True,         # If True, copy; if False, move\n",
    "    dry_run: bool = False           # If True, print action instead of executing\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Copy or move a file from source to destination.\n",
    "    Example:\n",
    "        copy_or_move_file('a.png', 'b/c.png', copy_mode=True, dry_run=True)\n",
    "        # Dry run: Would copy a.png to b/c.png\n",
    "    \"\"\"\n",
    "    source_path = Path(source_path)\n",
    "    dest_path = Path(dest_path)\n",
    "    action = \"copy\" if copy_mode else \"move\"\n",
    "    if dry_run:\n",
    "        print(f\"Dry run: Would {action} {source_path} to {dest_path}\")\n",
    "        return\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if copy_mode:\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "    else:\n",
    "        shutil.move(str(source_path), str(dest_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 16:05:56,728 - be_vision_ad_tools.inference.prediction_system - INFO - Predicting with .pt model on 2462401115552714.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 16:05:57,550 - be_vision_ad_tools.inference.prediction_system - INFO - Prediction: NORMAL (Score: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "rs = predict_image(\n",
    "\tmodel_path=MODEL_PATH,\n",
    "\timage_path=sm_img,\n",
    "\theatmap_style='side_by_side',\n",
    "\tsave_heatmap=False,\n",
    "\tshow_heatmap=False,\n",
    "\toutput_dir=OUTPUT_DIR,\n",
    "\tcompress=True,\n",
    "\tjpeg_quality=95,\n",
    "\tdevice='cpu'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hasan/Schreibtisch/projects/data/malacca/g_imgs/2462401115552714.png\n"
     ]
    }
   ],
   "source": [
    "im_path = rs.get('image_path')\n",
    "print(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "anomaly_score = rs.get('anomaly_score')\n",
    "print(anomaly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_prediction_result(\n",
    "    result: Dict[str, Any]  # Prediction result dictionary\n",
    ") -> Tuple[Optional[str], Optional[float]]:  # Returns (image_path, anomaly_score) or (None, None) if invalid\n",
    "    \"\"\"\n",
    "    Validate and extract image_path and anomaly_score from prediction result.\n",
    "\n",
    "    Returns (image_path, anomaly_score) if valid, (None, None) if invalid.\n",
    "    \"\"\"\n",
    "    image_path = result.get('image_path')\n",
    "    anomaly_score = result.get('anomaly_score')\n",
    "\n",
    "    if image_path is None or anomaly_score is None:\n",
    "        return None, None\n",
    "    return image_path, anomaly_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hasan/Schreibtisch/projects/data/malacca/g_imgs/2462401115552714.png\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "im_p, a_s = validate_prediction_result(rs)\n",
    "print(im_p)\n",
    "print(a_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g_imgs'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_parent_folder(im_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_imgs\n",
      "0.5\n",
      "/home/hasan/Schreibtisch/projects/data/malacca/output/g_imgs/0.5\n"
     ]
    }
   ],
   "source": [
    "score_thresholds = [0.5, 1]\n",
    "parent_folder = get_image_parent_folder(im_p)\n",
    "print(parent_folder)\n",
    "folder_name = determine_score_folder(a_s, score_thresholds)\n",
    "print(folder_name)\n",
    "target_folder = build_target_folder_path(\n",
    "\tOUTPUT_DIR, parent_folder, folder_name)\n",
    "print(target_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_image_by_score(\n",
    "    image_path: Union[str, Path],  # Path to the source image\n",
    "    anomaly_score: float,  # Anomaly score for the image\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    "    dry_run: bool = False,  # If True, do not move or copy files\n",
    "    copy_mode: bool = True  # If True, copy files; if False, move files\n",
    ") -> Path:  # Returns the destination path\n",
    "    \"\"\"\n",
    "    Save (copy or move) an image to the appropriate score folder.\n",
    "\n",
    "    Returns the destination path where the image was saved.\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "\n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # Get parent folder name\n",
    "    im_folder = get_image_parent_folder(image_path)\n",
    "\n",
    "    # Determine target folder\n",
    "    folder_name = determine_score_folder(anomaly_score, score_thresholds)\n",
    "    target_folder = build_target_folder_path(output_dir, im_folder, folder_name)\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create destination path\n",
    "    dest_path = target_folder / image_path.name\n",
    "\n",
    "    # Copy or move the file or dry run\n",
    "    if dry_run:\n",
    "        print(f\"Dry run: Would move {image_path} to {dest_path}\")\n",
    "    else:\n",
    "        copy_or_move_file(image_path, dest_path, copy_mode)\n",
    "\n",
    "    return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry run: Would move /home/hasan/Schreibtisch/projects/data/malacca/g_imgs/2462401115552714.png to /home/hasan/Schreibtisch/projects/data/malacca/output/g_imgs/0.5/2462401115552714.png\n"
     ]
    }
   ],
   "source": [
    "dest = save_image_by_score(\n",
    "\tim_p,\n",
    "\ta_s,\n",
    "\tOUTPUT_DIR,\n",
    "\tscore_thresholds,\n",
    "\tdry_run=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 1]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.5': Path('/home/hasan/Schreibtisch/projects/data/malacca/output/0.5'),\n",
       " '1': Path('/home/hasan/Schreibtisch/projects/data/malacca/output/1')}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_map = {}\n",
    "for i in score_thresholds:\n",
    "\tnm = str(i)\n",
    "\tf_p = Path(OUTPUT_DIR,nm)\n",
    "\tf_map[nm] = f_p\n",
    "f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_score_folders(\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    ") -> Dict[str, Path]:  # Returns dict mapping threshold strings to folder paths\n",
    "    \"\"\"\n",
    "    Create subdirectories for each score threshold.\n",
    "\n",
    "    Returns a dictionary mapping threshold values to their folder paths.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    folder_map = {}\n",
    "\n",
    "    for threshold in score_thresholds:\n",
    "        folder_name = str(threshold)\n",
    "        folder_path = Path(output_dir, folder_name)\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        folder_map[folder_name] = folder_path\n",
    "\n",
    "    print(f\"‚úÖ Created {len(folder_map)} score folders in {output_dir}\")\n",
    "    for threshold, path in sorted(folder_map.items()):\n",
    "        print(f\"   üìÅ {threshold}: {path}\")\n",
    "\n",
    "    return folder_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "def process_single_image_result(\n",
    "    result: Dict[str, Any],  # Prediction result dictionary\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    "    copy_mode: bool  # Whether to copy or move\n",
    ") -> Optional[Dict[str, Any]]:  # Returns dict with folder_name and dest_path, or None if failed\n",
    "    \"\"\"\n",
    "    Process a single prediction result: save image and return metadata.\n",
    "\n",
    "    Returns dict with 'folder_name' and 'dest_path', or None if processing failed.\n",
    "    \"\"\"\n",
    "    image_path, anomaly_score = validate_prediction_result(result)\n",
    "\n",
    "    if image_path is None or anomaly_score is None:\n",
    "        print(f\"‚ö†Ô∏è  Skipping result with missing data: {result}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        dest_path = save_image_by_score(\n",
    "            image_path=image_path,\n",
    "            anomaly_score=anomaly_score,\n",
    "            output_dir=output_dir,\n",
    "            score_thresholds=score_thresholds,\n",
    "            copy_mode=copy_mode\n",
    "        )\n",
    "\n",
    "        folder_name = determine_score_folder(anomaly_score, score_thresholds)\n",
    "        return {\n",
    "            'folder_name': folder_name,\n",
    "            'dest_path': str(dest_path),\n",
    "            'anomaly_score': float(anomaly_score)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "#| export\n",
    "def initialize_folder_stats(\n",
    "    score_thresholds: List[float]  # List of score thresholds\n",
    ") -> Dict[str, Dict[str, Any]]:  # Returns initialized stats dictionary\n",
    "    \"\"\"\n",
    "    Initialize folder statistics dictionary.\n",
    "\n",
    "    Returns dict with structure: {folder_name: {'count': 0, 'images': [], 'scores': []}}\n",
    "    \"\"\"\n",
    "    return {str(t): {'count': 0, 'images': [], 'scores': []} for t in score_thresholds}\n",
    "\n",
    "#| export\n",
    "def update_folder_stats(\n",
    "    folder_stats: Dict[str, Dict[str, Any]],  # Folder statistics dictionary\n",
    "    folder_name: str,  # Folder name\n",
    "    dest_path: str,  # Destination path\n",
    "    anomaly_score: float  # Anomaly score\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Update folder statistics with a new image result.\n",
    "    \"\"\"\n",
    "    folder_stats[folder_name]['count'] += 1\n",
    "    folder_stats[folder_name]['images'].append(dest_path)\n",
    "    folder_stats[folder_name]['scores'].append(anomaly_score)\n",
    "\n",
    "#| export\n",
    "def create_folder_metadata(\n",
    "    folder_name: str,  # Folder name (threshold)\n",
    "    stats: Dict[str, Any]  # Folder statistics\n",
    ") -> Dict[str, Any]:  # Returns metadata dictionary\n",
    "    \"\"\"\n",
    "    Create metadata dictionary for a folder.\n",
    "    \"\"\"\n",
    "    scores = stats['scores']\n",
    "    return {\n",
    "        'threshold': folder_name,\n",
    "        'count': stats['count'],\n",
    "        'avg_score': float(np.mean(scores)) if scores else 0.0,\n",
    "        'min_score': float(np.min(scores)) if scores else 0.0,\n",
    "        'max_score': float(np.max(scores)) if scores else 0.0,\n",
    "        'images': stats['images']\n",
    "    }\n",
    "\n",
    "#| export\n",
    "def save_folder_metadata(\n",
    "    metadata_path: Path,  # Path to save metadata JSON\n",
    "    metadata: Dict[str, Any]  # Metadata dictionary\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save folder metadata to JSON file.\n",
    "    \"\"\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "#| export\n",
    "def save_all_folder_metadata(\n",
    "    folder_map: Dict[str, Path],  # Mapping of folder names to paths\n",
    "    folder_stats: Dict[str, Dict[str, Any]]  # Folder statistics\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save metadata JSON files for all folders that have images.\n",
    "    \"\"\"\n",
    "    print(\"\\nüíæ Saving metadata...\")\n",
    "    for folder_name, stats in folder_stats.items():\n",
    "        if stats['count'] > 0:\n",
    "            metadata_path = folder_map[folder_name] / \"metadata.json\"\n",
    "            metadata = create_folder_metadata(folder_name, stats)\n",
    "            save_folder_metadata(metadata_path, metadata)\n",
    "\n",
    "#| export\n",
    "def print_organization_summary(\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    "    folder_stats: Dict[str, Dict[str, Any]],  # Folder statistics\n",
    "    failed_count: int  # Number of failed images\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Print summary of image organization.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä ORGANIZATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for threshold in sorted(score_thresholds):\n",
    "        folder_name = str(threshold)\n",
    "        count = folder_stats[folder_name]['count']\n",
    "        if count > 0:\n",
    "            avg_score = np.mean(folder_stats[folder_name]['scores'])\n",
    "            print(f\"üìÅ Folder '{folder_name}': {count} images (avg score: {avg_score:.4f})\")\n",
    "\n",
    "    if failed_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Failed: {failed_count} images\")\n",
    "\n",
    "    print(\"\\n‚úÖ Organization complete!\")\n",
    "\n",
    "#| export\n",
    "def build_organization_stats(\n",
    "    output_dir: Path,  # Output directory\n",
    "    score_thresholds: List[float],  # Score thresholds\n",
    "    folder_stats: Dict[str, Dict[str, Any]],  # Folder statistics\n",
    "    total_processed: int,  # Total processed images\n",
    "    failed_count: int  # Failed images count\n",
    ") -> Dict[str, Any]:  # Returns organization statistics dictionary\n",
    "    \"\"\"\n",
    "    Build final organization statistics dictionary.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'output_dir': str(output_dir),\n",
    "        'score_thresholds': score_thresholds,\n",
    "        'folder_stats': {k: {'count': v['count'],\n",
    "                             'avg_score': float(np.mean(v['scores'])) if v['scores'] else 0.0}\n",
    "                        for k, v in folder_stats.items()},\n",
    "        'total_processed': total_processed,\n",
    "        'failed_count': failed_count\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_score_folders(\n",
    "    output_dir: Path,  # Base output directory\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    ") -> Dict[str, Path]:  # Returns dict mapping threshold strings to folder paths\n",
    "    \"\"\"\n",
    "    Create subdirectories for each score threshold.\n",
    "\n",
    "    Returns a dictionary mapping threshold values to their folder paths.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    folder_map = {}\n",
    "\n",
    "    for threshold in score_thresholds:\n",
    "        folder_name = str(threshold)\n",
    "        folder_path = Path(output_dir, folder_name)\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        folder_map[folder_name] = folder_path\n",
    "\n",
    "    print(f\"‚úÖ Created {len(folder_map)} score folders in {output_dir}\")\n",
    "    for threshold, path in sorted(folder_map.items()):\n",
    "        print(f\"   üìÅ {threshold}: {path}\")\n",
    "\n",
    "    return folder_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 2 score folders in output_dir\n",
      "   üìÅ 0.5: output_dir/0.5\n",
      "   üìÅ 1: output_dir/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0.5': Path('output_dir/0.5'), '1': Path('output_dir/1')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = Path('output_dir')\n",
    "create_score_folders(output_dir, score_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def organize_images_by_score(\n",
    "    prediction_results: List[Dict[str, Any]],  # List of prediction results from predict_image_list\n",
    "    output_dir: Union[str, Path],  # Base output directory\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    copy_mode: bool = True,  # If True, copy files; if False, move files\n",
    "    save_metadata: bool = True  # If True, save metadata JSON for each folder\n",
    ") -> Dict[str, Any]:  # Returns organization statistics\n",
    "    \"\"\"\n",
    "    Organize images into folders based on their anomaly scores.\n",
    "\n",
    "    Args:\n",
    "        prediction_results: List of prediction results, each containing 'image_path' and 'anomaly_score'\n",
    "        output_dir: Base directory where score folders will be created\n",
    "        score_thresholds: List of threshold values (e.g., [0.5, 1.0] for simple two-folder setup)\n",
    "        copy_mode: Whether to copy (True) or move (False) images\n",
    "        save_metadata: Whether to save JSON metadata for each folder\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with organization statistics\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\nüóÇÔ∏è  ORGANIZING IMAGES BY ANOMALY SCORE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìÇ Output directory: {output_dir}\")\n",
    "    print(f\"üìä Score thresholds: {score_thresholds}\")\n",
    "    print(f\"üìã Total images: {len(prediction_results)}\")\n",
    "    print(f\"üîÑ Mode: {'COPY' if copy_mode else 'MOVE'}\")\n",
    "\n",
    "    # Create score folders\n",
    "    folder_map = create_score_folders(output_dir, score_thresholds)\n",
    "\n",
    "    # Initialize statistics\n",
    "    folder_stats = initialize_folder_stats(score_thresholds)\n",
    "    failed_count = 0\n",
    "\n",
    "    print(\"\\nüì¶ Processing images...\")\n",
    "\n",
    "    # Process each image\n",
    "    for result in tqdm(prediction_results, desc=\"Organizing images\"):\n",
    "        processed = process_single_image_result(\n",
    "            result, output_dir, score_thresholds, copy_mode\n",
    "        )\n",
    "\n",
    "        if processed is None:\n",
    "            failed_count += 1\n",
    "            continue\n",
    "\n",
    "        # Update statistics\n",
    "        update_folder_stats(\n",
    "            folder_stats,\n",
    "            processed['folder_name'],\n",
    "            processed['dest_path'],\n",
    "            processed['anomaly_score']\n",
    "        )\n",
    "\n",
    "    # Save metadata if requested\n",
    "    if save_metadata:\n",
    "        save_all_folder_metadata(folder_map, folder_stats)\n",
    "\n",
    "    # Print summary\n",
    "    print_organization_summary(score_thresholds, folder_stats, failed_count)\n",
    "\n",
    "    # Build and return statistics\n",
    "    return build_organization_stats(\n",
    "        output_dir, score_thresholds, folder_stats,\n",
    "        len(prediction_results) - failed_count, failed_count\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_posters_for_score_folders(\n",
    "    output_dir: Union[str, Path],  # Base output directory with score folders\n",
    "    image_index_df: pd.DataFrame,  # Dataframe with image indices\n",
    "    score_thresholds: List[float],  # List of score thresholds\n",
    "    images_per_poster: int = 20,  # Number of images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster\n",
    "    grid_cols: int = 5,  # Number of columns in the grid\n",
    "    annotate_with_index: bool = True,  # Whether to add index numbers\n",
    "    font_size: int = 30  # Font size for index numbers\n",
    ") -> Dict[str, List[Path]]:  # Returns dict mapping folder names to poster paths\n",
    "    \"\"\"\n",
    "    Create posters for all score folders.\n",
    "\n",
    "    This function processes each score folder and creates one or more posters\n",
    "    depending on the number of images in each folder.\n",
    "\n",
    "    Args:\n",
    "        output_dir: Base directory containing score folders\n",
    "        image_index_df: DataFrame with image indices\n",
    "        score_thresholds: List of threshold values\n",
    "        images_per_poster: How many images per poster\n",
    "        image_size: Size of each image in the poster\n",
    "        grid_cols: Number of columns in the grid\n",
    "        annotate_with_index: Whether to annotate images with indices\n",
    "        font_size: Font size for annotations\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping folder names to list of poster paths\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    poster_paths = {}\n",
    "\n",
    "    print(\"\\nüñºÔ∏è  CREATING POSTERS FOR SCORE FOLDERS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for threshold in score_thresholds:\n",
    "        folder_name = str(threshold)\n",
    "        folder_path = output_dir / folder_name\n",
    "\n",
    "        if not folder_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Folder {folder_name} does not exist, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Get all images in folder (excluding metadata.json)\n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "        images_in_folder = []\n",
    "        for ext in image_extensions:\n",
    "            images_in_folder.extend(folder_path.glob(f\"*{ext}\"))\n",
    "            images_in_folder.extend(folder_path.glob(f\"*{ext.upper()}\"))\n",
    "\n",
    "        images_in_folder = sorted(set(images_in_folder))\n",
    "\n",
    "        if not images_in_folder:\n",
    "            print(f\"üìÅ Folder '{folder_name}': No images found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìÅ Processing folder '{folder_name}': {len(images_in_folder)} images\")\n",
    "\n",
    "        # Calculate number of posters needed\n",
    "        num_posters = int(np.ceil(len(images_in_folder) / images_per_poster))\n",
    "        folder_poster_paths = []\n",
    "\n",
    "        # Create posters\n",
    "        for poster_idx in range(num_posters):\n",
    "            start_idx = poster_idx * images_per_poster\n",
    "            end_idx = min((poster_idx + 1) * images_per_poster, len(images_in_folder))\n",
    "\n",
    "            # Create a temporary folder for this subset\n",
    "            poster_output_path = folder_path / f\"poster_{poster_idx + 1:03d}.png\"\n",
    "\n",
    "            # Get subset of images for this poster\n",
    "            poster_images = images_in_folder[start_idx:end_idx]\n",
    "\n",
    "            # Create temporary folder with subset\n",
    "            temp_folder = folder_path / f\"_temp_poster_{poster_idx}\"\n",
    "            temp_folder.mkdir(exist_ok=True)\n",
    "\n",
    "            # Copy images to temp folder\n",
    "            for img in poster_images:\n",
    "                shutil.copy2(img, temp_folder / img.name)\n",
    "\n",
    "            # Create poster\n",
    "            try:\n",
    "                poster_path = create_poster_from_folder(\n",
    "                    folder_path=temp_folder,\n",
    "                    image_index_df=image_index_df,\n",
    "                    output_path=poster_output_path,\n",
    "                    images_per_poster=images_per_poster,\n",
    "                    poster_index=poster_idx,\n",
    "                    image_size=image_size,\n",
    "                    grid_cols=grid_cols,\n",
    "                    annotate_with_index=annotate_with_index,\n",
    "                    font_size=font_size,\n",
    "                    title=f\"Score Folder {folder_name}\"\n",
    "                )\n",
    "\n",
    "                if poster_path:\n",
    "                    folder_poster_paths.append(poster_path)\n",
    "                    print(f\"  ‚úÖ Created poster {poster_idx + 1}/{num_posters}: {len(poster_images)} images\")\n",
    "\n",
    "            finally:\n",
    "                # Clean up temp folder\n",
    "                shutil.rmtree(temp_folder, ignore_errors=True)\n",
    "\n",
    "        if folder_poster_paths:\n",
    "            poster_paths[folder_name] = folder_poster_paths\n",
    "            print(f\"üìä Folder '{folder_name}': Created {len(folder_poster_paths)} poster(s)\")\n",
    "\n",
    "    print(\"\\n‚úÖ Poster creation complete!\")\n",
    "    print(f\"   Total folders processed: {len(poster_paths)}\")\n",
    "    print(f\"   Total posters created: {sum(len(p) for p in poster_paths.values())}\")\n",
    "\n",
    "    return poster_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_and_organize_by_score(\n",
    "    model_path: Union[str, Path],  # Path to the trained model\n",
    "    image_list_file: Union[str, Path],  # Text file with image paths (one per line)\n",
    "    output_dir: Union[str, Path],  # Base output directory for organized images\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    batch_id: Optional[str] = None,  # Optional batch identifier\n",
    "    copy_mode: bool = True,  # If True, copy files; if False, move files\n",
    "    save_metadata: bool = True,  # If True, save metadata JSON for each folder\n",
    "    create_posters: bool = True,  # If True, create posters for each score folder\n",
    "    images_per_poster: int = 20,  # Number of images per poster\n",
    "    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster\n",
    "    grid_cols: int = 5,  # Number of columns in poster grid\n",
    "    annotate_with_index: bool = True,  # Whether to add index numbers to images in posters\n",
    "    font_size: int = 30,  # Font size for index annotations\n",
    "    device: str = \"auto\",  # Device for inference (\"auto\", \"cpu\", \"cuda\")\n",
    "    **kwargs  # Additional arguments passed to prediction function\n",
    ") -> Dict[str, Any]:  # Returns combined prediction and organization results\n",
    "    \"\"\"\n",
    "    Complete workflow: Predict anomaly scores, organize images, and create indexed posters.\n",
    "\n",
    "    This is the main function that combines:\n",
    "    1. Image index dataframe creation\n",
    "    2. Smart batch creation\n",
    "    3. Prediction using predict_image_list_from_file_enhanced\n",
    "    4. Image organization based on anomaly scores\n",
    "    5. Poster creation with index annotations (optional)\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the trained anomaly detection model\n",
    "        image_list_file: Text file containing paths to images (one per line)\n",
    "        output_dir: Directory where score-based folders will be created\n",
    "        score_thresholds: List of threshold values (customize to your needs)\n",
    "            Examples:\n",
    "            - [0.5, 1.0] for simple two-folder setup\n",
    "            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization\n",
    "        batch_id: Optional identifier for this batch\n",
    "        copy_mode: Whether to copy (True) or move (False) images\n",
    "        save_metadata: Whether to save JSON metadata for each folder\n",
    "        create_posters: Whether to create image posters for each score folder\n",
    "        images_per_poster: Number of images to include in each poster\n",
    "        image_size: Size to resize each image to in posters\n",
    "        grid_cols: Number of columns in the poster grid\n",
    "        annotate_with_index: Whether to annotate images with their dataframe index\n",
    "        font_size: Font size for index annotations\n",
    "        device: Device to use for inference\n",
    "        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - image_index_df: DataFrame with image indices\n",
    "        - prediction_results: Full prediction results\n",
    "        - organization_stats: Statistics about image organization\n",
    "        - poster_paths: Paths to created posters (if create_posters=True)\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE WITH INDEXED POSTERS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Step 0: Create image index dataframe\n",
    "    print(\"\\nüìä Step 0: Creating image index dataframe...\")\n",
    "    image_index_df = create_image_index_dataframe(image_list_file)\n",
    "\n",
    "    # Save the dataframe\n",
    "    output_dir_path = Path(output_dir)\n",
    "    output_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    df_path = output_dir_path / \"image_index.csv\"\n",
    "    image_index_df.to_csv(df_path, index=False)\n",
    "    print(f\"üíæ Saved image index dataframe to {df_path}\")\n",
    "\n",
    "    # Step 1: Run predictions\n",
    "    print(\"\\nüìä Step 1: Running predictions...\")\n",
    "    prediction_output = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=image_list_file,\n",
    "        batch_id=batch_id,\n",
    "        output_dir=output_dir,\n",
    "        device=device,\n",
    "        save_results=True,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Extract results\n",
    "    prediction_results = prediction_output.get('results', [])\n",
    "\n",
    "    if not prediction_results:\n",
    "        print(\"‚ö†Ô∏è  No prediction results to organize!\")\n",
    "        return {\n",
    "            'image_index_df': image_index_df,\n",
    "            'prediction_results': prediction_output,\n",
    "            'organization_stats': None,\n",
    "            'poster_paths': None\n",
    "        }\n",
    "\n",
    "    print(f\"‚úÖ Predictions complete: {len(prediction_results)} images processed\")\n",
    "\n",
    "    # Step 2: Organize images by score\n",
    "    print(\"\\nüìÅ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=prediction_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=save_metadata\n",
    "    )\n",
    "\n",
    "    # Step 3: Create posters (optional)\n",
    "    poster_paths = None\n",
    "    if create_posters:\n",
    "        print(\"\\nüñºÔ∏è  Step 3: Creating indexed posters...\")\n",
    "        poster_paths = create_posters_for_score_folders(\n",
    "            output_dir=output_dir,\n",
    "            image_index_df=image_index_df,\n",
    "            score_thresholds=score_thresholds,\n",
    "            images_per_poster=images_per_poster,\n",
    "            image_size=image_size,\n",
    "            grid_cols=grid_cols,\n",
    "            annotate_with_index=annotate_with_index,\n",
    "            font_size=font_size\n",
    "        )\n",
    "\n",
    "    print(\"\\nüéâ WORKFLOW COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìä Image index dataframe: {df_path}\")\n",
    "    print(f\"üìÅ Organized images: {output_dir}\")\n",
    "    if poster_paths:\n",
    "        total_posters = sum(len(p) for p in poster_paths.values())\n",
    "        print(f\"üñºÔ∏è  Created {total_posters} poster(s)\")\n",
    "\n",
    "    return {\n",
    "        'image_index_df': image_index_df,\n",
    "        'image_index_df_path': str(df_path),\n",
    "        'prediction_results': prediction_output,\n",
    "        'organization_stats': organization_stats,\n",
    "        'poster_paths': poster_paths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def annotate_image_with_index(\n",
    "    image: Union[Image.Image, np.ndarray],  # PIL Image or numpy array\n",
    "    index: int,  # Index number to display\n",
    "    font_size: int = 40,  # Font size for the index number\n",
    "    position: str = \"top_left\",  # Position: \"top_left\", \"top_right\", \"bottom_left\", \"bottom_right\"\n",
    "    text_color: Tuple[int, int, int] = (255, 255, 0),  # RGB color for text (yellow)\n",
    "    bg_color: Tuple[int, int, int, int] = (0, 0, 0, 180)  # RGBA color for background (semi-transparent black)\n",
    ") -> Image.Image:  # Returns annotated PIL Image\n",
    "    \"\"\"\n",
    "    Add an index number to an image.\n",
    "\n",
    "    Args:\n",
    "        image: Input image (PIL Image or numpy array)\n",
    "        index: Index number to display\n",
    "        font_size: Size of the font\n",
    "        position: Where to place the index number\n",
    "        text_color: RGB tuple for text color\n",
    "        bg_color: RGBA tuple for background color (includes alpha for transparency)\n",
    "\n",
    "    Returns:\n",
    "        PIL Image with index number annotated\n",
    "    \"\"\"\n",
    "    # Convert to PIL Image if numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "    # Make a copy to avoid modifying original\n",
    "    img_copy = image.copy().convert(\"RGBA\")\n",
    "\n",
    "    # Create a transparent overlay\n",
    "    overlay = Image.new('RGBA', img_copy.size, (255, 255, 255, 0))\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "    # Try to use a nice font, fall back to default if not available\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", font_size)\n",
    "    except:\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", font_size)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Prepare text\n",
    "    text = f\"#{index}\"\n",
    "\n",
    "    # Get text bounding box\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "\n",
    "    # Add padding\n",
    "    padding = 10\n",
    "    box_width = text_width + 2 * padding\n",
    "    box_height = text_height + 2 * padding\n",
    "\n",
    "    # Calculate position\n",
    "    img_width, img_height = img_copy.size\n",
    "\n",
    "    if position == \"top_left\":\n",
    "        x, y = padding, padding\n",
    "    elif position == \"top_right\":\n",
    "        x, y = img_width - box_width - padding, padding\n",
    "    elif position == \"bottom_left\":\n",
    "        x, y = padding, img_height - box_height - padding\n",
    "    elif position == \"bottom_right\":\n",
    "        x, y = img_width - box_width - padding, img_height - box_height - padding\n",
    "    else:\n",
    "        x, y = padding, padding  # default to top_left\n",
    "\n",
    "    # Draw semi-transparent background rectangle\n",
    "    draw.rectangle(\n",
    "        [x, y, x + box_width, y + box_height],\n",
    "        fill=bg_color\n",
    "    )\n",
    "\n",
    "    # Draw text\n",
    "    draw.text(\n",
    "        (x + padding, y + padding),\n",
    "        text,\n",
    "        font=font,\n",
    "        fill=text_color\n",
    "    )\n",
    "\n",
    "    # Composite the overlay onto the image\n",
    "    result = Image.alpha_composite(img_copy, overlay)\n",
    "\n",
    "    # Convert back to RGB\n",
    "    return result.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_image_index_dataframe(\n",
    "    image_list: Union[List[Union[str, Path]], str, Path]  # List of images or path to text file\n",
    ") -> pd.DataFrame:  # Returns dataframe with index and image paths\n",
    "    \"\"\"\n",
    "    Create a dataframe with index numbers for all images.\n",
    "\n",
    "    This dataframe is used to track and reference images by index number\n",
    "    when creating posters.\n",
    "\n",
    "    Args:\n",
    "        image_list: Either a list of image paths or a path to text file containing image paths\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: ['index', 'image_path', 'image_name']\n",
    "    \"\"\"\n",
    "    # Handle input - could be list or file path\n",
    "    if isinstance(image_list, (str, Path)):\n",
    "        # Read from file\n",
    "        image_list_path = Path(image_list)\n",
    "        if image_list_path.exists() and image_list_path.is_file():\n",
    "            images = []\n",
    "            with open(image_list_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line and not line.startswith('#'):\n",
    "                        images.append(line)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Image list file not found: {image_list}\")\n",
    "    else:\n",
    "        images = [str(img) for img in image_list]\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'index': range(len(images)),\n",
    "        'image_path': images,\n",
    "        'image_name': [Path(img).name for img in images]\n",
    "    })\n",
    "\n",
    "    print(f\"üìä Created image index dataframe with {len(df)} images\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Indexing and Poster Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Workflow Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predict_and_organize_by_score(\n",
    "    model_path: Union[str, Path],  # Path to the trained model\n",
    "    image_list_file: Union[str, Path],  # Text file with image paths (one per line)\n",
    "    output_dir: Union[str, Path],  # Base output directory for organized images\n",
    "    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds\n",
    "    batch_id: Optional[str] = None,  # Optional batch identifier\n",
    "    copy_mode: bool = True,  # If True, copy files; if False, move files\n",
    "    save_metadata: bool = True,  # If True, save metadata JSON for each folder\n",
    "    device: str = \"auto\",  # Device for inference (\"auto\", \"cpu\", \"cuda\")\n",
    "    **kwargs  # Additional arguments passed to prediction function\n",
    ") -> Dict[str, Any]:  # Returns combined prediction and organization results\n",
    "    \"\"\"\n",
    "    Complete workflow: Predict anomaly scores and organize images into score-based folders.\n",
    "\n",
    "    This is the main function that combines:\n",
    "    1. Smart batch creation\n",
    "    2. Prediction using predict_image_list_from_file_enhanced\n",
    "    3. Image organization based on anomaly scores\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the trained anomaly detection model\n",
    "        image_list_file: Text file containing paths to images (one per line)\n",
    "        output_dir: Directory where score-based folders will be created\n",
    "        score_thresholds: List of threshold values (customize to your needs)\n",
    "            Examples:\n",
    "            - [0.5, 1.0] for simple two-folder setup\n",
    "            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization\n",
    "        batch_id: Optional identifier for this batch\n",
    "        copy_mode: Whether to copy (True) or move (False) images\n",
    "        save_metadata: Whether to save JSON metadata for each folder\n",
    "        device: Device to use for inference\n",
    "        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - prediction_results: Full prediction results\n",
    "        - organization_stats: Statistics about image organization\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Step 1: Run predictions\n",
    "    print(\"\\nüìä Step 1: Running predictions...\")\n",
    "    prediction_output = predict_image_list_from_file_enhanced(\n",
    "        model_path=model_path,\n",
    "        image_list_file=image_list_file,\n",
    "        batch_id=batch_id,\n",
    "        output_dir=output_dir,\n",
    "        device=device,\n",
    "        save_results=True,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Extract results\n",
    "    prediction_results = prediction_output.get('results', [])\n",
    "\n",
    "    if not prediction_results:\n",
    "        print(\"‚ö†Ô∏è  No prediction results to organize!\")\n",
    "        return {\n",
    "            'prediction_results': prediction_output,\n",
    "            'organization_stats': None\n",
    "        }\n",
    "\n",
    "    print(f\"‚úÖ Predictions complete: {len(prediction_results)} images processed\")\n",
    "\n",
    "    # Step 2: Organize images by score\n",
    "    print(\"\\nüìÅ Step 2: Organizing images by score...\")\n",
    "    organization_stats = organize_images_by_score(\n",
    "        prediction_results=prediction_results,\n",
    "        output_dir=output_dir,\n",
    "        score_thresholds=score_thresholds,\n",
    "        copy_mode=copy_mode,\n",
    "        save_metadata=save_metadata\n",
    "    )\n",
    "\n",
    "    print(\"\\nüéâ WORKFLOW COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return {\n",
    "        'prediction_results': prediction_output,\n",
    "        'organization_stats': organization_stats\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example 1: Simple two-folder organization (low vs high anomaly)\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.5, 1.0],  # Two folders: 0.5 (normal) and 1.0 (anomaly)\n",
    "    copy_mode=True\n",
    ")\n",
    "\n",
    "# Example 2: Fine-grained organization with 8 score folders\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    copy_mode=True,\n",
    "    save_heatmap=True,\n",
    "    heatmap_style=\"side_by_side\"\n",
    ")\n",
    "\n",
    "# Example 3: Custom thresholds\n",
    "results = predict_and_organize_by_score(\n",
    "    model_path=\"path/to/model.ckpt\",\n",
    "    image_list_file=\"path/to/images.txt\",\n",
    "    output_dir=\"organized_output\",\n",
    "    score_thresholds=[0.25, 0.5, 0.75, 1.0],  # Four folders\n",
    "    copy_mode=False  # Move files instead of copying\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test determine_score_folder\n",
    "test_eq(determine_score_folder(0.3, [0.5, 1.0]), \"0.5\")\n",
    "test_eq(determine_score_folder(0.7, [0.5, 1.0]), \"1.0\")\n",
    "test_eq(determine_score_folder(0.45, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), \"0.5\")\n",
    "test_eq(determine_score_folder(0.85, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), \"0.9\")\n",
    "print(\"‚úÖ All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
