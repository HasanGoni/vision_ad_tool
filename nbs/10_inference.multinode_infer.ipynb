{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform multinode inference\n",
    "> Performing inference on multiple node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.multinode_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from fastcore.all import *\n",
    "from fastcore.script import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d83152",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from be_vision_ad_tools.inference.multinode_from_aiop_tool import (\n",
    "    DistributeHPC, HPC_Job\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "CURRETNT_NB='/home/ai_dsx.work/data/projects/be-vision-ad-tools/nbs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from be_vision_ad_tools.inference.prediction_system import (\n",
    "    split_image_list, generate_hpc_commands, predict_image_list_from_file, \n",
    "    merge_batch_results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Union, List, Optional, Dict, Any, Tuple\n",
    "from fastcore.test import *\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resolve_test_folders(\n",
    "    test_folders: Union[str, Path,List[[Union[str, Path]]]]  # Could be str , image list ,[image_list +*.png + .jpg]\n",
    "    ) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Resolve test_folders parameter to a list of image paths.\n",
    "        \n",
    "    Example:\n",
    "        >>> folders = resolve_test_folders(\"path/to/images\")\n",
    "        >>> folders = resolve_test_folders([\"folder1\", \"folder2\"])  \n",
    "        >>> folders = resolve_test_folders([\"folder1\", \"image1.jpg\", \"folder2\"])\n",
    "    \"\"\"\n",
    "    if not isinstance(test_folders, list):\n",
    "        test_folders = [test_folders]\n",
    "    \n",
    "    image_paths = []\n",
    "    supported_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "    \n",
    "    for folder_or_file in test_folders:\n",
    "        path = Path(folder_or_file)\n",
    "        \n",
    "        if path.is_file() and path.suffix.lower() in supported_extensions:\n",
    "            # It's an image file\n",
    "            image_paths.append(path)\n",
    "        elif path.is_dir():\n",
    "            # It's a directory - find all images\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']:\n",
    "                image_paths.extend(path.glob(ext))\n",
    "                image_paths.extend(path.glob(ext.upper()))\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Warning: '{folder_or_file}' is not a valid file or directory\")\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    unique_paths = sorted(set(image_paths))\n",
    "    \n",
    "    print(f\"üìÅ Resolved {len(unique_paths)} images from {len(test_folders)} input path(s)\")\n",
    "    return unique_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dee74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resolve_test_folders function\n",
    "def test_resolve_test_folders():\n",
    "    \"\"\"Test folder resolution with mock data.\"\"\"\n",
    "    # Test empty input\n",
    "    result = resolve_test_folders([])\n",
    "    test_eq(len(result), 0)\n",
    "    \n",
    "    # Test with non-existent paths (should warn but not fail)\n",
    "    result = resolve_test_folders([\"non_existent_folder\"])\n",
    "    test_eq(len(result), 0)\n",
    "    \n",
    "    print(\"‚úÖ resolve_test_folders tests passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57066fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_resolve_test_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f553496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_images = resolve_test_folders(\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_model_path(model_path: Union[str, Path]) -> Path:\n",
    "    \"\"\"Validate that model path exists and return Path object.\"\"\"\n",
    "    model_path = Path(model_path)\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test validate_model_path function\n",
    "def test_validate_model_path():\n",
    "    \"\"\"Test model path validation.\"\"\"\n",
    "    # Test with non-existent file (should raise)\n",
    "    try:\n",
    "        validate_model_path(\"non_existent_model.ckpt\")\n",
    "        assert False, \"Should have raised FileNotFoundError\"\n",
    "    except FileNotFoundError:\n",
    "        pass  # Expected\n",
    "    \n",
    "    # Test with existing file (use README.md as proxy)\n",
    "    try:\n",
    "        result = validate_model_path(f\"{Path.cwd().parent}/README.md\")\n",
    "        test_eq(type(result), Path)\n",
    "        print(\"‚úÖ validate_model_path tests passed\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è README.md not found for testing, but function logic is correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_validate_model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee462f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"/home/ai_dsx.work/data/projects/AD_tool_test/models/best_model.pth\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c497bce",
   "metadata": {},
   "source": [
    "## Split image list into different batches\n",
    "- split into batches\n",
    "    - splitting can be done in different ways\n",
    "        - round robin\n",
    "        - chunk\n",
    "    - batch size can be different for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c30d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "paths = [Path(i) for i in tst_images]\n",
    "num_batches = (len(paths) + batch_size - 1) // batch_size\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765debee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [[] for _ in range(num_batches)]\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b01fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round robin\n",
    "for i, path in enumerate(paths):\n",
    "    batch_idx =  i%num_batches\n",
    "    batches[batch_idx].append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e46611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batches)\n",
    "print(len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8675a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk\n",
    "batches = [[] for _ in range(num_batches)]\n",
    "for i in range(0, len(paths), batch_size):\n",
    "    batch_idx = i//batch_size\n",
    "    print(batch_idx)\n",
    "    batch_end = min(i + batch_size, len(paths))\n",
    "    print(f' batch end = {batch_end}')\n",
    "    batches[batch_idx].append(paths[i:batch_end])\n",
    "print(batches)\n",
    "print(len(batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d42d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_image_list(\n",
    "    image_list: List[Union[str, Path]],  # List of image paths to split\n",
    "    batch_size: int,  # Maximum number of images per batch\n",
    "    batch_strategy: str = \"round_robin\"  # \"round_robin\" (balanced) or \"chunk\" (consecutive)\n",
    ") -> List[List[Path]]:  # Returns list of image path lists, one for each batch\n",
    "    \"\"\"Split a large image list into batches based on batch size for parallel processing.\"\"\"\n",
    "    \n",
    "    if not image_list:\n",
    "        return []\n",
    "    \n",
    "    if batch_size <= 0:\n",
    "        raise ValueError(\"Batch size must be positive\")\n",
    "    \n",
    "    # Convert to Path objects\n",
    "    paths = [Path(img) for img in image_list]\n",
    "    \n",
    "    if batch_size >= len(paths):\n",
    "        # Batch size larger than total images - return single batch with all images\n",
    "        return [paths]\n",
    "    \n",
    "    # Calculate number of batches needed\n",
    "    num_batches = (len(paths) + batch_size - 1) // batch_size  # Ceiling division\n",
    "    \n",
    "    batches = [[] for _ in range(num_batches)]\n",
    "    \n",
    "    if batch_strategy == \"round_robin\":\n",
    "        # Distribute images evenly across batches (balanced)\n",
    "        for i, path in enumerate(paths):\n",
    "            batch_idx = i % num_batches\n",
    "            batches[batch_idx].append(path)\n",
    "    \n",
    "    elif batch_strategy == \"chunk\":\n",
    "        # Split into consecutive chunks of batch_size\n",
    "        for i in range(0, len(paths), batch_size):\n",
    "            batch_idx = i // batch_size\n",
    "            batch_end = min(i + batch_size, len(paths))\n",
    "            batches[batch_idx] = paths[i:batch_end]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown batch strategy: {batch_strategy}\")\n",
    "    \n",
    "    # Remove empty batches (shouldn't happen with correct logic, but safety check)\n",
    "    batches = [batch for batch in batches if batch]\n",
    "    \n",
    "    print(f\"üì¶ Split {len(paths)} images into {len(batches)} batches (max {batch_size} per batch):\")\n",
    "    for i, batch in enumerate(batches):\n",
    "        print(f\"   Batch {i+1}: {len(batch)} images\")\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf459fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test split_image_list function with batch_size parameter\n",
    "def test_split_image_list():\n",
    "    \"\"\"Test image list splitting with batch size parameter.\"\"\"\n",
    "    from fastcore.test import test_eq\n",
    "    \n",
    "    # Test empty input\n",
    "    result = split_image_list([], batch_size=10)\n",
    "    test_eq(len(result), 0)\n",
    "    \n",
    "    # Test with small list (batch_size > list length)\n",
    "    small_list = [Path(f\"img_{i}.jpg\") for i in range(3)]\n",
    "    result = split_image_list(small_list, batch_size=5)\n",
    "    test_eq(len(result), 1)  # Should return single batch\n",
    "    test_eq(len(result[0]), 3)  # With all 3 images\n",
    "    \n",
    "    # Test with exact batch size match\n",
    "    exact_list = [Path(f\"img_{i}.jpg\") for i in range(10)]\n",
    "    result = split_image_list(exact_list, batch_size=5)\n",
    "    test_eq(len(result), 2)  # Should create 2 batches\n",
    "    test_eq(len(result[0]), 5)  # Each with 5 images\n",
    "    test_eq(len(result[1]), 5)\n",
    "    \n",
    "    # Test with remainder\n",
    "    remainder_list = [Path(f\"img_{i}.jpg\") for i in range(11)]\n",
    "    result = split_image_list(\n",
    "        remainder_list, \n",
    "        batch_size=5, \n",
    "        batch_strategy='round_robin')\n",
    "    test_eq(len(result), 3)  # Should create 3 batches\n",
    "    test_eq(len(result[0]), 4)  # First two with 5 images each\n",
    "    test_eq(len(result[1]), 4)\n",
    "    test_eq(len(result[2]), 3)  # Last with 1 image\n",
    "\n",
    "    \n",
    "    # Test chunk strategy\n",
    "    chunk_result = split_image_list(\n",
    "        remainder_list, \n",
    "        batch_size=5,\n",
    "        batch_strategy=\"chunk\"\n",
    "        )\n",
    "    test_eq(len(chunk_result), 3)\n",
    "    test_eq(len(chunk_result[0]), 5)  # First: 0,1,2,3,4\n",
    "    test_eq(len(chunk_result[1]), 5)  # Second: 5,6,7,8,9\n",
    "    test_eq(len(chunk_result[2]), 1)  # Third: 10\n",
    "    \n",
    "    # Test invalid batch size\n",
    "    try:\n",
    "        split_image_list([Path(\"test.jpg\")], batch_size=0)\n",
    "        assert False, \"Should raise ValueError for batch_size=0\"\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    print(\"‚úÖ split_image_list tests passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = split_image_list(tst_images, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_image_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd8d12",
   "metadata": {},
   "source": [
    "# From image batch we create a batch list file\n",
    "- batch list file is a text file with the list of images for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b544d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_batch_list_file(batch: List[Path], batch_list_file: Path) -> None:\n",
    "    \"\"\"Create text file with image paths for batch processing.\"\"\"\n",
    "    batch_list_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(batch_list_file, 'w') as f:\n",
    "        for img_path in batch:\n",
    "            f.write(f\"{img_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5427809",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"/home/ai_dsx.work/data/projects/AD_tool_test/inference_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe27b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch_list_file(image_batch[0], Path(output_path,\"batch_0.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(predict_image_list_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "def create_inference_command(\n",
    "    model_path: Path, \n",
    "    batch_list_file: Path, \n",
    "    batch_id: str, \n",
    "    output_dir: Path,\n",
    "    save_heatmaps: bool = True, \n",
    "    heatmap_style: str = \"combined\"\n",
    ") -> List[str]:  # Returns list of command arguments for proper HPC execution\n",
    "    \"\"\"Create Python command list for batch inference.\"\"\"\n",
    "    python_code = (\n",
    "        f\"from be_vision_ad_tools.inference.prediction_system import predict_image_list_from_file; \"\n",
    "        f\"predict_image_list_from_file(\"\n",
    "        f\"model_path='{model_path}', \"\n",
    "        f\"image_list_file='{batch_list_file}', \"\n",
    "        f\"batch_id='{batch_id}', \"\n",
    "        f\"output_dir='{output_dir}', \"\n",
    "        f\"save_heatmaps={save_heatmaps}, \"\n",
    "        f\"heatmap_style='{heatmap_style}')\"\n",
    "    )\n",
    "    \n",
    "    # Return proper command list format for HPC execution\n",
    "    return [\"python\", \"-c\", python_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_inference_command(\n",
    "    model_path=Path(\"/home/ai_dsx.work/data/projects/AD_tool_test/models/best_model.pth\"), \n",
    "    batch_list_file=Path(output_path,\"batch_0.txt\"), \n",
    "    batch_id=\"batch_0\", \n",
    "    output_dir=output_path, save_heatmaps=True,\n",
    "    heatmap_style=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Let's test the updated create_inference_command directly\n",
    "test_cmd = create_inference_command(\n",
    "    model_path=Path(\"/test/model.pth\"), \n",
    "    batch_list_file=Path(\"/test/batch.txt\"), \n",
    "    batch_id=\"debug_test\", \n",
    "    output_dir=Path(\"/test/output\")\n",
    ")\n",
    "print(f\"Command type: {type(test_cmd)}\")\n",
    "print(f\"Command length: {len(test_cmd)}\")\n",
    "print(f\"Command content: {test_cmd}\")\n",
    "print(f\"Is it a list? {isinstance(test_cmd, list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e370d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the corrected create_inference_command function\n",
    "def test_create_inference_command():\n",
    "    \"\"\"Test the corrected command creation function.\"\"\"\n",
    "    model_path = Path(\"/test/model.pth\")\n",
    "    batch_list_file = Path(\"/test/batch.txt\")\n",
    "    batch_id = \"test_batch\"\n",
    "    output_dir = Path(\"/test/output\")\n",
    "    \n",
    "    cmd = create_inference_command(\n",
    "        model_path=model_path,\n",
    "        batch_list_file=batch_list_file,\n",
    "        batch_id=batch_id,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Should return a list with 3 elements: [\"python\", \"-c\", \"python_code\"]\n",
    "    test_eq(len(cmd), 3)\n",
    "    test_eq(cmd[0], \"python\")\n",
    "    test_eq(cmd[1], \"-c\")\n",
    "    assert isinstance(cmd[2], str), f\"Expected string, got {type(cmd[2])}\"\n",
    "    assert \"predict_image_list_from_file\" in cmd[2], \"Expected function call in command\"\n",
    "    \n",
    "    print(\"‚úÖ create_inference_command tests passed!\")\n",
    "    print(f\"   Command format: {cmd[:2] + [cmd[2][:50] + '...']}\")\n",
    "\n",
    "test_create_inference_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab60ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce148d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b480d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da275bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46a353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35aa92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_hpc_job(\n",
    "    batch_id: str,  # Unique identifier for the batch\n",
    "    command: Union[str, List[str]],  # Command string or list to execute\n",
    "    job_name_prefix: str = \"anomaly_inference\",  # Prefix for job naming\n",
    "    cores: int = 4,  # Number of CPU cores to request\n",
    "    **hpc_kwargs  # Additional HPC job parameters\n",
    ") -> HPC_Job:  # Returns configured HPC job object\n",
    "    \"\"\"Create single HPC job for batch inference with correct parameters.\"\"\"\n",
    "    \n",
    "    # Handle both string and list command formats\n",
    "    if isinstance(command, str):\n",
    "        # Legacy string format - wrap in list\n",
    "        cmd_list = [command]\n",
    "    elif isinstance(command, list):\n",
    "        # New list format - use directly\n",
    "        cmd_list = command\n",
    "    else:\n",
    "        raise ValueError(f\"Command must be string or list, got {type(command)}\")\n",
    "    \n",
    "    job = HPC_Job(\n",
    "        cmd=cmd_list,\n",
    "        cores=cores,\n",
    "        **hpc_kwargs\n",
    "    )\n",
    "    \n",
    "    # Store batch_id for identification\n",
    "    job.description = f\"{job_name_prefix}_{batch_id}\"\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the corrected create_hpc_job function\n",
    "def test_create_hpc_job():\n",
    "    \"\"\"Test HPC job creation with both string and list commands.\"\"\"\n",
    "    \n",
    "    # Test with string command (legacy)\n",
    "    string_job = create_hpc_job(\"test_batch\", \"echo 'hello'\")\n",
    "    test_eq(string_job.description, \"anomaly_inference_test_batch\")\n",
    "    test_eq(string_job.command, [\"echo 'hello'\"])\n",
    "    \n",
    "    # Test with list command (new format)\n",
    "    list_cmd = [\"python\", \"-c\", \"print('hello')\"]\n",
    "    list_job = create_hpc_job(\"test_batch2\", list_cmd)\n",
    "    test_eq(list_job.command, list_cmd)\n",
    "    \n",
    "    # Test with inference command (real usage)\n",
    "    inference_cmd = create_inference_command(\n",
    "        model_path=Path(\"/test/model.pth\"),\n",
    "        batch_list_file=Path(\"/test/batch.txt\"),\n",
    "        batch_id=\"real_test\",\n",
    "        output_dir=Path(\"/test/output\")\n",
    "    )\n",
    "    inference_job = create_hpc_job(\"real_batch\", inference_cmd)\n",
    "    test_eq(len(inference_job.command), 3)\n",
    "    test_eq(inference_job.command[0], \"python\")\n",
    "    \n",
    "    print(\"‚úÖ create_hpc_job tests passed!\")\n",
    "    print(f\"   String command format: {string_job.command}\")\n",
    "    print(f\"   List command format: {list_job.command[:2] + ['...']}\")\n",
    "\n",
    "test_create_hpc_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Create a better __repr__ method for HPC_Job using fastcore's patch\n",
    "#@patch_to(HPC_Job)\n",
    "#def __repr__(self: HPC_Job) -> str:\n",
    "    #\"\"\"Better representation for HPC_Job objects.\"\"\"\n",
    "    #state_names = {\n",
    "        #1: \"NONE\", 2: \"SUBMITTED\", 4: \"WAITING\", \n",
    "        #8: \"RUNNING\", 16: \"COMPLETED\", 4096: \"BSUB_FAILED\", 8192: \"TASK_FAILED\"\n",
    "    #}\n",
    "    #state_name = state_names.get(self.state, f\"UNKNOWN({self.state})\")\n",
    "    \n",
    "    #cmd_display = self.command[:2] if len(self.command) > 2 else self.command\n",
    "    #if len(self.command) > 2:\n",
    "        #cmd_display = f\"{cmd_display}... [{len(self.command)} args]\"\n",
    "    \n",
    "    #return (f\"HPC_Job(cmd={cmd_display}, \"\n",
    "            #f\"state={state_name}, \"\n",
    "            #f\"job_id={self.lsf_job_id or 'None'}, \"\n",
    "            #f\"description='{self.description}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_job = create_hpc_job(\n",
    "    batch_id=\"batch_0\",\n",
    "    command=create_inference_command(\n",
    "        model_path=Path(\"/home/ai_dsx.work/data/projects/AD_tool_test/models/best_model.pth\"), \n",
    "        batch_list_file=Path(output_path,\"batch_0.txt\"), \n",
    "        batch_id=\"batch_0\", \n",
    "        output_dir=output_path, save_heatmaps=True,\n",
    "        heatmap_style=\"combined\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb073e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_multinode_jobs_fresh(\n",
    "    model_path: Union[str, Path],  # Path to trained model checkpoint\n",
    "    test_folders: Union[str, Path, List[Union[str, Path]]],  # Test image folders/files\n",
    "    batch_size: int = 100,  # Maximum images per batch\n",
    "    output_dir: str = \"multinode_results\",  # Output directory for results\n",
    "    **job_kwargs  # Additional HPC job parameters\n",
    ") -> List[HPC_Job]:  # Returns list of HPC jobs for execution\n",
    "    \"\"\"Create list of HPC jobs for multinode inference with batch size control.\"\"\"\n",
    "    model_path = validate_model_path(model_path)\n",
    "    image_paths = resolve_test_folders(test_folders)\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No valid images found in test_folders\")\n",
    "    \n",
    "    # Split into batches based on batch_size and create jobs\n",
    "    image_batches = split_image_list(image_paths, batch_size=batch_size)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    jobs = []\n",
    "    for i, batch in enumerate(image_batches):\n",
    "        batch_id = f\"batch_{i+1:04d}\"\n",
    "        batch_list_file = output_path / \"batch_lists\" / f\"{batch_id}_images.txt\"\n",
    "        \n",
    "        create_batch_list_file(batch, batch_list_file)\n",
    "        command = create_inference_command(\n",
    "            model_path, \n",
    "            batch_list_file, \n",
    "            batch_id, \n",
    "            output_path)\n",
    "        \n",
    "        # Use corrected create_hpc_job function\n",
    "        job = create_hpc_job(batch_id, command, **job_kwargs)\n",
    "        jobs.append(job)\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multinode_jobs_fresh(\n",
    "    model_path=model_path,\n",
    "    test_folders=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\",\n",
    "    batch_size=50,\n",
    "    output_dir=\"/home/ai_dsx.work/data/projects/AD_tool_test/inference_batch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def submit_hpc_jobs(jobs: List[HPC_Job], num_nodes: int = 4) -> DistributeHPC:\n",
    "    \"\"\"Submit HPC jobs and return distributor for monitoring.\"\"\"\n",
    "    \n",
    "    # Create DistributeHPC with worker parameter (not jobs parameter)\n",
    "    distributor = DistributeHPC(worker=num_nodes)\n",
    "    \n",
    "    # Set jobs using the set_jobs method\n",
    "    distributor.set_jobs(jobs)\n",
    "    \n",
    "    # Start the job execution\n",
    "    distributor.start()\n",
    "    \n",
    "    print(f\"‚úÖ Submitted {len(jobs)} jobs to {num_nodes} worker nodes\")\n",
    "    return distributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the exact submit_hpc_jobs function manually\n",
    "print(\"üîç Testing submit_hpc_jobs manually...\")\n",
    "\n",
    "def manual_submit_hpc_jobs(jobs_list, num_nodes=4):\n",
    "    \"\"\"Manual version of submit function for testing\"\"\"\n",
    "    print(f\"Creating DistributeHPC with worker={num_nodes}\")\n",
    "    distributor = DistributeHPC(worker=num_nodes)\n",
    "    \n",
    "    print(f\"Setting {len(jobs_list)} jobs\")\n",
    "    distributor.set_jobs(jobs_list)\n",
    "    \n",
    "    print(\"Starting distributor\")\n",
    "    distributor.start()\n",
    "    \n",
    "    print(f\"‚úÖ Submitted {len(jobs_list)} jobs to {num_nodes} worker nodes\")\n",
    "    return distributor\n",
    "\n",
    "# Test with manual function\n",
    "test_jobs = [HPC_Job(cmd=[\"echo test1\"]), HPC_Job(cmd=[\"echo test2\"])]\n",
    "try:\n",
    "    manual_dist = manual_submit_hpc_jobs(test_jobs, 2)\n",
    "    print(\"‚úÖ Manual submit_hpc_jobs works!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Manual submit failed: {e}\")\n",
    "\n",
    "# Test the actual function from the notebook\n",
    "try:\n",
    "    actual_dist = submit_hpc_jobs(test_jobs, 2)\n",
    "    print(\"‚úÖ Actual submit_hpc_jobs works!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Actual submit failed: {e}\")\n",
    "    \n",
    "print(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=Path(\"/home/ai_dsx.work/data/projects/AD_tool_test/models/exports/TEST_MULITNODE_task_000_padim_resnet18_18_layer1/weights/torch/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb26aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multinode_jobs_fresh(\n",
    "     model_path=model_path,\n",
    "     test_folders=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\",\n",
    "     batch_size=50,\n",
    "     output_dir=\"/home/ai_dsx.work/data/projects/AD_tool_test/inference_multinode\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re-run the corrected function definition\n",
    "def submit_hpc_jobs_fresh(jobs: List[HPC_Job], num_nodes: int = 4) -> DistributeHPC:\n",
    "    \"\"\"Submit HPC jobs and return distributor for monitoring - FRESH VERSION.\"\"\"\n",
    "    \n",
    "    # Create DistributeHPC with worker parameter (not jobs parameter)\n",
    "    distributor = DistributeHPC(worker=num_nodes)\n",
    "    \n",
    "    # Set jobs using the set_jobs method\n",
    "    distributor.set_jobs(jobs)\n",
    "    \n",
    "    # Start the job execution\n",
    "    distributor.start()\n",
    "    \n",
    "    print(f\"‚úÖ Submitted {len(jobs)} jobs to {num_nodes} worker nodes\")\n",
    "    return distributor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_hpc_jobs_fresh(\n",
    "    jobs = create_multinode_jobs_fresh(\n",
    "        model_path=model_path,\n",
    "        test_folders=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\",\n",
    "        batch_size=50,\n",
    "        output_dir=\"/home/ai_dsx.work/data/projects/AD_tool_test/inference_multinode\",\n",
    "    ),\n",
    "    num_nodes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528bc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the fresh version\n",
    "try:\n",
    "    fresh_dist = submit_hpc_jobs_fresh(test_jobs, 2)\n",
    "    print(\"‚úÖ Fresh submit_hpc_jobs works!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fresh submit failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b267e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629053bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "def wait_and_summarize_jobs(distributor: DistributeHPC, jobs: List[HPC_Job]) -> Dict[str, Any]:\n",
    "    \"\"\"Wait for jobs completion and return summary statistics.\"\"\"\n",
    "    \n",
    "    # Note: DistributeHPC API may not have wait_for_all_jobs method\n",
    "    # Check if the method exists before calling\n",
    "    if hasattr(distributor, 'wait_for_all_jobs'):\n",
    "        try:\n",
    "            distributor.wait_for_all_jobs()\n",
    "            print(\"‚úÖ All jobs completed!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error waiting for jobs: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è DistributeHPC doesn't have wait_for_all_jobs method\")\n",
    "        print(\"üí° You may need to monitor jobs manually using distributor status\")\n",
    "    \n",
    "    # Count job statuses - check if jobs have status methods\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    other = 0\n",
    "    \n",
    "    for job in jobs:\n",
    "        if hasattr(job, 'get_status'):\n",
    "            status = job.get_status()\n",
    "            if status == \"completed\":\n",
    "                successful += 1\n",
    "            elif status == \"failed\":\n",
    "                failed += 1\n",
    "            else:\n",
    "                other += 1\n",
    "        elif hasattr(job, 'state'):\n",
    "            # Use state attribute if available\n",
    "            state = job.state\n",
    "            if state == job.JOB_COMPLETED:\n",
    "                successful += 1\n",
    "            elif state == job.JOB_TASK_FAILED:\n",
    "                failed += 1\n",
    "            else:\n",
    "                other += 1\n",
    "        else:\n",
    "            other += 1\n",
    "    \n",
    "    print(f\"üìä Results: ‚úÖ {successful} successful, ‚ùå {failed} failed, üîÑ {other} other\")\n",
    "    \n",
    "    return {\n",
    "        \"total_jobs\": len(jobs),\n",
    "        \"successful_jobs\": successful, \n",
    "        \"failed_jobs\": failed,\n",
    "        \"other_jobs\": other\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa41601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multinode_jobs(\n",
    "     model_path=model_path,\n",
    "     test_folders=\"/home/ai_dsx.work/data/projects/AD_tool_test/images/good\",\n",
    "     batch_size=50,\n",
    "     output_dir=\"/home/ai_dsx.work/data/projects/AD_tool_test/inference_multinode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24652787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_multinode_inference(\n",
    "    model_path: Union[str, Path],  # Path to trained anomaly detection model\n",
    "    test_folders: Union[str, Path, List[Union[str, Path]]],  # Test image sources\n",
    "    num_nodes: int = 4,  # Number of HPC nodes to use\n",
    "    batch_size: int = 100,  # Maximum images per batch (not images_per_batch)\n",
    "    output_dir: str = \"multinode_results\",  # Output directory path\n",
    "    wait_for_completion: bool = True,  # Whether to wait for job completion\n",
    "    **job_kwargs  # Additional HPC job parameters\n",
    ") -> Dict[str, Any]:  # Returns results dictionary with job information\n",
    "    \"\"\"Run multinode anomaly detection inference using HPC jobs with batch size control.\"\"\"\n",
    "    print(\"üöÄ Starting Multinode Inference\")\n",
    "    \n",
    "    # Create and submit jobs\n",
    "    jobs = create_multinode_jobs(model_path, test_folders, batch_size, output_dir, **job_kwargs)\n",
    "    distributor = submit_hpc_jobs(jobs, num_nodes)\n",
    "    \n",
    "    # Wait and get results if requested\n",
    "    results = {\"jobs\": jobs, \"distributor\": distributor, \"output_dir\": output_dir}\n",
    "    \n",
    "    if wait_for_completion:\n",
    "        job_summary = wait_and_summarize_jobs(distributor, jobs)\n",
    "        results.update(job_summary)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea548a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test framework\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0ad9e",
   "metadata": {},
   "source": [
    "# Usage Examples\n",
    "\n",
    "The multinode inference system provides flexible ways to run anomaly detection across multiple HPC nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc19611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Single folder inference with batch size\n",
    "# results = run_multinode_inference(\n",
    "#     model_path=\"path/to/padim_model.ckpt\",  # Your trained PaDiM model\n",
    "#     test_folders=\"test_images/\",            # Single test folder\n",
    "#     num_nodes=4,                           # Use 4 HPC nodes\n",
    "#     batch_size=50                          # Process max 50 images per batch\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Multiple folders with PaDiM model and larger batches\n",
    "# results = run_multinode_inference(\n",
    "#     model_path=\"models/padim_trained.ckpt\",         # PaDiM model checkpoint\n",
    "#     test_folders=[\"normal_test\", \"anomaly_test\"],   # Multiple test folders\n",
    "#     num_nodes=8,                                   # Scale to 8 nodes\n",
    "#     batch_size=100,                                # Max 100 images per batch\n",
    "#     save_heatmaps=True,                           # Generate visualizations\n",
    "#     memory_gb=32,                                 # More memory for larger batches\n",
    "#     gpu_required=True                             # Use GPU acceleration\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Mixed input with production settings and optimal batch size\n",
    "# results = run_multinode_inference(\n",
    "#     model_path=\"/home/models/production_padim.ckpt\",  # Production model\n",
    "#     test_folders=[                                    # Mixed input types\n",
    "#         \"batch_1_images/\",                           # Directory\n",
    "#         \"batch_2_images/\",                           # Directory  \n",
    "#         \"/absolute/path/special_image.jpg\"           # Single file\n",
    "#     ],\n",
    "#     num_nodes=6,                                     # Moderate parallelism\n",
    "#     batch_size=75,                                   # Max 75 images per batch\n",
    "#     output_dir=\"production_inference_results\",        # Custom output\n",
    "#     wait_for_completion=True,                        # Block until done\n",
    "#     time_hours=4,                                    # Longer time limit\n",
    "#     memory_gb=64                                     # High memory for quality\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the resolve_test_folders function\n",
    "test_paths = [\n",
    "    \"tutorial\",  # This should be a folder in your project\n",
    "    \"README.md\"  # This should be ignored (not an image)\n",
    "]\n",
    "\n",
    "try:\n",
    "    resolved = resolve_test_folders(test_paths)\n",
    "    print(f\"‚úÖ Function works! Found {len(resolved)} images\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Function test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('10_inference.multinode_infer.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
