"""Organize and save images based on their anomaly scores into customizable threshold folders"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/14_inference.anomaly_score_organizer.ipynb.

# %% auto 0
__all__ = ['determine_score_folder', 'create_score_folders', 'save_image_by_score', 'organize_images_by_score',
           'create_posters_for_score_folders', 'predict_and_organize_by_score', 'annotate_image_with_index',
           'create_image_index_dataframe']

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 3
import os
import json
import shutil
from pathlib import Path
from typing import Union, List, Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.patches as patches

from fastcore.all import *
from fastcore.test import *

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 4
# Import from existing modules
from vision_ad_tool.inference.prediction_system import (
    predict_image_list_from_file_enhanced,
    predict_image_list
)

from vision_ad_tool.inference.multinode_inference import (
    create_smart_batches,
    scan_folder_structure,
    create_batch_list_file
)

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 6
def determine_score_folder(
    anomaly_score: float,  # Anomaly score (0.0 to 1.0)
    score_thresholds: List[float]  # List of score thresholds (e.g., [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
) -> str:  # Returns the folder name based on the score
    """
    Determine which folder an image should go to based on its anomaly score.
    
    The image is placed in the folder corresponding to the smallest threshold that is >= the score.
    
    Example:
        score_thresholds = [0.5, 1.0]
        - score 0.3 -> folder "0.5"
        - score 0.7 -> folder "1.0"
    """
    # Sort thresholds to ensure correct ordering
    sorted_thresholds = sorted(score_thresholds)
    
    # Find the appropriate folder
    for threshold in sorted_thresholds:
        if anomaly_score <= threshold:
            return str(threshold)
    
    # If score exceeds all thresholds, use the last one
    return str(sorted_thresholds[-1])

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 7
def create_score_folders(
    output_dir: Path,  # Base output directory
    score_thresholds: List[float]  # List of score thresholds
) -> Dict[str, Path]:  # Returns dict mapping threshold strings to folder paths
    """
    Create subdirectories for each score threshold.
    
    Returns a dictionary mapping threshold values to their folder paths.
    """
    output_dir = Path(output_dir)
    folder_map = {}
    
    for threshold in score_thresholds:
        folder_name = str(threshold)
        folder_path = output_dir / folder_name
        folder_path.mkdir(parents=True, exist_ok=True)
        folder_map[folder_name] = folder_path
    
    print(f"‚úÖ Created {len(folder_map)} score folders in {output_dir}")
    for threshold, path in sorted(folder_map.items()):
        print(f"   üìÅ {threshold}: {path}")
    
    return folder_map

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 8
def save_image_by_score(
    image_path: Union[str, Path],  # Path to the source image
    anomaly_score: float,  # Anomaly score for the image
    output_dir: Path,  # Base output directory
    score_thresholds: List[float],  # List of score thresholds
    copy_mode: bool = True  # If True, copy files; if False, move files
) -> Path:  # Returns the destination path
    """
    Save (copy or move) an image to the appropriate score folder.
    
    Returns the destination path where the image was saved.
    """
    image_path = Path(image_path)
    
    if not image_path.exists():
        raise FileNotFoundError(f"Image not found: {image_path}")
    
    # Determine target folder
    folder_name = determine_score_folder(anomaly_score, score_thresholds)
    target_folder = output_dir / folder_name
    target_folder.mkdir(parents=True, exist_ok=True)
    
    # Create destination path
    dest_path = target_folder / image_path.name
    
    # Copy or move the file
    if copy_mode:
        shutil.copy2(image_path, dest_path)
    else:
        shutil.move(str(image_path), str(dest_path))
    
    return dest_path

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 9
def organize_images_by_score(
    prediction_results: List[Dict[str, Any]],  # List of prediction results from predict_image_list
    output_dir: Union[str, Path],  # Base output directory
    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds
    copy_mode: bool = True,  # If True, copy files; if False, move files
    save_metadata: bool = True  # If True, save metadata JSON for each folder
) -> Dict[str, Any]:  # Returns organization statistics
    """
    Organize images into folders based on their anomaly scores.
    
    Args:
        prediction_results: List of prediction results, each containing 'image_path' and 'anomaly_score'
        output_dir: Base directory where score folders will be created
        score_thresholds: List of threshold values (e.g., [0.5, 1.0] for simple two-folder setup)
        copy_mode: Whether to copy (True) or move (False) images
        save_metadata: Whether to save JSON metadata for each folder
    
    Returns:
        Dictionary with organization statistics
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("\nüóÇÔ∏è  ORGANIZING IMAGES BY ANOMALY SCORE")
    print("="*70)
    print(f"üìÇ Output directory: {output_dir}")
    print(f"üìä Score thresholds: {score_thresholds}")
    print(f"üìã Total images: {len(prediction_results)}")
    print(f"üîÑ Mode: {'COPY' if copy_mode else 'MOVE'}")
    
    # Create score folders
    folder_map = create_score_folders(output_dir, score_thresholds)
    
    # Track statistics
    folder_stats = {str(t): {'count': 0, 'images': [], 'scores': []} for t in score_thresholds}
    failed_count = 0
    
    print("\nüì¶ Processing images...")
    
    # Process each image
    for result in tqdm(prediction_results, desc="Organizing images"):
        try:
            image_path = result.get('image_path')
            anomaly_score = result.get('anomaly_score')
            
            if image_path is None or anomaly_score is None:
                print(f"‚ö†Ô∏è  Skipping result with missing data: {result}")
                failed_count += 1
                continue
            
            # Save image to appropriate folder
            dest_path = save_image_by_score(
                image_path=image_path,
                anomaly_score=anomaly_score,
                output_dir=output_dir,
                score_thresholds=score_thresholds,
                copy_mode=copy_mode
            )
            
            # Update statistics
            folder_name = determine_score_folder(anomaly_score, score_thresholds)
            folder_stats[folder_name]['count'] += 1
            folder_stats[folder_name]['images'].append(str(dest_path))
            folder_stats[folder_name]['scores'].append(float(anomaly_score))
            
        except Exception as e:
            print(f"‚ùå Error processing {result.get('image_path', 'unknown')}: {e}")
            failed_count += 1
    
    # Save metadata for each folder if requested
    if save_metadata:
        print("\nüíæ Saving metadata...")
        for folder_name, stats in folder_stats.items():
            if stats['count'] > 0:
                metadata_path = folder_map[folder_name] / "metadata.json"
                metadata = {
                    'threshold': folder_name,
                    'count': stats['count'],
                    'avg_score': float(np.mean(stats['scores'])) if stats['scores'] else 0.0,
                    'min_score': float(np.min(stats['scores'])) if stats['scores'] else 0.0,
                    'max_score': float(np.max(stats['scores'])) if stats['scores'] else 0.0,
                    'images': stats['images']
                }
                with open(metadata_path, 'w') as f:
                    json.dump(metadata, f, indent=2)
    
    # Print summary
    print("\nüìä ORGANIZATION SUMMARY")
    print("="*70)
    for threshold in sorted(score_thresholds):
        folder_name = str(threshold)
        count = folder_stats[folder_name]['count']
        if count > 0:
            avg_score = np.mean(folder_stats[folder_name]['scores'])
            print(f"üìÅ Folder '{folder_name}': {count} images (avg score: {avg_score:.4f})")
    
    if failed_count > 0:
        print(f"\n‚ö†Ô∏è  Failed: {failed_count} images")
    
    print("\n‚úÖ Organization complete!")
    
    return {
        'output_dir': str(output_dir),
        'score_thresholds': score_thresholds,
        'folder_stats': {k: {'count': v['count'], 
                             'avg_score': float(np.mean(v['scores'])) if v['scores'] else 0.0}
                        for k, v in folder_stats.items()},
        'total_processed': len(prediction_results) - failed_count,
        'failed_count': failed_count
    }

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 10
def create_posters_for_score_folders(
    output_dir: Union[str, Path],  # Base output directory with score folders
    image_index_df: pd.DataFrame,  # Dataframe with image indices
    score_thresholds: List[float],  # List of score thresholds
    images_per_poster: int = 20,  # Number of images per poster
    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster
    grid_cols: int = 5,  # Number of columns in the grid
    annotate_with_index: bool = True,  # Whether to add index numbers
    font_size: int = 30  # Font size for index numbers
) -> Dict[str, List[Path]]:  # Returns dict mapping folder names to poster paths
    """
    Create posters for all score folders.
    
    This function processes each score folder and creates one or more posters
    depending on the number of images in each folder.
    
    Args:
        output_dir: Base directory containing score folders
        image_index_df: DataFrame with image indices
        score_thresholds: List of threshold values
        images_per_poster: How many images per poster
        image_size: Size of each image in the poster
        grid_cols: Number of columns in the grid
        annotate_with_index: Whether to annotate images with indices
        font_size: Font size for annotations
    
    Returns:
        Dictionary mapping folder names to list of poster paths
    """
    output_dir = Path(output_dir)
    poster_paths = {}
    
    print("\nüñºÔ∏è  CREATING POSTERS FOR SCORE FOLDERS")
    print("="*70)
    
    for threshold in score_thresholds:
        folder_name = str(threshold)
        folder_path = output_dir / folder_name
        
        if not folder_path.exists():
            print(f"‚ö†Ô∏è  Folder {folder_name} does not exist, skipping...")
            continue
        
        # Get all images in folder (excluding metadata.json)
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']
        images_in_folder = []
        for ext in image_extensions:
            images_in_folder.extend(folder_path.glob(f"*{ext}"))
            images_in_folder.extend(folder_path.glob(f"*{ext.upper()}"))
        
        images_in_folder = sorted(set(images_in_folder))
        
        if not images_in_folder:
            print(f"üìÅ Folder '{folder_name}': No images found")
            continue
        
        print(f"\nüìÅ Processing folder '{folder_name}': {len(images_in_folder)} images")
        
        # Calculate number of posters needed
        num_posters = int(np.ceil(len(images_in_folder) / images_per_poster))
        folder_poster_paths = []
        
        # Create posters
        for poster_idx in range(num_posters):
            start_idx = poster_idx * images_per_poster
            end_idx = min((poster_idx + 1) * images_per_poster, len(images_in_folder))
            
            # Create a temporary folder for this subset
            poster_output_path = folder_path / f"poster_{poster_idx + 1:03d}.png"
            
            # Get subset of images for this poster
            poster_images = images_in_folder[start_idx:end_idx]
            
            # Create temporary folder with subset
            temp_folder = folder_path / f"_temp_poster_{poster_idx}"
            temp_folder.mkdir(exist_ok=True)
            
            # Copy images to temp folder
            for img in poster_images:
                shutil.copy2(img, temp_folder / img.name)
            
            # Create poster
            try:
                poster_path = create_poster_from_folder(
                    folder_path=temp_folder,
                    image_index_df=image_index_df,
                    output_path=poster_output_path,
                    images_per_poster=images_per_poster,
                    poster_index=poster_idx,
                    image_size=image_size,
                    grid_cols=grid_cols,
                    annotate_with_index=annotate_with_index,
                    font_size=font_size,
                    title=f"Score Folder {folder_name}"
                )
                
                if poster_path:
                    folder_poster_paths.append(poster_path)
                    print(f"  ‚úÖ Created poster {poster_idx + 1}/{num_posters}: {len(poster_images)} images")
            
            finally:
                # Clean up temp folder
                shutil.rmtree(temp_folder, ignore_errors=True)
        
        if folder_poster_paths:
            poster_paths[folder_name] = folder_poster_paths
            print(f"üìä Folder '{folder_name}': Created {len(folder_poster_paths)} poster(s)")
    
    print("\n‚úÖ Poster creation complete!")
    print(f"   Total folders processed: {len(poster_paths)}")
    print(f"   Total posters created: {sum(len(p) for p in poster_paths.values())}")
    
    return poster_paths

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 11
def predict_and_organize_by_score(
    model_path: Union[str, Path],  # Path to the trained model
    image_list_file: Union[str, Path],  # Text file with image paths (one per line)
    output_dir: Union[str, Path],  # Base output directory for organized images
    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds
    batch_id: Optional[str] = None,  # Optional batch identifier
    copy_mode: bool = True,  # If True, copy files; if False, move files
    save_metadata: bool = True,  # If True, save metadata JSON for each folder
    create_posters: bool = True,  # If True, create posters for each score folder
    images_per_poster: int = 20,  # Number of images per poster
    image_size: Tuple[int, int] = (224, 224),  # Size of each image in the poster
    grid_cols: int = 5,  # Number of columns in poster grid
    annotate_with_index: bool = True,  # Whether to add index numbers to images in posters
    font_size: int = 30,  # Font size for index annotations
    device: str = "auto",  # Device for inference ("auto", "cpu", "cuda")
    **kwargs  # Additional arguments passed to prediction function
) -> Dict[str, Any]:  # Returns combined prediction and organization results
    """
    Complete workflow: Predict anomaly scores, organize images, and create indexed posters.
    
    This is the main function that combines:
    1. Image index dataframe creation
    2. Smart batch creation
    3. Prediction using predict_image_list_from_file_enhanced
    4. Image organization based on anomaly scores
    5. Poster creation with index annotations (optional)
    
    Args:
        model_path: Path to the trained anomaly detection model
        image_list_file: Text file containing paths to images (one per line)
        output_dir: Directory where score-based folders will be created
        score_thresholds: List of threshold values (customize to your needs)
            Examples:
            - [0.5, 1.0] for simple two-folder setup
            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization
        batch_id: Optional identifier for this batch
        copy_mode: Whether to copy (True) or move (False) images
        save_metadata: Whether to save JSON metadata for each folder
        create_posters: Whether to create image posters for each score folder
        images_per_poster: Number of images to include in each poster
        image_size: Size to resize each image to in posters
        grid_cols: Number of columns in the poster grid
        annotate_with_index: Whether to annotate images with their dataframe index
        font_size: Font size for index annotations
        device: Device to use for inference
        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)
    
    Returns:
        Dictionary containing:
        - image_index_df: DataFrame with image indices
        - prediction_results: Full prediction results
        - organization_stats: Statistics about image organization
        - poster_paths: Paths to created posters (if create_posters=True)
    """
    print("\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE WITH INDEXED POSTERS")
    print("="*70)
    
    # Step 0: Create image index dataframe
    print("\nüìä Step 0: Creating image index dataframe...")
    image_index_df = create_image_index_dataframe(image_list_file)
    
    # Save the dataframe
    output_dir_path = Path(output_dir)
    output_dir_path.mkdir(parents=True, exist_ok=True)
    df_path = output_dir_path / "image_index.csv"
    image_index_df.to_csv(df_path, index=False)
    print(f"üíæ Saved image index dataframe to {df_path}")
    
    # Step 1: Run predictions
    print("\nüìä Step 1: Running predictions...")
    prediction_output = predict_image_list_from_file_enhanced(
        model_path=model_path,
        image_list_file=image_list_file,
        batch_id=batch_id,
        output_dir=output_dir,
        device=device,
        save_results=True,
        **kwargs
    )
    
    # Extract results
    prediction_results = prediction_output.get('results', [])
    
    if not prediction_results:
        print("‚ö†Ô∏è  No prediction results to organize!")
        return {
            'image_index_df': image_index_df,
            'prediction_results': prediction_output,
            'organization_stats': None,
            'poster_paths': None
        }
    
    print(f"‚úÖ Predictions complete: {len(prediction_results)} images processed")
    
    # Step 2: Organize images by score
    print("\nüìÅ Step 2: Organizing images by score...")
    organization_stats = organize_images_by_score(
        prediction_results=prediction_results,
        output_dir=output_dir,
        score_thresholds=score_thresholds,
        copy_mode=copy_mode,
        save_metadata=save_metadata
    )
    
    # Step 3: Create posters (optional)
    poster_paths = None
    if create_posters:
        print("\nüñºÔ∏è  Step 3: Creating indexed posters...")
        poster_paths = create_posters_for_score_folders(
            output_dir=output_dir,
            image_index_df=image_index_df,
            score_thresholds=score_thresholds,
            images_per_poster=images_per_poster,
            image_size=image_size,
            grid_cols=grid_cols,
            annotate_with_index=annotate_with_index,
            font_size=font_size
        )
    
    print("\nüéâ WORKFLOW COMPLETE!")
    print("="*70)
    print(f"üìä Image index dataframe: {df_path}")
    print(f"üìÅ Organized images: {output_dir}")
    if poster_paths:
        total_posters = sum(len(p) for p in poster_paths.values())
        print(f"üñºÔ∏è  Created {total_posters} poster(s)")
    
    return {
        'image_index_df': image_index_df,
        'image_index_df_path': str(df_path),
        'prediction_results': prediction_output,
        'organization_stats': organization_stats,
        'poster_paths': poster_paths
    }

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 12
def annotate_image_with_index(
    image: Union[Image.Image, np.ndarray],  # PIL Image or numpy array
    index: int,  # Index number to display
    font_size: int = 40,  # Font size for the index number
    position: str = "top_left",  # Position: "top_left", "top_right", "bottom_left", "bottom_right"
    text_color: Tuple[int, int, int] = (255, 255, 0),  # RGB color for text (yellow)
    bg_color: Tuple[int, int, int, int] = (0, 0, 0, 180)  # RGBA color for background (semi-transparent black)
) -> Image.Image:  # Returns annotated PIL Image
    """
    Add an index number to an image.
    
    Args:
        image: Input image (PIL Image or numpy array)
        index: Index number to display
        font_size: Size of the font
        position: Where to place the index number
        text_color: RGB tuple for text color
        bg_color: RGBA tuple for background color (includes alpha for transparency)
    
    Returns:
        PIL Image with index number annotated
    """
    # Convert to PIL Image if numpy array
    if isinstance(image, np.ndarray):
        image = Image.fromarray(image)
    
    # Make a copy to avoid modifying original
    img_copy = image.copy().convert("RGBA")
    
    # Create a transparent overlay
    overlay = Image.new('RGBA', img_copy.size, (255, 255, 255, 0))
    draw = ImageDraw.Draw(overlay)
    
    # Try to use a nice font, fall back to default if not available
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
    except:
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf", font_size)
        except:
            font = ImageFont.load_default()
    
    # Prepare text
    text = f"#{index}"
    
    # Get text bounding box
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    
    # Add padding
    padding = 10
    box_width = text_width + 2 * padding
    box_height = text_height + 2 * padding
    
    # Calculate position
    img_width, img_height = img_copy.size
    
    if position == "top_left":
        x, y = padding, padding
    elif position == "top_right":
        x, y = img_width - box_width - padding, padding
    elif position == "bottom_left":
        x, y = padding, img_height - box_height - padding
    elif position == "bottom_right":
        x, y = img_width - box_width - padding, img_height - box_height - padding
    else:
        x, y = padding, padding  # default to top_left
    
    # Draw semi-transparent background rectangle
    draw.rectangle(
        [x, y, x + box_width, y + box_height],
        fill=bg_color
    )
    
    # Draw text
    draw.text(
        (x + padding, y + padding),
        text,
        font=font,
        fill=text_color
    )
    
    # Composite the overlay onto the image
    result = Image.alpha_composite(img_copy, overlay)
    
    # Convert back to RGB
    return result.convert("RGB")

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 13
def create_image_index_dataframe(
    image_list: Union[List[Union[str, Path]], str, Path]  # List of images or path to text file
) -> pd.DataFrame:  # Returns dataframe with index and image paths
    """
    Create a dataframe with index numbers for all images.
    
    This dataframe is used to track and reference images by index number
    when creating posters.
    
    Args:
        image_list: Either a list of image paths or a path to text file containing image paths
    
    Returns:
        DataFrame with columns: ['index', 'image_path', 'image_name']
    """
    # Handle input - could be list or file path
    if isinstance(image_list, (str, Path)):
        # Read from file
        image_list_path = Path(image_list)
        if image_list_path.exists() and image_list_path.is_file():
            images = []
            with open(image_list_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        images.append(line)
        else:
            raise FileNotFoundError(f"Image list file not found: {image_list}")
    else:
        images = [str(img) for img in image_list]
    
    # Create dataframe
    df = pd.DataFrame({
        'index': range(len(images)),
        'image_path': images,
        'image_name': [Path(img).name for img in images]
    })
    
    print(f"üìä Created image index dataframe with {len(df)} images")
    
    return df

# %% ../../nbs/14_inference.anomaly_score_organizer.ipynb 16
def predict_and_organize_by_score(
    model_path: Union[str, Path],  # Path to the trained model
    image_list_file: Union[str, Path],  # Text file with image paths (one per line)
    output_dir: Union[str, Path],  # Base output directory for organized images
    score_thresholds: List[float] = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Score thresholds
    batch_id: Optional[str] = None,  # Optional batch identifier
    copy_mode: bool = True,  # If True, copy files; if False, move files
    save_metadata: bool = True,  # If True, save metadata JSON for each folder
    device: str = "auto",  # Device for inference ("auto", "cpu", "cuda")
    **kwargs  # Additional arguments passed to prediction function
) -> Dict[str, Any]:  # Returns combined prediction and organization results
    """
    Complete workflow: Predict anomaly scores and organize images into score-based folders.
    
    This is the main function that combines:
    1. Smart batch creation
    2. Prediction using predict_image_list_from_file_enhanced
    3. Image organization based on anomaly scores
    
    Args:
        model_path: Path to the trained anomaly detection model
        image_list_file: Text file containing paths to images (one per line)
        output_dir: Directory where score-based folders will be created
        score_thresholds: List of threshold values (customize to your needs)
            Examples:
            - [0.5, 1.0] for simple two-folder setup
            - [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for fine-grained organization
        batch_id: Optional identifier for this batch
        copy_mode: Whether to copy (True) or move (False) images
        save_metadata: Whether to save JSON metadata for each folder
        device: Device to use for inference
        **kwargs: Additional arguments (save_heatmap, heatmap_style, etc.)
    
    Returns:
        Dictionary containing:
        - prediction_results: Full prediction results
        - organization_stats: Statistics about image organization
    """
    print("\nüöÄ PREDICT AND ORGANIZE BY ANOMALY SCORE")
    print("="*70)
    
    # Step 1: Run predictions
    print("\nüìä Step 1: Running predictions...")
    prediction_output = predict_image_list_from_file_enhanced(
        model_path=model_path,
        image_list_file=image_list_file,
        batch_id=batch_id,
        output_dir=output_dir,
        device=device,
        save_results=True,
        **kwargs
    )
    
    # Extract results
    prediction_results = prediction_output.get('results', [])
    
    if not prediction_results:
        print("‚ö†Ô∏è  No prediction results to organize!")
        return {
            'prediction_results': prediction_output,
            'organization_stats': None
        }
    
    print(f"‚úÖ Predictions complete: {len(prediction_results)} images processed")
    
    # Step 2: Organize images by score
    print("\nüìÅ Step 2: Organizing images by score...")
    organization_stats = organize_images_by_score(
        prediction_results=prediction_results,
        output_dir=output_dir,
        score_thresholds=score_thresholds,
        copy_mode=copy_mode,
        save_metadata=save_metadata
    )
    
    print("\nüéâ WORKFLOW COMPLETE!")
    print("="*70)
    
    return {
        'prediction_results': prediction_output,
        'organization_stats': organization_stats
    }
